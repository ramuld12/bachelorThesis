{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CleanText(text):\n",
    "    text = re.sub(r'''[\\[|\\]]''', \"\", text).split()\n",
    "    text = np.array(text, dtype=\"float64\")\n",
    "    return text\n",
    "\n",
    "# Normal dataset\n",
    "df1 = pd.read_csv(\"all_data_with_identitiesEmbedded.csv\")\n",
    "df1['comment_text'] = df1['comment_text'].apply(lambda text: CleanText(text))\n",
    "df1['toxicity'] = df1['toxicity'].apply(lambda text: round(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../CSVFiles/all_data_with_identities.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df['other_religions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal dataset\n",
    "df = pd.read_csv(\"../CSVFiles/all_data_with_identities.csv\")\n",
    "df['toxicity'] = df['toxicity'].apply(lambda text: np.round(text >= 0.5))\n",
    "\n",
    "df['male'] = df['male'].apply(lambda x: np.round(x >= 0.5))\n",
    "df['female'] = df['female'].apply(lambda x: np.round(x >= 0.5))\n",
    "df['LGBTQ'] = df['LGBTQ'].apply(lambda x: np.round(x >= 0.5))\n",
    "df['christian'] = df['christian'].apply(lambda x: np.round(x >= 0.5))\n",
    "df['muslim'] = df['muslim'].apply(lambda x: np.round(x >= 0.5))\n",
    "df['black'] = df['black'].apply(lambda x: np.round(x >= 0.5))\n",
    "df['white'] = df['white'].apply(lambda x: np.round(x >= 0.5))\n",
    "df['other_religion'] = df['other_religion'].apply(lambda x: np.round(x >= 0.5))\n",
    "\n",
    "df = df.loc[:, [\"comment_text\", \"split\", \"toxicity\", \"male\", \"female\", \"LGBTQ\", \"christian\", \"muslim\", \"other_religion\", \"black\", \"white\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxLst = []\n",
    "splitLst = []\n",
    "\n",
    "idxLst.extend(df.query('other_religion>=0.5 and toxicity == 1').index[:30])\n",
    "for i in range(10):\n",
    "    splitLst.append('train')\n",
    "    splitLst.append('test')\n",
    "    splitLst.append('val')\n",
    "    \n",
    "\n",
    "idxLst.extend(df.query('other_religion>=0.5 and toxicity == 0').index[:30])\n",
    "for i in range(10):\n",
    "    splitLst.append('train')\n",
    "    splitLst.append('test')\n",
    "    splitLst.append('val')\n",
    "    \n",
    "    \n",
    "toxicity = [1, 0]\n",
    "\n",
    "for t in toxicity:\n",
    "    count = 0\n",
    "    iterater = 0\n",
    "    currentDF = df.query('toxicity=='+str(t))\n",
    "    currentDFIndexes = currentDF.index\n",
    "    while count < 25000:\n",
    "        if currentDFIndexes[iterater] not in idxLst:\n",
    "            idxLst.append(currentDFIndexes[iterater])\n",
    "            count+=1\n",
    "            if count <= 22000:\n",
    "                splitLst.append('train')\n",
    "            elif count > 22000 and count <= 23500:\n",
    "                splitLst.append('test')\n",
    "            else:\n",
    "                splitLst.append('val')\n",
    "        iterater +=1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxLst = []\n",
    "splitLst = []\n",
    "\n",
    "idxLst.extend(df.query('other_religion>=0.5 and toxicity == 1').index[:30])\n",
    "for i in range(10):\n",
    "    splitLst.append('train')\n",
    "    splitLst.append('test')\n",
    "    splitLst.append('val')\n",
    "    \n",
    "\n",
    "idxLst.extend(df.query('other_religion>=0.5 and toxicity == 0').index[:30])\n",
    "for i in range(10):\n",
    "    splitLst.append('train')\n",
    "    splitLst.append('test')\n",
    "    splitLst.append('val')\n",
    "    \n",
    "    \n",
    "print(len(idxLst))\n",
    "print(len(splitLst))\n",
    "\n",
    "\n",
    "#categories = ['male', 'christian', 'LGBTQ', 'muslim', 'female', 'black', 'white']\n",
    "toxicity = [1, 0]\n",
    "\n",
    "for t in toxicity:\n",
    "    for cat in categories:\n",
    "        \n",
    "        count = 0\n",
    "        iterater = 0\n",
    "        \n",
    "        currentDF = df.query(cat+'>=0.5 and toxicity=='+str(t))\n",
    "        currentDFIndexes = currentDF.index\n",
    "        while count < 4000:\n",
    "            if currentDFIndexes[iterater] not in idxLst:\n",
    "                idxLst.append(currentDFIndexes[iterater])\n",
    "                count+=1\n",
    "                if count <= 3000:\n",
    "                    splitLst.append('train')\n",
    "                elif count > 3000 and count <= 3500:\n",
    "                    splitLst.append('test')\n",
    "                else:\n",
    "                    splitLst.append('val')\n",
    "            iterater +=1\n",
    "        print(iterater)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDF = df.loc[idxLst]\n",
    "\n",
    "for i, idx in enumerate(idxLst):\n",
    "    newDF.at[idx, 'split'] = splitLst[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDF.to_csv(r'C:\\Users\\frede\\Desktop\\small50000AllDataWithIdentities.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempDF = newDF.loc[:, [\"comment_text\", \"split\", \"toxicity\", \"male\", \"female\", \"LGBTQ\", \"christian\", \"muslim\", \"other_religion\", \"black\", \"white\"]]\n",
    "\n",
    "print('Toxic samples: ', sum(newDF['toxicity']))\n",
    "print('None-toxic samples: ', len(newDF['toxicity'])-sum(newDF['toxicity']))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Validation samples: \", np.sum(newDF['split'] == 'val'))\n",
    "print(\"Test samples\", np.sum(newDF['split'] == 'test'))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "for col in tempDF.columns[3:]:\n",
    "    print(col + \": \" + str(np.sum(tempDF[col])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "newDF = newDF.loc[:, [\"comment_text\", \"split\", \"toxicity\", \"male\", \"female\", \"LGBTQ\", \"christian\", \"muslim\", \"other_religion\", \"black\", \"white\"]]\n",
    "\n",
    "newDF['male'] = newDF['male'].apply(lambda x: np.round(x >= 0.5))\n",
    "newDF['female'] = newDF['female'].apply(lambda x: np.round(x >= 0.5))\n",
    "newDF['LGBTQ'] = newDF['LGBTQ'].apply(lambda x: np.round(x >= 0.5))\n",
    "newDF['christian'] = newDF['christian'].apply(lambda x: np.round(x >= 0.5))\n",
    "newDF['muslim'] = newDF['muslim'].apply(lambda x: np.round(x >= 0.5))\n",
    "newDF['black'] = newDF['black'].apply(lambda x: np.round(x >= 0.5))\n",
    "newDF['white'] = newDF['white'].apply(lambda x: np.round(x >= 0.5))\n",
    "newDF['other_religion'] = newDF['other_religion'].apply(lambda x: np.round(x >= 0.5))\n",
    "\n",
    "\n",
    "dfToEmbedding= newDF\n",
    "\n",
    "bertweet = AutoModel.from_pretrained(\"vinai/bertweet-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False, normalization=True)                     \n",
    "bertweet.eval()\n",
    "bertweet.to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, idx in enumerate(dfToEmbedding.index):\n",
    "        bertweet.resize_token_embeddings(len(tokenizer))\n",
    "        dfToEmbedding.at[idx, 'comment_text'] = str(bertweet(torch.tensor(tokenizer.encode\n",
    "                                                                  (dfToEmbedding['comment_text'][idx], add_special_tokens=True,\n",
    "                                                                   truncation=True)).to('cuda').unsqueeze(0))[1].detach().cpu().numpy()[0])\n",
    "\n",
    "dfToEmbedding.to_csv(r'C:\\Users\\frede\\Desktop\\50000DomainDataBertweetEmbedded.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "dfToEmbedding= pd.read_csv(\"../CSVFiles/smallDomainDataNotEmbedded.csv\")\n",
    "\n",
    "\n",
    "bertweet = AutoModel.from_pretrained(\"vinai/bertweet-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False, normalization=True)                     \n",
    "bertweet.eval()\n",
    "bertweet.to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, idx in enumerate(dfToEmbedding.index):\n",
    "        embeds = bertweet(torch.tensor(tokenizer.encode(dfToEmbedding['comment_text'][idx], add_special_tokens=True,\n",
    "                                                                   truncation=True)).to('cuda').unsqueeze(0))[0].squeeze(0)\n",
    "        \n",
    "        if embeds.shape[0] < 200:\n",
    "            embeds = torch.cat((embeds, torch.zeros((200-embeds.shape[0], 768)).to('cuda')))\n",
    "            \n",
    "        elif embeds.shape[0] > 200:\n",
    "            embeds = embeds[0:200]\n",
    "        \n",
    "        dfToEmbedding.at[idx, 'comment_text'] = embeds.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
