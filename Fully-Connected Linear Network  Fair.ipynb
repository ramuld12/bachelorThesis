{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cosmetic-budget",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "explicit-trigger",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CleanText(text):\n",
    "    text = re.sub(r'''[\\[|\\]]''', \"\", text).split()\n",
    "    text = np.array(text, dtype=\"float64\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-hello",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-emergency",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "still-country",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal dataset\n",
    "#df = pd.read_csv(\"domain_data_with_identities.csv\")\n",
    "\n",
    "# Epsilon 0,1 fair dataset\n",
    "df = pd.read_csv(\"domain_data_with_identities_private_xtrain0,1.csv\")\n",
    "\n",
    "# Epsilon 0,01 fair dataset\n",
    "#df = pd.read_csv(\"domain_data_with_identities_private_xtrain0,1.csv\")\n",
    "\n",
    "df['comment_text'] = df['comment_text'].apply(lambda text: CleanText(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "korean-measure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating values for training_data\n",
    "training_data = df[df['split'] == 'train']\n",
    "#training_data = training_data.drop(training_data.query('toxicity==0').sample(frac=.85).index)\n",
    "\n",
    "# Getting test_data\n",
    "test_data = df[df['split'] == 'test']\n",
    "\n",
    "# Getting validation_data\n",
    "validation_data = df[df['split'] == 'val']\n",
    "#validation_data = validation_data.drop(validation_data.query('toxicity==0').sample(frac=.85).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "sorted-tulsa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxic samples training data:  11358.0\n",
      "None-toxic samples training data:  87747.0\n",
      "\n",
      "\n",
      "Toxic samples validation data:  1878.0\n",
      "None-toxic samples validation data:  14552.0\n",
      "\n",
      "\n",
      "Toxic samples test data:  5640.0\n",
      "None-toxic samples test data:  42235.0\n",
      "\n",
      "\n",
      "male: 26894.0\n",
      "female: 34305.0\n",
      "LGBTQ: 8420\n",
      "christian: 23475.0\n",
      "muslim: 13080.0\n",
      "other_religion: 49.0\n",
      "black: 9207.0\n",
      "white: 15855.0\n"
     ]
    }
   ],
   "source": [
    "print('Toxic samples training data: ', sum(training_data['toxicity']))\n",
    "print('None-toxic samples training data: ', len(training_data['toxicity'])-sum(training_data['toxicity']))\n",
    "\n",
    "print(\"\\n\")\n",
    "print('Toxic samples validation data: ', sum(validation_data['toxicity']))\n",
    "print('None-toxic samples validation data: ', len(validation_data['toxicity'])-sum(validation_data['toxicity']))\n",
    "\n",
    "print(\"\\n\")\n",
    "print('Toxic samples test data: ', sum(test_data['toxicity']))\n",
    "print('None-toxic samples test data: ', len(test_data['toxicity'])-sum(test_data['toxicity']))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "for col in training_data.columns[3:]:\n",
    "    print(col + \": \" + str(np.sum(training_data[col])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "defensive-interaction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device(type='cuda')\n"
     ]
    }
   ],
   "source": [
    "### Set parameters for the model\n",
    "#torch.manual_seed(42) # set fixed random seed for reproducibility\n",
    "batch_size = 128\n",
    "epochs = 1000\n",
    "lr = 0.0001\n",
    "\n",
    "cuda = True # Set this if training on GPU\n",
    "cuda = cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "print(\"Using \"+repr(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "perfect-proceeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Creating data loaders\n",
    "X_train = np.array(training_data['comment_text'].values.tolist())\n",
    "Y_train = np.array(training_data['toxicity'].values.tolist())\n",
    "\n",
    "X_test = np.array(test_data['comment_text'].values.tolist())\n",
    "Y_test = np.array(test_data['toxicity'].values.tolist())\n",
    "\n",
    "X_val = np.array(validation_data['comment_text'].values.tolist())\n",
    "Y_val = np.array(validation_data['toxicity'].values.tolist())\n",
    "\n",
    "                    \n",
    "prepare_trainloader = []\n",
    "for i in range(len(X_train)):\n",
    "    prepare_trainloader.append([X_train[i], Y_train[i]])\n",
    "    \n",
    "prepare_testloader = []\n",
    "for i in range(len(X_test)):\n",
    "    prepare_testloader.append([X_test[i], Y_test[i]])\n",
    "    \n",
    "prepare_validloader = []\n",
    "for i in range(len(X_val)):\n",
    "    prepare_validloader.append([X_val[i], Y_val[i]])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(prepare_trainloader, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(prepare_validloader, batch_size=len(prepare_validloader), shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(prepare_testloader, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "generic-consistency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([16430, 768])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, data in enumerate(valid_loader):\n",
    "    print(batch_idx, data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "composed-postage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CheckAccuracy(predictions, labels):\n",
    "        acc = 0.0\n",
    "        for i in range(len(predictions)):\n",
    "            if (predictions[i] == labels[i]):\n",
    "                acc += 1\n",
    "        return acc/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "applicable-waste",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Sequential(nn.Linear(768, 64), nn.ReLU(), nn.Dropout(p=0.2))\n",
    "        self.fc2 = nn.Sequential(nn.Linear(64, 32), nn.ReLU())\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        #self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "threaded-springfield",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1 Average training loss: 0.005125\n",
      "====> Validation set loss: 0.005487\n",
      "Accuracy on Validation set:  0.4782073380940655\n",
      "F1_score:  0.6228866346324968\n",
      "\n",
      "\n",
      "====> Epoch: 2 Average training loss: 0.004589\n",
      "====> Validation set loss: 0.005463\n",
      "Accuracy on Validation set:  0.5215464171386358\n",
      "F1_score:  0.5513738166705149\n",
      "\n",
      "\n",
      "====> Epoch: 3 Average training loss: 0.004482\n",
      "====> Validation set loss: 0.005443\n",
      "Accuracy on Validation set:  0.5180989903964541\n",
      "F1_score:  0.3327650869416979\n",
      "\n",
      "\n",
      "====> Epoch: 4 Average training loss: 0.004441\n",
      "====> Validation set loss: 0.005446\n",
      "Accuracy on Validation set:  0.5213001723713371\n",
      "F1_score:  0.10083256244218317\n",
      "\n",
      "\n",
      "====> Epoch: 5 Average training loss: 0.004414\n",
      "====> Validation set loss: 0.005466\n",
      "Accuracy on Validation set:  0.5328736764343758\n",
      "F1_score:  0.03263640999490056\n",
      "\n",
      "\n",
      "====> Epoch: 6 Average training loss: 0.004390\n",
      "====> Validation set loss: 0.005495\n",
      "Accuracy on Validation set:  0.5368135927111549\n",
      "F1_score:  0.00947867298578199\n",
      "\n",
      "\n",
      "====> Epoch: 7 Average training loss: 0.004372\n",
      "====> Validation set loss: 0.005522\n",
      "Accuracy on Validation set:  0.5368135927111549\n",
      "F1_score:  0.0021220159151193636\n",
      "\n",
      "\n",
      "====> Epoch: 8 Average training loss: 0.004362\n",
      "====> Validation set loss: 0.005569\n",
      "Accuracy on Validation set:  0.5373060822457523\n",
      "F1_score:  0.0\n",
      "\n",
      "\n",
      "====> Epoch: 9 Average training loss: 0.004346\n",
      "====> Validation set loss: 0.005612\n",
      "Accuracy on Validation set:  0.537552327013051\n",
      "F1_score:  0.0\n",
      "\n",
      "\n",
      "====> Epoch: 10 Average training loss: 0.004331\n",
      "====> Validation set loss: 0.005648\n",
      "Accuracy on Validation set:  0.537552327013051\n",
      "F1_score:  0.0\n",
      "\n",
      "\n",
      "====> Epoch: 11 Average training loss: 0.004317\n",
      "====> Validation set loss: 0.005721\n",
      "Accuracy on Validation set:  0.537552327013051\n",
      "F1_score:  0.0\n",
      "\n",
      "\n",
      "====> Epoch: 12 Average training loss: 0.004315\n",
      "====> Validation set loss: 0.005770\n",
      "Accuracy on Validation set:  0.537552327013051\n",
      "F1_score:  0.0\n",
      "\n",
      "\n",
      "====> Epoch: 13 Average training loss: 0.004292\n",
      "====> Validation set loss: 0.005840\n",
      "Accuracy on Validation set:  0.537552327013051\n",
      "F1_score:  0.0\n",
      "\n",
      "\n",
      "====> Epoch: 14 Average training loss: 0.004282\n",
      "====> Validation set loss: 0.005927\n",
      "Accuracy on Validation set:  0.537552327013051\n",
      "F1_score:  0.0\n",
      "\n",
      "\n",
      "====> Epoch: 15 Average training loss: 0.004275\n",
      "====> Validation set loss: 0.005978\n",
      "Accuracy on Validation set:  0.537552327013051\n",
      "F1_score:  0.0\n",
      "\n",
      "\n",
      "====> Epoch: 16 Average training loss: 0.004264\n",
      "====> Validation set loss: 0.006074\n",
      "Accuracy on Validation set:  0.537552327013051\n",
      "F1_score:  0.0\n",
      "\n",
      "\n",
      "====> Epoch: 17 Average training loss: 0.004246\n",
      "====> Validation set loss: 0.006197\n",
      "Accuracy on Validation set:  0.537552327013051\n",
      "F1_score:  0.0\n",
      "\n",
      "\n",
      "====> Epoch: 18 Average training loss: 0.004231\n",
      "====> Validation set loss: 0.006303\n",
      "Accuracy on Validation set:  0.537552327013051\n",
      "F1_score:  0.0\n",
      "\n",
      "\n",
      "====> Epoch: 19 Average training loss: 0.004219\n",
      "====> Validation set loss: 0.006419\n",
      "Accuracy on Validation set:  0.537552327013051\n",
      "F1_score:  0.0\n",
      "\n",
      "\n",
      "====> Epoch: 20 Average training loss: 0.004213\n",
      "====> Validation set loss: 0.006565\n",
      "Accuracy on Validation set:  0.537552327013051\n",
      "F1_score:  0.0\n",
      "\n",
      "\n",
      "====> Epoch: 21 Average training loss: 0.004199\n",
      "====> Validation set loss: 0.006662\n",
      "Accuracy on Validation set:  0.537552327013051\n",
      "F1_score:  0.0\n",
      "\n",
      "\n",
      "====> Epoch: 22 Average training loss: 0.004187\n",
      "====> Validation set loss: 0.006783\n",
      "Accuracy on Validation set:  0.537552327013051\n",
      "F1_score:  0.0\n",
      "\n",
      "\n",
      "====> Epoch: 23 Average training loss: 0.004180\n",
      "====> Validation set loss: 0.006888\n",
      "Accuracy on Validation set:  0.537552327013051\n",
      "F1_score:  0.0\n",
      "\n",
      "\n",
      "====> Epoch: 24 Average training loss: 0.004167\n",
      "====> Validation set loss: 0.007033\n",
      "Accuracy on Validation set:  0.537552327013051\n",
      "F1_score:  0.0\n",
      "\n",
      "\n",
      "====> Epoch: 25 Average training loss: 0.004156\n",
      "====> Validation set loss: 0.007111\n",
      "Accuracy on Validation set:  0.537552327013051\n",
      "F1_score:  0.0\n",
      "\n",
      "\n",
      "====> Epoch: 26 Average training loss: 0.004134\n",
      "====> Validation set loss: 0.007266\n",
      "Accuracy on Validation set:  0.537552327013051\n",
      "F1_score:  0.0\n",
      "\n",
      "\n",
      "====> Epoch: 27 Average training loss: 0.004138\n",
      "====> Validation set loss: 0.007372\n",
      "Accuracy on Validation set:  0.537552327013051\n",
      "F1_score:  0.0\n",
      "\n",
      "\n",
      "====> Epoch: 28 Average training loss: 0.004128\n",
      "====> Validation set loss: 0.007497\n",
      "Accuracy on Validation set:  0.537552327013051\n",
      "F1_score:  0.0\n",
      "\n",
      "\n",
      "====> Epoch: 29 Average training loss: 0.004111\n",
      "====> Validation set loss: 0.007605\n",
      "Accuracy on Validation set:  0.537552327013051\n",
      "F1_score:  0.0\n",
      "\n",
      "\n",
      "====> Epoch: 30 Average training loss: 0.004099\n",
      "====> Validation set loss: 0.007732\n",
      "Accuracy on Validation set:  0.537552327013051\n",
      "F1_score:  0.0\n",
      "\n",
      "\n",
      "====> Epoch: 31 Average training loss: 0.004084\n",
      "====> Validation set loss: 0.007894\n",
      "Accuracy on Validation set:  0.537552327013051\n",
      "F1_score:  0.0\n",
      "\n",
      "\n",
      "====> Epoch: 32 Average training loss: 0.004086\n",
      "====> Validation set loss: 0.007972\n",
      "Accuracy on Validation set:  0.537552327013051\n",
      "F1_score:  0.0\n",
      "\n",
      "\n",
      "====> Epoch: 33 Average training loss: 0.004063\n",
      "====> Validation set loss: 0.008112\n",
      "Accuracy on Validation set:  0.537552327013051\n",
      "F1_score:  0.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Setting up model parameters\n",
    "model = Net().to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "loss_function = nn.BCELoss()\n",
    "#loss_function = nn.MSELoss()\n",
    "#loss_function = nn.NLLLoss()\n",
    "\n",
    "# Initialising early stopping criterias\n",
    "early_stopping = 30\n",
    "notImproved = 0\n",
    "bestLoss = None\n",
    "bestModel = None\n",
    "\n",
    "trainArr = []\n",
    "valArr = []\n",
    "\n",
    "bestf1 = 0\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    \n",
    "    train_loss = 0.0\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        \n",
    "        # get the input\n",
    "        inputs, labels = data\n",
    "        \n",
    "        inputs = inputs.unsqueeze(1)\n",
    "        \n",
    "        inputs = inputs.to(device).float()\n",
    "        labels = labels.to(device).float()\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize            \n",
    "        outputs = model(inputs).squeeze()\n",
    "        \n",
    "        \n",
    "        loss = loss_function(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    \n",
    "    print('====> Epoch: {} Average training loss: {:.6f}'.format(epoch, train_loss))\n",
    "    \n",
    "    trainArr.append(train_loss)\n",
    "    \n",
    "    valid_loss = 0\n",
    "    labs = []\n",
    "    preds = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():        \n",
    "        for batch_idx, data in enumerate(valid_loader):\n",
    "            # get the input\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.unsqueeze(1)\n",
    "            inputs = inputs.to(device).float()\n",
    "            #labels = labels.to(device).long()\n",
    "            labels = labels.to(device).float()\n",
    "            \n",
    "            outputs = model(inputs).squeeze()\n",
    "            \n",
    "            labs.extend(labels)\n",
    "            preds.extend(torch.round(outputs))\n",
    "            #preds.extend(outputs.argmax(axis=1))\n",
    "            \n",
    "            valid_loss += loss_function(outputs, labels).item()\n",
    "    \n",
    "    valid_loss /= len(valid_loader.dataset)\n",
    "    \n",
    "    valArr.append(valid_loss)\n",
    "    \n",
    "    print('====> Validation set loss: {:.6f}'.format(valid_loss))\n",
    "    \n",
    "    print(\"Accuracy on Validation set: \", CheckAccuracy(labs, preds))\n",
    "    \n",
    "    f1 = f1_score(torch.Tensor(labs).numpy(), torch.Tensor(preds).numpy(), zero_division=1)\n",
    "    \n",
    "    print(\"F1_score: \", f1)\n",
    "    if f1 > bestf1:\n",
    "        bestModel = model\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # Initialising params for early stopping\n",
    "    if bestLoss == None:\n",
    "        bestLoss = valid_loss\n",
    "        \n",
    "    # Checks for early stopping\n",
    "    if valid_loss <= bestLoss:\n",
    "        notImproved = 0\n",
    "        bestLoss = valid_loss\n",
    "        #bestModel = model\n",
    "    else:\n",
    "        notImproved +=1\n",
    "        \n",
    "    # Converges if the training has not improved for a certain amount of iterations\n",
    "    if notImproved >= early_stopping:\n",
    "        break\n",
    "\n",
    "#if bestModel != None:\n",
    "model = bestModel\n",
    "    \n",
    "\n",
    "#torch.save(model, 'bestModelFullyConnectedNetwork0,1Fair.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "amateur-wells",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnQAAAFNCAYAAACJ9PI3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA4sElEQVR4nO3de3xV1Z338c+XICqK2AG0CiZBB6+ggUZgRKmXWi+txbZaYfJIrW0pVlur01YsM4V2hulMtR3GGS+D1Y60sehTqw92bO1I6206VqMiFIQOYIJRihjHiA1y8/f8sXfwEHI5ycnh5CTf9+t1XuSsvdc+a+8cm2/X2mttRQRmZmZmVrz6FboBZmZmZpYbBzozMzOzIudAZ2ZmZlbkHOjMzMzMipwDnZmZmVmRc6AzMzMzK3IOdGZFQtIvJH26u/ftZBtOl1Tf3cftqSQ9Kulz6c9Vkn6Vzb5d+JxSSW9LKulqW9s5dkj68+4+7t7S8roX+/mY5YsDnVkepX+km1/vStqS8b6qM8eKiPMi4q7u3rc3k3S9pMdbKR8qaZuk0dkeKyKqI+LD3dSuWkkfyjj2+og4MCJ2dsfxe5PuvO7tkfRnku6X9CdJdZL+sp19R0t6WNLrkryYq/UIDnRmeZT+kT4wIg4E1gMXZJRVN+8nqX/hWtmr/Qg4RdLIFuVTgeUR8fsCtMl6ppuBbcChQBVwq6QT2th3O3Av8Nm91DazDjnQmRVA89ClpOsk/RH4oaT3Sfq5pE2S/jf9eURGnczhv8skPSnpxnTflySd18V9R0p6XNJmSY9IulnSj7M8j+PSz3pT0gpJH8vYdr6klelxX5H01bR8aHpub0p6Q9ITkvb43yJJt0m6sUXZ/5N0bfrzdelxN0taLemslseIiHrg18ClLTZNB+7q6Jq3+OzLJD2Z8f5sSaskNUr6V0AZ246S9GtJDWkvTrWkg9NtPwJKgQfTntqvSypPhxL7p/scLmlxen3WSPp8xrHnSrpX0sL03FdIqmz9N7THOQxO621Ke6H+uvnaS/pzSY+l5/O6pHvSckn6J0mvpduWqY2ezfT4d0jakP5u/k7pMHJ6/f5L0r+kx1mV+TtLt69Lz+klpT3YLa97J86n3e99i+McAHwS+JuIeDsingQWs+f3BoCIWB0RdwArsrnuZnuDA51Z4bwf+DOgDJhB8t/jD9P3pcAW4F/bqT8BWA0MBb4L3CFJXdj3buBpYAgwlzb+iLUkaR/gQeBXwCHAl4BqSceku9wBfCEiBgGjSYIVwF8B9cAwkt6QbwCtDVvdDVzS3E5J7wM+DCxKP+Mq4OT0+OcAtW009a7Mc0rrVgA/ofPXvPkYQ4H7gL8muaZrgUmZuwDfAQ4HjgOOILm2RMSl7N5b+91WPuInJNfocOAi4O9bBNaPAYuAg0mCR4dtTv0LMBg4EvggSbD9TLrtb0l+l+8DRqT7QnLNJwNHp593CdDQxvHvAnYAfw6MTetm3lc4AVhHcs3mAD9TMtR5AHATcF76+zwFWJrj+TR/Xjb/jRwN7IyIP2SUvQC01UNn1uM40JkVzrvAnIjYGhFbIqIhIu6LiKaI2AzMI/kj1Za6iLg9ve/qLuAwkoCU9b6SSoGTgW9GxLaMnolsTAQOBP4hrftr4OfAtHT7duB4SQdFxP9GxHMZ5YcBZRGxPSKeiNYfKv0ESdA7LX1/EfDfEfEqsBPYNz3+PhFRGxFr22jn/em5npK+nw78IiI2deGaNzsfWBkRP42I7cB84I/NGyNiTUT8Z/q73QR8P8vjIukI4FTguoh4JyKWAj9g96D9ZEQ8lP4+fwSclMVxS0jC2PURsTkiaoHvZRx3O0mwPTz93CczygcBxwKKiBcjYkMrxz8UOA/4SkT8KSJeA/6JZHi72WvA/PT3fg9J2PpIuu1dYLSk/SNiQ0S02/uVxflA9v+NHAg0tihrTM/brCg40JkVzqaIeKf5jaSBkv4tHTp6C3gcOFhtz3zMDBBN6Y8HdnLfw4E3MsoAXs6y/YcDL0fEuxlldcDw9OdPkgSfunQo7y/S8huANcCv0iG2Wa0dPA15i3gvIP4lUJ1uWwN8haTX6zVJiyQd3sZxmoD/C0xPe2eqSP64d+Wa73buLdq6672kQ9I2vZIe98ckvUTZaP6dbM4oy7yukPH7BJqA/dTxfZhDgQHpsVo77tdJehafTodxL0/P7dckPYA3AxslLZB0UCvHLwP2ATYoGU5/E/g3kt7bZq+0CO91JAHyTyThbGZa/z8kHZvj+UD2/428DbQ8p4OAza3sa9YjOdCZFU7LXqm/Ao4BJkTEQSTDXJBxb1YebAD+TNLAjLIjsqz7KnCEdr//rRR4BSAinomIKSR/0B8guYmctDflryLiSOAC4Fq1cv9b6ifARZLKSIbP7mveEBF3R8SpJEEigH9sp613AZ8Czibpdfl5Wt7Va76BjOuUBsXM6/adtE0npsf9Py2O2d7MyFdJfieZvUO7rmsOXue9Xrg9jhsRf4yIz0fE4cAXgFuULg8SETdFxAdIhiCPBr7WyvFfBrYCQyPi4PR1UERkDlsObzHkWUpyvkTEwxFxNkkv2irg9lzOp5P+APSXNCqj7CR8j5wVEQc6s55jEMk9XG9K+jOSe4zyKiLqgBpgrqQBaS/aBVlW/x3wJ+DrkvaRdHpad1F6rCpJg9MhybdIhkmR9FElN+Aro7zV5Toi4nlgE8mQ48MR8WZ6jGMknSlpX+AdkuvW3pIfTwBvAguARRGxLS3v6jX/D+AESZ9Ie8a+THJPZLNBJL0+b0oazp4BaCPJfV97iIiXgd8C35G0n6QTSWZTVre2f7bSYcd7gXmSBqUh+VqS3kMkXaz3JoT8L0no3CnpZEkT0nsm/0Ryvfe41ukw7K+A70k6SFI/JZNDMoeaDwG+nH5fLia5v/AhSYdK+lh6L91WkmvX7hIuHZ1PJ6/Nn4CfAd+WdICkScAUkuFs0usT6Xe8eaLIfiQ9hKS/p307+7lm3cmBzqznmA/sT9Lz8BTwy730uVXAX5Dc6P53wD0kf1TblYaij5HcN/U6cAswPSJWpbtcCtSmQ44zSXqpAEYBj5D80f5v4JaIeLSdj/oJ8CGSSRLN9gX+If3cP5IEhW+009YAFpL05izM2DSfLlzziHgduDhtQ0N6Tv+Vscu3gHEk92H9B0lYyPQd4K/TocmvtvIR04Bykt6r+0nutfzPbNrWgS+RhLJ1wJMk1/TOdNvJwO8kvU1yH+XVEfESydDj7SQhr47kfG+kddNJQs7KdP+fkvS4NfsdybV6neR+xYsiooHkb9Ffpef7Bsn9hl/M8Xw664sk34XXSL5zVzTfx5cG3beB5em+ZST/R6C5B28Lyf2AZgWj1u9FNrO+SslyFasiIu89hNZ3SLoM+Fw6TF5UJP0f4ISIuL7QbTFrixczNevjJJ1M0ivyEskyE1NIep7MDIiITg/jmu1tDnRm9n6SIcEhJGufXZHeu2ZmZkXCQ65mZmZmRc6TIszMzMyKnAOdmZmZWZHr0/fQDR06NMrLywvdDDMzM7MOPfvss69HxLDWtvXpQFdeXk5NTU2hm2FmZmbWIUl1bW3zkKuZmZlZkXOgMzMzMytyDnRmZmZmRa5P30NnZmbWV2zfvp36+nreeeedQjfFOrDffvsxYsQI9tlnn6zrONCZmZn1AfX19QwaNIjy8nIkFbo51oaIoKGhgfr6ekaOHJl1PQ+5mpmZ9QHvvPMOQ4YMcZjr4SQxZMiQTvekOtCZmZn1EQ5zxaErvycHOjMzM8u7hoYGKioqqKio4P3vfz/Dhw/f9X7btm3t1q2pqeHLX/5yh59xyimndEtbH330UT760Y9mtW9DUwPLNi6j5tUalm1cRkNTQ7e0obN8D52ZmZnl3ZAhQ1i6dCkAc+fO5cADD+SrX/3qru07duygf//WY0llZSWVlZUdfsZvf/vbbmlrthqaGqhrrOPdeBeAbTu3UdeYrP07ZOCQvdoW99CZmZnZnqqrobwc+vVL/q2u7vaPuOyyy7j22ms544wzuO6663j66ac55ZRTGDt2LKeccgqrV68Gdu8xmzt3Lpdffjmnn346Rx55JDfddNOu4x144IG79j/99NO56KKLOPbYY6mqqiIiAHjooYc49thjOfXUU/nyl7/cYU/cG2+8wYUXXsiJJ57IxIkTWbZsGQCPPfYYk8ZPYuqHplL14Sr+9PafeH3j63zu459j0vhJjB49mieeeKLbr1lb3ENnZmZmu6uuhhkzoKkpeV9Xl7wHqKrq1o/6wx/+wCOPPEJJSQlvvfUWjz/+OP379+eRRx7hG9/4Bvfdd98edVatWsVvfvMbNm/ezDHHHMMVV1yxxxIfzz//PCtWrODwww9n0qRJ/Nd//ReVlZV84Qtf4PHHH2fkyJFMmzatw/bNmTOHsWPH8sADD/DrX/+a6dOns3TpUm688Ua+Nu9rnHTySTT9qYkB+w7g/h/fz8QPTuTyqy9n7KFjaWq+fnuBe+jMzMxsd7NnvxfmmjU1JeXd7OKLL6akpASAxsZGLr74YkaPHs0111zDihUrWq3zkY98hH333ZehQ4dyyCGHsHHjxj32GT9+PCNGjKBfv35UVFRQW1vLqlWrOPLII3ctB5JNoHvyySe59NJLATjzzDNpaGigsbGRSZMmMf9b81l0xyI2N26mf//+HF9xPA/e+yB3fP8Oli9fzqBBg7p6WTrNgc7MzMx2t35958pzcMABB+z6+W/+5m8444wz+P3vf8+DDz7Y5tId++67766fS0pK2LFjR1b7NA+7dkZrdSQxa9YsbrntFra9s43LL7ic2jW1jJs4jh/87AccPfJoLr30UhYuXNjpz+uqvAY6SedKWi1pjaRZrWyXpJvS7cskjeuorqQKSU9JWiqpRtL4jG3Xp/uvlnROPs/NzMys1yot7Vx5N2lsbGT48OEA/Pu//3u3H//YY49l3bp11NbWAnDPPfd0WGfy5MlUp/cPPvroowwdOpSDDjqItWvXctr405gzew4nVJxA7ZpaXn/1dSqOquCaK6/hs5/9LM8991y3n0Nb8hboJJUANwPnAccD0yQd32K384BR6WsGcGsWdb8LfCsiKoBvpu9Jt08FTgDOBW5Jj2NmZmadMW8eDBy4e9nAgUl5Hn3961/n+uuvZ9KkSezcubPbj7///vtzyy23cO6553Lqqady6KGHMnjw4HbrzJ07l5qaGk488URmzZrFXXfdBcD8+fMZPXo0Z/7FmRx68KF8qepLbFyxkbNOOYuxY8dy3333cfXVV3f7ObRFXel+zOrA0l8AcyPinPT99QAR8Z2Mff4NeDQifpK+Xw2cDpS3VVfSw8CdEXGPpGnABRHxly2Pn+43NyL+u602VlZWRk1NTfeeuJmZWQ/04osvctxxx2Vfobo6uWdu/fqkZ27evG6fEFEIb7/9NgceeCARwZVXXsmoUaO45pprCt2sPbT2+5L0bES0un5LPme5DgdeznhfD0zIYp/hHdT9CvCwpBtJehibVxEcDjzVyrHMzMyss6qqekWAa+n222/nrrvuYtu2bYwdO5aLLr2IZRuXsW3nNgaUDGD4oOF7fQ257pDPQNfacytadge2tU97da8AromI+yR9CrgD+FCWn4ekGSTDu5Tm+V4AMzMz61muueaaXT1yPWlh4Fzlc1JEPXBExvsRwKtZ7tNe3U8DP0t//r9A86SIbD6PiFgQEZURUTls2LCsT8bMzMx6l1c2v7IrzDV7N97llc2vFKhFXZfPQPcMMErSSEkDSCYsLG6xz2JgejrbdSLQGBEbOqj7KvDB9Oczgf/JONZUSftKGkky0eLpfJ2cmZmZFbdtO1t/hmxb5T1Z3oZcI2KHpKuAh4ESkokMKyTNTLffBjwEnA+sAZqAz7RXNz3054F/ltQfeId0+DQ99r3ASmAHcGVEdP8UGTMzM+sVBpQMaDW8DSgZUIDW5Cavj/6KiIdIQltm2W0ZPwdwZbZ10/IngQ+0UWcekN851WZmZtZjNDQ18MrmV7o0qWH4oOG73UMH0E/9GD6o+OZU+kkRZmZmlnenn346Dz/88G5l8+fP54tf/GK7dZqXFzv//PN58803d9ve0NTAN/7mG9xx8x3Ae5MaGpoadtvvgQceYOXKlbvef/Ob3+SRRx5hyMAhlA0u29UjN6BkAGWDy7IOhI8++igf/ehHs9o33/LaQ2dmZmYGyXNTFy1axDnnvPcgp0WLFnHDDTdkVf+hh/YYtOOVza8QLRa0aJ7UkBnKHnjgAT760Y9y/PHJMwq+/e1v79o2ZOCQopvR2hr30JmZmdkeqpdXUz6/nH7f6kf5/HKql1fndLyLLrqIn//852zduhWA2tpaXn31VU499VSuuOIKKisrOeGEE5gzZ06r9cvLy3n99dcBmDdvHscccwyfu+hz1K2t27XP/dX3M/386Vx0xkV88pOfpKmpid/+9rcsXryYr33ta1RUVLB27Vouu+wyfvrTnwKwZMkSxo4dy5gxY7j88st3ta+8vJw5c+Ywbtw4xowZw6pVq9o9vzfeeIMLL7yQE088kYkTJ7Js2TIAHnvsMSoqKqioqGDs2LFs3ryZDRs2MHnyZCoqKhg9ejRPPPFETtcWHOjMzMysherl1cx4cAZ1jXUEQV1jHTMenJFTqBsyZAjjx4/nl7/8JZD0zl1yySVIYt68edTU1LBs2TIee+yxXWGoNc8++yyLFi3i+eefZ/4P57PyhfeGUs847wwWPrSQn/7mpxx33HHccccdnHLKKXzsYx/jhhtuYOnSpRx11FG79n/nnXe47LLLuOeee1i+fDk7duzg1ltv3bV96NChPPfcc1xxxRXceOON7Z7fnDlzGDt2LMuWLePv//7vmT59OgA33ngjN998M0uXLuWJJ55g//335+677+acc85h6dKlvPDCC1RUVHTlku7Ggc7MzMx2M3vJbJq2N+1W1rS9idlLZud03OZhV0gC3bRp0wC49957GTduHGPHjmXFihW73e/W0hNPPMHHP/5xBg4cyDGHH8MHP/zBXdvWrl7L5z/+eaaeOZXq6mpWrFjR5nEAVq9ezciRIzn66KMB+PSnP83jjz++a/snPvEJAD7wgQ9QW1vb7rGefPJJLr30UgDOPPNMGhoaaGxsZNKkSVx77bXcdNNNvPnmm/Tv35+TTz6ZH/7wh8ydO5fly5czaNCgdo+dDQc6MzMz2836xvWdKs/WhRdeyJIlS3juuefYsmUL48aN46WXXuLGG29kyZIlLFu2jI985CO888477R5HSh4ONWTgEAYNGER/JVMCvn3Nt5n/z/NZuWIlc+bM6fA4HT3Pft999wWgpKSEHTt2dPpYkpg1axY/+MEP2LJlCxMnTmTVqlVMnjyZxx9/nOHDh3PppZeycOHCdo+dDQc6MzMz203p4NYfjdlWebYOPPBATj/9dC6//PJdvXNvvfUWBxxwAIMHD2bjxo384he/aPcYkydP5v7772fLli1s3ryZR375CIcNOozKwyvZ2rSV4448ju3bt1Nd/d7w8KBBg9i8efMexzr22GOpra1lzZo1APzoRz/igx/84B77ZWPy5Mm7PvPRRx9l6NChHHTQQaxdu5YxY8Zw3XXXUVlZyapVq6irq+OQQw7h85//PJ/97Gd57rnnuvSZmRzozMzMbDfzzprHwH0G7lY2cJ+BzDsr96Vep02bxgsvvMDUqVMBOOmkkxg7diwnnHACl19+OZMmTWq3/rhx47jkkkuoqKjgk5/8JKeddtqubX/7t3/LhAkTOPvsszn22GN3lU+dOpUbbriBsWPHsnbt2l3l++23Hz/84Q+5+OKLGTNmDP369WPmzJldOq+5c+dSU1PDiSeeyKxZs7jrrruAZGmW0aNHc9JJJ7H//vtz3nnn8eijj+6aJHHfffdx9dVXd+kzM6mj7sberLKyMprXtzEzM+vNXnzxRY477ris969eXs3sJbNZ37ie0sGlzDtrHlVjqvLYQsvU2u9L0rMRUdna/l6HzszMzPZQNaZqrwS4XJ70YO9xoDMzM7OCaGhq2O3RW81PegAc6jrJ99CZmZlZQbyy+ZXdnqMK7z3pwTrHgc7MzKyP6Gn3zW/bua1T5X1FV35PDnRmZmZ9wH777UdDQ0OPCnUDSgZ0qrwviAgaGhrYb7/9OlXP99CZmZn1ASNGjKC+vp5NmzYVuim7bNu2jYYtu4dMSQzZfwgvvvFiAVtWWPvttx8jRozoVB0HOjMzsz5gn332YeTIkYVuxh5aWx7lnDHnFLpZRcfr0HkdOjMzs5x4zbq9w+vQmZmZWV5UL69mxoMzaNreBEBdYx0zHpwB4FC3F3lShJmZmXXZ7CWzd4W5Zk3bm5i9ZHaBWtQ3OdCZmZlZl61vXN+pcssPBzozMzPrstLBpZ0qt/xwoDMzM7Mum3fWPAbuM3C3soH7DGTeWfMK1KK+Ka+BTtK5klZLWiNpVivbJemmdPsySeM6qivpHklL01etpKVpebmkLRnbbsvnuZmZmVky8WHBBQsoG1yGEGWDy1hwwQJPiNjL8jbLVVIJcDNwNlAPPCNpcUSszNjtPGBU+poA3ApMaK9uRFyS8RnfAxozjrc2IirydU5mZma9Ua7LjlSNqXKAK7B8LlsyHlgTEesAJC0CpgCZgW4KsDCSxfCeknSwpMOA8o7qShLwKeDMPJ6DmZlZr+ZlR3qHfA65Dgdeznhfn5Zls082dU8DNkbE/2SUjZT0vKTHJJ2WS+PNzMz6Ai870jvks4dOrZS1fCxFW/tkU3ca8JOM9xuA0ohokPQB4AFJJ0TEW7t9oDQDmAFQWuoZOGZm1rd52ZHeIZ89dPXAERnvRwCvZrlPu3Ul9Qc+AdzTXBYRWyOiIf35WWAtcHTLRkXEgoiojIjKYcOGdeG0zMzMeg8vO9I75DPQPQOMkjRS0gBgKrC4xT6LgenpbNeJQGNEbMii7oeAVRFR31wgaVg6mQJJR5JMtFiXr5MzMzPrDbzsSO+QtyHXiNgh6SrgYaAEuDMiVkiamW6/DXgIOB9YAzQBn2mvbsbhp7L7cCvAZODbknYAO4GZEfFGvs7PzMysN2ie+JDLLFcrPCUTTPumysrKqKmpKXQzzMzMzDok6dmIqGxtm58UYWZmVuSql1dTPr+cft/qR/n8cqqXVxe6SbaX5XOWq5mZmeWZ15EzcA+dmZlZUfM6cgYOdGZmZkXN68gZONCZmZkVNa8jZ+BAZ2ZmVtS8jpyBA52ZmVnB5TJLtWpMFQsuWEDZ4DKEKBtcxoILFnhCRB/jdei8Dp2ZmRVQy1mqkPSwOZRZS16HzszMrIfyLFXrDg50ZmZmBeRZqtYdHOjMzMwKyLNUrTs40JmZmRWQZ6lad3CgMzMzKyDPUrXu4FmunuVqZmZmRcCzXM3MzMx6MQc6MzOzHOWyMLBZd+hf6AaYmZkVs5YLA9c11jHjwRkAvg/O9hr30JmZmeXACwNbT+BAZ2ZmlgMvDGw9gQOdmZlZDrwwsPUEDnRmZtbn5TKpwQsDW0+Q10An6VxJqyWtkTSrle2SdFO6fZmkcR3VlXSPpKXpq1bS0oxt16f7r5Z0Tj7PzczMeofmSQ11jXUEsWtSQ7ahzgsDW0+Qt4WFJZUAfwDOBuqBZ4BpEbEyY5/zgS8B5wMTgH+OiAnZ1E3rfw9ojIhvSzoe+AkwHjgceAQ4OiJ2ttVGLyxsZmbl88upa6zbo7xscBm1X6nd+w0ya0OhFhYeD6yJiHURsQ1YBExpsc8UYGEkngIOlnRYNnUlCfgUSYhrPtaiiNgaES8Ba9LjmJmZtcmTGqw3yGegGw68nPG+Pi3LZp9s6p4GbIyI/+nE55mZme3GkxqsN8hnoFMrZS3Hd9vaJ5u603ivdy7bz0PSDEk1kmo2bdrUShUzM+tLPKnBeoN8Brp64IiM9yOAV7Pcp926kvoDnwDu6eTnERELIqIyIiqHDRuW9cmYmVnv5EkN1hvk89FfzwCjJI0EXgGmAn/ZYp/FwFWSFpFMimiMiA2SNnVQ90PAqoiob3GsuyV9n2RSxCjg6Tycl5mZ9TJVY6oc4Kyo5S3QRcQOSVcBDwMlwJ0RsULSzHT7bcBDJDNc1wBNwGfaq5tx+KnsPtxKeux7gZXADuDK9ma4mpmZmfUWeVu2pBh42RIzs96henk1s5fMZn3jekoHlzLvrHnucbNep71lS/I55GpmZpZ3zQsDN21vAti1MDDgUGd9hh/9ZWZmRW32ktm7wlyzpu1NzF4yu0AtMtv7HOjMzKyoeWFgMwc6MzMrcl4Y2MyBzszMipwXBjZzoDMzsx6ienk15fPL6fetfpTPL6d6eXVW9bwwsJmXLfGyJWZmPUDLmaqQ9LI5mJm9p71lS9xDZ2ZmBeeZqma5caAzM7OC80xVs9w40JmZWcF5pqpZbhzozMys4DxT1Sw3DnRmZlZwnqlqlhvPcvUsVzMzMysCnuVqZmZ519V15Mwsd/0L3QAzMyt+LdeRq2usY8aDMwA8bGq2F7iHzszMcuZ15MwKy4HOzMxy5nXkzArLgc7MzHLmdeTMCsuBzszMcuZ15MwKy4HOzMyA3Gapeh05s8LyOnReh87MbI9ZqpD0sDmUmfUcXofOzMza5VmqZsUtr4FO0rmSVktaI2lWK9sl6aZ0+zJJ47KpK+lL6bYVkr6blpVL2iJpafq6LZ/nZmbWm3iWqllxy9vCwpJKgJuBs4F64BlJiyNiZcZu5wGj0tcE4FZgQnt1JZ0BTAFOjIitkg7JON7aiKjI1zmZmfVWpYNLqWusa7XczHq+fPbQjQfWRMS6iNgGLCIJYpmmAAsj8RRwsKTDOqh7BfAPEbEVICJey+M5mJn1CZ6lalbc8hnohgMvZ7yvT8uy2ae9ukcDp0n6naTHJJ2csd9ISc+n5ad1x0mYmfUFnqVqVtzy+SxXtVLWckptW/u0V7c/8D5gInAycK+kI4ENQGlENEj6APCApBMi4q3dPlCaAcwAKC31UIKZWbOqMVUOcGZFKp89dPXAERnvRwCvZrlPe3XrgZ+lw7RPA+8CQyNia0Q0AETEs8Bakt683UTEgoiojIjKYcOGdfnkzMzMzHqKfAa6Z4BRkkZKGgBMBRa32GcxMD2d7ToRaIyIDR3UfQA4E0DS0cAA4HVJw9LJFKQ9dqOAdXk8PzOzHiWXhYHNrLjlbcg1InZIugp4GCgB7oyIFZJmpttvAx4CzgfWAE3AZ9qrmx76TuBOSb8HtgGfjoiQNBn4tqQdwE5gZkS8ka/zMzPrSVouDFzXWMeMB2cAeBjVrA/wkyL8pAgz6wXK55e3uuxI2eAyar9Su/cbZGbdzk+KMDPr5bwwsFnf5kBnZtYLtLUAsBcGNusbHOjMzHoBLwxs1rc50JmZ9QJeGNisb/OkCE+KMLMeonp5NbOXzGZ943pKB5cy76x5DmRmtkt7kyLy+aQIMzPLkpcdMbNceMjVzKwHmL1k9q4w16xpexOzl8wuUIvMrJg40JmZ9QBedsTMcuFAZ2bWA3jZETPLhQOdmVkP4GVHzCwXDnRmZt2kenk15fPL6fetfpTPL6d6eXXWdb3siJnlIqtlSyQdAGyJiHclHQ0cC/wiIrbnu4H55GVLzKy7tJylCkkPm0OZmXWX7niW6+PAfpKGA0uAzwD/3j3NMzMrfp6lamaFlG2gU0Q0AZ8A/iUiPg4cn79mmZkVF89SNbNCyjrQSfoLoAr4j7TMixKbmaU8S9XMCinbQPcV4Hrg/ohYIelI4Dd5a5WZWZHxLFUzK6Ssetki4jHgMQBJ/YDXI+LL+WyYmVkxaZ744GexmlkhZDvL9W5gJrATeBYYDHw/Im7Ib/Pyy7NczczMrFh0xyzX4yPiLeBC4CGgFLi0e5pnZtYz5LKOnJlZIWU7sWEfSfuQBLp/jYjtkjru2jMzKxIt15Gra6xjxoMzADxsamY9XrY9dP8G1AIHAI9LKgPeylejzMz2Nq8jZ2bFLKtAFxE3RcTwiDg/EnXAGR3Vk3SupNWS1kia1cp2Sbop3b5M0rhs6kr6UrpthaTvZpRfn+6/WtI52ZybmRl4HTkzK25ZBTpJgyV9X1JN+voeSW9de3VKgJuB80gWIZ4mqeVixOcBo9LXDODWjupKOgOYApwYEScAN6blxwNTgROAc4Fb0uOYmXXI68iZWTHLdsj1TmAz8Kn09Rbwww7qjAfWRMS6iNgGLCIJYpmmAAvTXr+ngIMlHdZB3SuAf4iIrQAR8VrGsRZFxNaIeAlYkx7HzKxDXkfOzIpZtoHuqIiYkwasdRHxLeDIDuoMB17OeF+flmWzT3t1jwZOk/Q7SY9JOrkTn2dmvVxXZ6pWjaliwQULKBtchhBlg8tYcMECT4gws6KQ7SzXLZJOjYgnASRNArZ0UEetlLWcGdvWPu3V7Q+8D5gInAzcmz65IpvPQ9IMkuFdSks9lGLWm+Q6U7VqTJUDnJkVpWx76GYCN0uqlVQL/CvwhQ7q1ANHZLwfAbya5T7t1a0HfpYO0z4NvAsMzfLziIgFEVEZEZXDhg3r4BTMrJh4pqqZ9VXZznJ9ISJOAk4kmYwwFjizg2rPAKMkjZQ0gGTCwuIW+ywGpqezXScCjRGxoYO6DzR/tqSjgQHA6+n2qZL2lTSSZKLF09mcn5n1HLks7uuZqmbWV2U75ApA+rSIZtcC89vZd4ekq4CHgRLgzohYIWlmuv02kqdOnE8ygaEJ+Ex7ddND3wncKen3wDbg05E8v2yFpHuBlcAO4MqI2NmZ8zOzwsp1yLR0cCl1jXWtlpuZ9WZZPcu11YrSyxFxRMd79lx+lqtZz1I+v7zVQFY2uIzar9R2WL9lIIRkpqonN5hZb9Adz3JtjR/9ZWbdKtchU89UNbO+qt0hV0mbaT24Cdg/Ly0ysz6rO4ZMPVPVzPqidnvoImJQRBzUymtQRHTq/jsz6xtymdTgxX3NzLomlyFXM7PdNN/DVtdYRxC7JjV4cV8zs/zq8qSI3sCTIsy6V66TGszMrG35mhRhZrYbrwNnZlYYDnRmtptc7oFra/KC14EzM8svBzoz2yXXe+A8qcHMrDAc6Mxsl1yfhepJDWZmheGlR8x6merl1cxeMpv1jespHVzKvLPmZR2ouuMeOK8DZ2a297mHzqwXyXXI1PfAmZkVJwc6s14k1yFT3wNnZlacHOjMehE/C9XMrG/yPXRmvYifhWpm1je5h86sh/GzUM3MrLMc6Mx6ED8L1czMusLPcvWzXC0Purp0iJ+FamZmbWnvWa6+h86smzX3sjXPNm3uZQM6DHV+FqqZmXWFh1zNulkuS4d4HTgzM+sKBzqzVuQyMSGXXjZPajAzs65woDNroZBPW/CkBjMz6woHOuuVculhK/TTFqrGVFH7lVrenfMutV+pdZgzM7MO5TXQSTpX0mpJayTNamW7JN2Ubl8maVxHdSXNlfSKpKXp6/y0vFzSlozy2/J5btZz5drD5qctmJlZscnbsiWSSoA/AGcD9cAzwLSIWJmxz/nAl4DzgQnAP0fEhPbqSpoLvB0RN7b4vHLg5xExOts2etmSnqury35A7kt/eOkQMzPridpbtiSfPXTjgTURsS4itgGLgCkt9pkCLIzEU8DBkg7Lsm6Pl8uwX19W6B42T0wwM7Nik89ANxx4OeN9fVqWzT4d1b0qHaK9U9L7MspHSnpe0mOSTsv5DHKQayhpPkaxBsJC3sOW69IfHjI1M7Nik89Ap1bKWo7vtrVPe3VvBY4CKoANwPfS8g1AaUSMBa4F7pZ00B6NkmZIqpFUs2nTpg5PoqtyDSW5BsJcw2Au9XtDD5snJpiZWTHJZ6CrB47IeD8CeDXLfdqsGxEbI2JnRLwL3E4yPEtEbI2IhvTnZ4G1wNEtGxURCyKiMiIqhw0blsPptS/XUJJLIOyOMJhLffewmZmZ7V35DHTPAKMkjZQ0AJgKLG6xz2JgejrbdSLQGBEb2qub3mPX7OPA79PyYelkCiQdCYwC1uXv9NqXayjJJRDmGqhyre8eNjMzs70rb4EuInYAVwEPAy8C90bECkkzJc1Md3uIJHStIelt+2J7ddM635W0XNIy4AzgmrR8MrBM0gvAT4GZEfFGvs6vI7mGklwCYa6BKtf67mEzMzPbu/K2bEkxyPeyJbksvdHyAe+QBMJsgk2hl+3Ipe1mZmbWukItW9Ln5TLsl0svVa69g93xpAP3sJmZme097qHrpQsL59I72B31zczMrHu110PnQNdLA52ZmZn1Lh5yNTMzM+vFHOjMzMzMipwDnZmZmVmRc6AzMzMzK3IOdGZmZmZFzoHOzMzMrMg50JmZmZkVOQc6MzMzsyLnQGdmZmZW5BzozMzMzIqcA52ZmZlZkXOgMzMzMytyDnT5VF0N5eXQr1/yb3V1oVtkZmZmvVD/Qjeg16quhhkzoKkpeV9Xl7wHqKoqXLvMzMys13EPXb7Mnv1emGvW1JSUm5mZmXUjB7p8Wb++c+VmZmZmXeRAly+lpZ0rNzMzM+siB7p8mTcPBg7cvWzgwKTczMzMrBvlNdBJOlfSaklrJM1qZbsk3ZRuXyZpXEd1Jc2V9Iqkpenr/Ixt16f7r5Z0Tj7PrUNVVbBgAZSVgZT8u2CBJ0SYmZlZt8vbLFdJJcDNwNlAPfCMpMURsTJjt/OAUelrAnArMCGLuv8UETe2+LzjganACcDhwCOSjo6Infk6xw5VVTnAmZmZWd7ls4duPLAmItZFxDZgETClxT5TgIWReAo4WNJhWdZtaQqwKCK2RsRLwJr0OGZmZma9Wj4D3XDg5Yz39WlZNvt0VPeqdIj2Tknv68TnmZmZmfU6+Qx0aqUsstynvbq3AkcBFcAG4Hud+DwkzZBUI6lm06ZNrVQxMzMzKy75DHT1wBEZ70cAr2a5T5t1I2JjROyMiHeB23lvWDWbzyMiFkREZURUDhs2rNMnZWZmZtbT5DPQPQOMkjRS0gCSCQuLW+yzGJieznadCDRGxIb26qb32DX7OPD7jGNNlbSvpJEkEy2eztfJmZmZmfUUeZvlGhE7JF0FPAyUAHdGxApJM9PttwEPAeeTTGBoAj7TXt300N+VVEEynFoLfCGts0LSvcBKYAdwZUFnuJqZmZntJYrY4zazPqOysjJqamoK3QwzMzOzDkl6NiIqW9vmJ0WYmZmZFTkHOjMzM7Mi50BnZmZmVuQc6MzMzMyKnAOdmZmZWZFzoDMzMzMrcg50ZmZmZkXOgc7MzMysyDnQmZmZmRU5BzozMzOzIudAZ2ZmZlbkHOjMzMzMipwDnZmZmVmRc6AzMzMzK3IOdGZmZmZFzoHOzMzMrMg50JmZmZkVOQe6nqy6GsrLoV+/5N/q6kK3yMzMzHqg/oVugLWhuhpmzICmpuR9XV3yHqCqqnDtMjMzsx7HPXQ91ezZ74W5Zk1NSbmZmZlZBge6nmr9+s6Vm5mZWZ/lQNdTlZZ2rtzMzMz6rLwGOknnSlotaY2kWa1sl6Sb0u3LJI3rRN2vSgpJQ9P35ZK2SFqavm7L57nl3bx5MHDg7mUDByblZmZmZhnyNilCUglwM3A2UA88I2lxRKzM2O08YFT6mgDcCkzoqK6kI9JtLccf10ZERb7Oaa9qnvgwe3YyzFpamoQ5T4gwMzOzFvLZQzceWBMR6yJiG7AImNJinynAwkg8BRws6bAs6v4T8HUg8tj+wquqgtpaePfd5N/OhDkveWJmZtZn5DPQDQdeznhfn5Zls0+bdSV9DHglIl5o5TNHSnpe0mOSTsux/cWrecmTujqIeG/JE4c6MzOzXimfgU6tlLXsUWtrn1bLJQ0EZgPfbGX7BqA0IsYC1wJ3Szpoj0ZJMyTVSKrZtGlTuydQtLpjyRP38JmZmRWNfAa6euCIjPcjgFez3Ket8qOAkcALkmrT8uckvT8itkZEA0BEPAusBY5u2aiIWBARlRFROWzYsBxOrwfLdckT9/CZmZkVlXwGumeAUZJGShoATAUWt9hnMTA9ne06EWiMiA1t1Y2I5RFxSESUR0Q5SfAbFxF/lDQsnUyBpCNJJlqsy+P59Vy5LnniHj4zM7OikrdAFxE7gKuAh4EXgXsjYoWkmZJmprs9RBK61gC3A19sr24HHzkZWCbpBeCnwMyIeKObT6s45LrkSU/o4XMgNDMzy5oievdE0fZUVlZGTU1NoZuRH9XVXV/ypLw8CWEtlZUls23zXb/lc2whCaQLFnjZFjMz67MkPRsRla1t85MieqtcljwpdA9fTxjydQ+hmZkVEQc621NVVdIbVlYGUvJvZ3rHcr2Hr9BDvh4yNjOzIuNAZ60rZA9foSd15Fq/OwKlw6CZmXWCA511v1x7+Ao95FvIIeOe0DvoQGlmVnQc6Cw/cunhK/SQbyGHjHtC72ChA6WZmXWaA531TIUc8i3kkHGhJ5QUOlA2H8OB0MysUxzorPfJtYevkEPGhZ5QUuhAWehA6DBpZsUqIvrs6wMf+ECY5cWPfxxRVhYhJf/++MfZ1xs4MCKJM8lr4MDs65eV7V63+VVWtnfqS63Xl/bO5+dy/XK99s3H6Mrv3cwsC0BNtJFpCh6qCvlyoLMeKZdQkGsoKXSgLGQgLGSYzDyGA6GZtcGBzoHO+pJcQ0EhA2UhA2Ex9y5mHqNQv3szyzsHOgc6s72nWANhMfcuRhS+d7b5GA6EZnnjQOdAZ1Y8ChUIi7l3sTs+v9CBsvkYufzuHSatl3Ogc6Az6zsKFQqKPRAWOlB6QotZhxzoHOjMbG8o5kBY6EDpCS1mHWov0HkdOjOz7lLIJ6QU84LakNsaiH19/cSeUN8Kr62k1xde7qEzs16lr85wLubexYjCT2hxD2XRwEOuDnRmZnnnCS2FCYSFrt8dgdJhMCsOdA50ZmY9nye0dC0QFrp+LuffE3oHiyhQOtA50JmZWXuKORAWun4ugbAn9A4WOlB2ggOdA52ZmeVTMT+yr5CBtNiHq7sjEHZCe4HOs1zNzMxyVcgZzoWun8sM6ULOju6O+rnOkO5GeQ10ks6VtFrSGkmzWtkuSTel25dJGteJul+VFJKGZpRdn+6/WtI5+TszMzOzbpRLICx0/VwCYaGXyyl0oOxGeQt0kkqAm4HzgOOBaZKOb7HbecCo9DUDuDWbupKOAM4G1meUHQ9MBU4AzgVuSY9jZmZm+dTVQNjX11/sRvnsoRsPrImIdRGxDVgETGmxzxRgYTo0/BRwsKTDsqj7T8DXgWhxrEURsTUiXgLWpMcxMzOznqqYh6tzDYTdqH8ejz0ceDnjfT0wIYt9hrdXV9LHgFci4gVJLY/1VCvHMjMzs96qqqrzQ8zdVb+53uzZyTBraWkS5nJpTxflM9CplbLIcp9WyyUNBGYDH+7i5yFpBsnwLqUF6BI1MzOzXiTXQNlN8jnkWg8ckfF+BPBqlvu0VX4UMBJ4QVJtWv6cpPdn+XlExIKIqIyIymHDhnXhtMzMzMx6lnwGumeAUZJGShpAMmFhcYt9FgPT09muE4HGiNjQVt2IWB4Rh0REeUSUk4S4cRHxx/RYUyXtK2kkyUSLp/N4fmZmZmY9Qt6GXCNih6SrgIeBEuDOiFghaWa6/TbgIeB8kgkMTcBn2qvbweetkHQvsBLYAVwZETvzc3ZmZmZmPYeShYf7psrKyqipqSl0M8zMzMw6JOnZiKhsbZufFGFmZmZW5BzozMzMzIqcA52ZmZlZkXOgMzMzMytyfXpShKRNQN1e+KihwOt74XN6I1+7rvO16zpfu9z4+nWdr13X9YVrVxYRrS6i26cD3d4iqaatWSnWPl+7rvO16zpfu9z4+nWdr13X9fVr5yFXMzMzsyLnQGdmZmZW5Bzo9o4FhW5AEfO16zpfu67ztcuNr1/X+dp1XZ++dr6HzszMzKzIuYfOzMzMrMg50OWRpHMlrZa0RtKsQren2EiqlbRc0lJJfuhuOyTdKek1Sb/PKPszSf8p6X/Sf99XyDb2VG1cu7mSXkm/e0slnV/INvZUko6Q9BtJL0paIenqtNzfvQ60c+383cuCpP0kPS3phfT6fSst77PfPQ+55omkEuAPwNlAPfAMMC0iVha0YUVEUi1QGRG9fV2hnEmaDLwNLIyI0WnZd4E3IuIf0v9D8b6IuK6Q7eyJ2rh2c4G3I+LGQratp5N0GHBYRDwnaRDwLHAhcBn+7rWrnWv3Kfzd65AkAQdExNuS9gGeBK4GPkEf/e65hy5/xgNrImJdRGwDFgFTCtwm66Ui4nHgjRbFU4C70p/vIvljYS20ce0sCxGxISKeS3/eDLwIDMffvQ61c+0sC5F4O327T/oK+vB3z4Euf4YDL2e8r8f/sXZWAL+S9KykGYVuTBE6NCI2QPLHAzikwO0pNldJWpYOyfaZYZuuklQOjAV+h797ndLi2oG/e1mRVCJpKfAa8J8R0ae/ew50+aNWyjy+3TmTImIccB5wZTo0ZrY33AocBVQAG4DvFbQ1PZykA4H7gK9ExFuFbk8xaeXa+buXpYjYGREVwAhgvKTRBW5SQTnQ5U89cETG+xHAqwVqS1GKiFfTf18D7icZxrbsbUzv02m+X+e1ArenaETExvSPxbvA7fi716b0/qX7gOqI+Fla7O9eFlq7dv7udV5EvAk8CpxLH/7uOdDlzzPAKEkjJQ0ApgKLC9ymoiHpgPRGYSQdAHwY+H37tayFxcCn058/Dfy/AralqDT/QUh9HH/3WpXemH4H8GJEfD9jk797HWjr2vm7lx1JwyQdnP68P/AhYBV9+LvnWa55lE43nw+UAHdGxLzCtqh4SDqSpFcOoD9wt69f2yT9BDgdGApsBOYADwD3AqXAeuDiiPDN/y20ce1OJxnyCqAW+ELzfTn2HkmnAk8Ay4F30+JvkNwL5u9eO9q5dtPwd69Dkk4kmfRQQtI5dW9EfFvSEProd8+BzszMzKzIecjVzMzMrMg50JmZmZkVOQc6MzMzsyLnQGdmZmZW5BzozMzMzIqcA52ZWRsk7ZS0NOM1qxuPXS7Ja4yZWbfoX+gGmJn1YFvSRwuZmfVo7qEzM+skSbWS/lHS0+nrz9PyMklL0gerL5FUmpYfKul+SS+kr1PSQ5VIul3SCkm/Sle8NzPrNAc6M7O27d9iyPWSjG1vRcR44F9JnghD+vPCiDgRqAZuSstvAh6LiJOAccCKtHwUcHNEnAC8CXwyr2djZr2WnxRhZtYGSW9HxIGtlNcCZ0bEuvQB63+MiCGSXgcOi4jtafmGiBgqaRMwIiK2ZhyjHPjPiBiVvr8O2Cci/m4vnJqZ9TLuoTMz65po4+e29mnN1oyfd+L7ms2sixzozMy65pKMf/87/fm3wNT05yrgyfTnJcAVAJJKJB20txppZn2D/9+gmVnb9pe0NOP9LyOieemSfSX9juT/GE9Ly74M3Cnpa8Am4DNp+dXAAkmfJemJuwLYkO/Gm1nf4XvozMw6Kb2HrjIiXi90W8zMwEOuZmZmZkXPPXRmZmZmRc49dGZmZmZFzoHOzMzMrMg50JmZmZkVOQc6MzMzsyLnQGdmZmZW5BzozMzMzIrc/wc+CkwaZVm5zAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.scatter(np.arange(0,len(trainArr)), trainArr, color='r', label='Training loss')\n",
    "plt.scatter(np.arange(0,len(valArr)), valArr, color='g', label='Validation loss')\n",
    "plt.title(\"Training loss vs Validation loss epsilon 0,1\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "australian-pottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_Scores(preds, labels):\n",
    "    true_positives = 0\n",
    "    true_negatives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "    for i in range(len(labs)):\n",
    "        if labels[i]==1 and preds[i]==1:\n",
    "            true_positives += 1\n",
    "        if labels[i]==0 and preds[i]==0:\n",
    "            true_negatives += 1\n",
    "        if labels[i]==0 and preds[i]==1:\n",
    "            false_positives += 1\n",
    "        if labels[i]==1 and preds[i]==0:\n",
    "            false_negatives += 1\n",
    "    print(\"true_positives\", true_positives)\n",
    "    print(\"true_negatives\", true_negatives)\n",
    "    print(\"false_positives\", false_positives)\n",
    "    print(\"false_negatives\", false_negatives)\n",
    "    \n",
    "    return true_positives, true_negatives, false_positives, false_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "affected-bruce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set:  0.8821723237597912\n",
      "F1_score:  0.0\n",
      "true_positives 0\n",
      "true_negatives 42234\n",
      "false_positives 1\n",
      "false_negatives 5640\n",
      "Toxic accuracy:  0.0\n",
      "Non-toxic accuracy:  0.9999763229548952\n"
     ]
    }
   ],
   "source": [
    "labs = []\n",
    "preds = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():        \n",
    "    for batch_idx, data in enumerate(test_loader):\n",
    "        # get the input\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.unsqueeze(1)\n",
    "        inputs = inputs.to(device).float()\n",
    "        labels = labels.to(device).float()\n",
    "        \n",
    "        outputs = model(inputs).squeeze()\n",
    "        \n",
    "        labs.extend(labels)\n",
    "        preds.extend(torch.round(outputs))\n",
    "        \n",
    "print(\"Accuracy on test set: \", CheckAccuracy(labs, preds))\n",
    "\n",
    "f1 = f1_score(torch.Tensor(labs).numpy(), torch.Tensor(preds).numpy(), zero_division=1)\n",
    "print(\"F1_score: \", f1)\n",
    "\n",
    "true_positives, true_negatives, false_positives, false_negatives = F1_Scores(preds, labs)\n",
    "\n",
    "print(\"Toxic accuracy: \", true_positives/5640)\n",
    "print(\"Non-toxic accuracy: \", true_negatives/42235)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-marker",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-lemon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-repeat",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "entitled-investigator",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frede\\anaconda3\\lib\\site-packages\\diffprivlib\\models\\logistic_regression.py:221: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score:  0.16722284019280684\n",
      "0.6246892950391645\n",
      "true_positives 1804\n",
      "true_negatives 28103\n",
      "false_positives 14132\n",
      "false_negatives 3836\n",
      "0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frede\\anaconda3\\lib\\site-packages\\diffprivlib\\models\\logistic_regression.py:221: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score:  0.18976664981507596\n",
      "0.3639477806788512\n",
      "true_positives 3566\n",
      "true_negatives 13858\n",
      "false_positives 28377\n",
      "false_negatives 2074\n",
      "0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frede\\anaconda3\\lib\\site-packages\\diffprivlib\\models\\logistic_regression.py:221: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score:  0.13047295072972676\n",
      "0.6689712793733682\n",
      "true_positives 1189\n",
      "true_negatives 30838\n",
      "false_positives 11397\n",
      "false_negatives 4451\n",
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frede\\anaconda3\\lib\\site-packages\\diffprivlib\\models\\logistic_regression.py:221: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score:  0.19447133483919543\n",
      "0.5307154046997389\n",
      "true_positives 2712\n",
      "true_negatives 22696\n",
      "false_positives 19539\n",
      "false_negatives 2928\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frede\\anaconda3\\lib\\site-packages\\diffprivlib\\models\\logistic_regression.py:221: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score:  0.24124605678233438\n",
      "0.5980783289817232\n",
      "true_positives 3059\n",
      "true_negatives 25574\n",
      "false_positives 16661\n",
      "false_negatives 2581\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frede\\anaconda3\\lib\\site-packages\\diffprivlib\\models\\logistic_regression.py:221: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score:  0.2696797241723092\n",
      "0.6327728459530026\n",
      "true_positives 3246\n",
      "true_negatives 27048\n",
      "false_positives 15187\n",
      "false_negatives 2394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frede\\anaconda3\\lib\\site-packages\\diffprivlib\\models\\logistic_regression.py:394: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"lbfgs failed to converge. Increase the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from diffprivlib.models import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "epsilons = [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "\n",
    "\n",
    "\n",
    "for eps in epsilons:\n",
    "    print(eps)\n",
    "    clf = LogisticRegression(epsilon=eps)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "    f1 = f1_score(predictions, Y_test, zero_division=1)\n",
    "    \n",
    "    print(\"F1_score: \", f1)\n",
    "    \n",
    "    print(clf.score(X_test, Y_test))\n",
    "    \n",
    "    F1_Scores(predictions, Y_test)\n",
    "\n",
    "#predictions = np.array(predictions).reshape(len(predictions), 1)\n",
    "#Y_test = np.array(Y_test).reshape(len(Y_test), 1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-webcam",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
