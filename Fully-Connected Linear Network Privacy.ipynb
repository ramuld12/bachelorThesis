{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beneficial-knight",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn, optim\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "professional-update",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CleanText(text):\n",
    "    text = re.sub(r'''[\\[|\\]]''', \"\", text).split()\n",
    "    text = np.array(text, dtype=\"float64\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "joint-producer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal dataset\n",
    "#df = pd.read_csv('CSVFiles/smallDomainDataBertweetEmbedded.csv')\n",
    "#df = pd.read_csv('CSVFiles/small10000DomainDataBertweetEmbedded.csv')\n",
    "df = pd.read_csv('CSVFiles/small50000DomainDataBertweetEmbedded.csv')\n",
    "df['comment_text'] = df['comment_text'].apply(lambda text: CleanText(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-citation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "apart-celebrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating values for training_data\n",
    "training_data = df[df['split'] == 'train']\n",
    "\n",
    "# Getting test_data\n",
    "test_data = df[df['split'] == 'test']\n",
    "\n",
    "# Getting validation_data\n",
    "validation_data = df[df['split'] == 'val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "killing-minister",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxic samples training data:  22010.0\n",
      "None-toxic samples training data:  22010.0\n",
      "\n",
      "\n",
      "Toxic samples validation data:  1510.0\n",
      "None-toxic samples validation data:  1510.0\n",
      "\n",
      "\n",
      "Toxic samples test data:  1510.0\n",
      "None-toxic samples test data:  1510.0\n",
      "\n",
      "\n",
      "male: 4567.0\n",
      "female: 5272.0\n",
      "LGBTQ: 1652.0\n",
      "christian: 2300.0\n",
      "muslim: 2332.0\n",
      "other_religion: 20.0\n",
      "black: 2475.0\n",
      "white: 3818.0\n"
     ]
    }
   ],
   "source": [
    "print('Toxic samples training data: ', sum(training_data['toxicity']))\n",
    "print('None-toxic samples training data: ', len(training_data['toxicity'])-sum(training_data['toxicity']))\n",
    "\n",
    "print(\"\\n\")\n",
    "print('Toxic samples validation data: ', sum(validation_data['toxicity']))\n",
    "print('None-toxic samples validation data: ', len(validation_data['toxicity'])-sum(validation_data['toxicity']))\n",
    "\n",
    "print(\"\\n\")\n",
    "print('Toxic samples test data: ', sum(test_data['toxicity']))\n",
    "print('None-toxic samples test data: ', len(test_data['toxicity'])-sum(test_data['toxicity']))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "for col in training_data.columns[3:]:\n",
    "    print(col + \": \" + str(np.sum(training_data[col])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "furnished-scheme",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CheckAccuracy(predictions, labels):\n",
    "        acc = 0.0\n",
    "        for i in range(len(predictions)):\n",
    "            if (predictions[i] == labels[i]):\n",
    "                acc += 1\n",
    "        return acc/len(predictions)\n",
    "    \n",
    "def CreatePlot(trainArr, valArr, path):\n",
    "    plt.figure()\n",
    "    plt.scatter(np.arange(0,len(trainArr)), trainArr, color='r', label='Training loss')\n",
    "    plt.scatter(np.arange(0,len(valArr)), valArr, color='g', label='Validation loss')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend(loc='upper right')\n",
    "    print(path)\n",
    "    plt.savefig(path, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "accomplished-bowling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device(type='cuda')\n"
     ]
    }
   ],
   "source": [
    "### Set parameters for the model\n",
    "#torch.manual_seed(1) # set fixed random seed for reproducibility\n",
    "cuda = True # Set this if training on GPU\n",
    "cuda = cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "print(\"Using \"+repr(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "robust-vitamin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating data loaders\n",
    "X_train = np.array(training_data['comment_text'].values.tolist())\n",
    "Y_train = np.array(training_data['toxicity'].values.tolist())\n",
    "\n",
    "X_test = np.array(test_data['comment_text'].values.tolist())\n",
    "Y_test = np.array(test_data['toxicity'].values.tolist())\n",
    "\n",
    "X_val = np.array(validation_data['comment_text'].values.tolist())\n",
    "Y_val = np.array(validation_data['toxicity'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dominant-reader",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Sequential(nn.Linear(768, 64), nn.ReLU())\n",
    "        self.fc2 = nn.Sequential(nn.Linear(64, 32), nn.ReLU())\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "modular-brown",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Train(model, train_loader, valid_loader, loss_function, optimizer, learning_rate, early_stopping=50, epochs=1000):\n",
    "    \n",
    "    # Setting up model parameters\n",
    "    model = model.to(device)\n",
    "    if optimizer == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    if optimizer == 'AdamW':\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    if optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    loss_function = loss_function\n",
    "\n",
    "    # Initialising early stopping criterias\n",
    "    early_stopping = early_stopping\n",
    "    notImproved = 0\n",
    "    \n",
    "    bestLoss = None\n",
    "    bestModel = None\n",
    "\n",
    "    trainArr = []\n",
    "    valArr = []\n",
    "\n",
    "    bestf1 = 0\n",
    "    bestEpoch = 0\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_loss = 0.0\n",
    "        for batch_idx, data in enumerate(train_loader):\n",
    "        \n",
    "            # get the input\n",
    "            inputs, labels = data\n",
    "    \n",
    "            inputs = inputs.to(device).float()\n",
    "            labels = labels.to(device).float()\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.squeeze(1)\n",
    "        \n",
    "            loss = loss_function(outputs, labels)\n",
    "        \n",
    "            loss.backward()\n",
    "        \n",
    "            optimizer.step()\n",
    "        \n",
    "            train_loss += loss.item()\n",
    "    \n",
    "        train_loss /= len(train_loader.dataset)    \n",
    "        trainArr.append(train_loss)\n",
    "    \n",
    "        valid_loss = 0\n",
    "        labs = []\n",
    "        preds = []\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():        \n",
    "            for batch_idx, data in enumerate(valid_loader):\n",
    "                # get the input\n",
    "                inputs, labels = data           \n",
    "            \n",
    "                inputs = inputs.to(device).float()\n",
    "                labels = labels.to(device).float()\n",
    "                \n",
    "                outputs = model(inputs).squeeze()\n",
    "                \n",
    "                labs.extend(labels)\n",
    "                preds.extend(torch.round(outputs))\n",
    "            \n",
    "                valid_loss += loss_function(outputs, labels).item()\n",
    "        \n",
    "        valid_loss /= len(valid_loader.dataset)\n",
    "        valArr.append(valid_loss)\n",
    "        \n",
    "        if bestLoss == None:\n",
    "            bestLoss = valid_loss\n",
    "    \n",
    "        if valid_loss <= bestLoss:\n",
    "            bestModel = torch.save(model, 'currentModel.pth')\n",
    "            bestLoss = valid_loss\n",
    "            notImproved = 0\n",
    "            bestEpoch = epoch\n",
    "        else:\n",
    "            notImproved +=1\n",
    "        \n",
    "        if notImproved >= early_stopping:\n",
    "            break\n",
    "\n",
    "    model = torch.load('currentModel.pth')\n",
    "    return model, valArr, trainArr, epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-awareness",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fourth-mainstream",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DemoAndF1AndAcc(class_model, pca_model, df):\n",
    "    f1_scores = []\n",
    "    accuracies = []\n",
    "    demographics = []\n",
    "    \n",
    "    for col in df.columns[3:]:\n",
    "        tempdf = df[(df[col] == 1)]\n",
    "        \n",
    "        tempX = np.array(tempdf['comment_text'].values.tolist())\n",
    "        tempY = np.array(tempdf['toxicity'].values.tolist())\n",
    "        \n",
    "        transformedXTest = pca_model.transform(tempX)\n",
    "        prep_testloader = []\n",
    "        for i in range(len(tempX)):\n",
    "            prep_testloader.append([transformedXTest[i], Y_train[i]])\n",
    "        \n",
    "        test_loader = torch.utils.data.DataLoader(prep_testloader, batch_size=32, shuffle=False)\n",
    "        \n",
    "        labs = []\n",
    "        preds = []\n",
    "        class_model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, data in enumerate(test_loader):\n",
    "                inputs, labels = data\n",
    "                inputs = inputs.to(device).float()\n",
    "                labels = labels.to(device).float()\n",
    "                outputs = class_model(inputs).squeeze()\n",
    "                labs.extend(labels)\n",
    "                preds.extend(torch.round(outputs))\n",
    "                \n",
    "        labs = torch.Tensor(labs).detach().numpy()\n",
    "        preds = torch.Tensor(preds).detach().numpy()\n",
    "        \n",
    "        f1_scores.append(f1_score(labs, preds, zero_division=1))\n",
    "        accuracies.append(CheckAccuracy(labs, preds))\n",
    "        demographics.append(col)\n",
    "            \n",
    "    return np.array(demographics), np.array(f1_scores), np.array(accuracies)\n",
    "\n",
    "def pRule(class_model, pca_model, df):\n",
    "    pRules = []\n",
    "    \n",
    "    for col in df.columns[3:]:\n",
    "        \n",
    "        tempdfz1 = df[(df[col] == 1)]\n",
    "        tempdfz0 = df[(df[col] == 0)]\n",
    "        \n",
    "        tempXz1 = np.array(tempdfz1['comment_text'].values.tolist())\n",
    "        tempYz1 = np.array(tempdfz1['toxicity'].values.tolist())\n",
    "        \n",
    "        tempXz0 = np.array(tempdfz0['comment_text'].values.tolist())\n",
    "        tempYz0 = np.array(tempdfz0['toxicity'].values.tolist())\n",
    "        \n",
    "        # For z=1\n",
    "        transformedtempXz1 = pca_model.transform(tempXz1)\n",
    "        prep_testloaderz1 = []\n",
    "        for i in range(len(transformedtempXz1)):\n",
    "            prep_testloaderz1.append([transformedtempXz1[i], tempYz1[i]])\n",
    "            transformedtempXz1 = pca_model.transform(tempXz1)\n",
    "        test_loaderz1 = torch.utils.data.DataLoader(prep_testloaderz1, batch_size=32, shuffle=False)\n",
    "        \n",
    "        labsz1 = []\n",
    "        predsz1 = []\n",
    "        class_model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, data in enumerate(test_loaderz1):\n",
    "                inputs, labels = data\n",
    "                inputs = inputs.to(device).float()\n",
    "                labels = labels.to(device).float()\n",
    "                outputs = class_model(inputs).squeeze()\n",
    "                labsz1.extend(labels)\n",
    "                predsz1.extend(torch.round(outputs))\n",
    "        \n",
    "        # For z=0\n",
    "        transformedtempXz0 = pca_model.transform(tempXz0)\n",
    "        prep_testloaderz0 = []\n",
    "        for i in range(len(transformedtempXz0)):\n",
    "            prep_testloaderz0.append([transformedtempXz0[i], tempYz0[i]])\n",
    "        test_loaderz0 = torch.utils.data.DataLoader(prep_testloaderz0, batch_size=32, shuffle=False)\n",
    "        \n",
    "        labsz0 = []\n",
    "        predsz0 = []\n",
    "        class_model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, data in enumerate(test_loaderz0):\n",
    "                inputs, labels = data\n",
    "                inputs = inputs.to(device).float()\n",
    "                labels = labels.to(device).float()\n",
    "                outputs = class_model(inputs).squeeze()\n",
    "                labsz0.extend(labels)\n",
    "                predsz0.extend(torch.round(outputs))\n",
    "        \n",
    "        predictionsz1 = torch.Tensor(predsz1).detach().numpy()\n",
    "        predictionsz0 = torch.Tensor(predsz0).detach().numpy()\n",
    "        \n",
    "        with np.errstate(divide='ignore'):\n",
    "            \n",
    "            z1Ut1 = np.sum(predictionsz1)/len(df)\n",
    "            pz1 = len(predictionsz1)/len(df)\n",
    "            \n",
    "            z0Ut1 = np.sum(predictionsz0)/len(df)\n",
    "            pz0 = len(predictionsz0)/len(df)\n",
    "\n",
    "            pscore0 = (z1Ut1/pz1) / (z0Ut1/pz0)\n",
    "            pscore1 = (z0Ut1/pz0) / (z1Ut1/pz1)\n",
    "        \n",
    "        if np.isnan(pscore0) or np.isnan(pscore1):\n",
    "            finalpscore = 0\n",
    "        else:\n",
    "            finalpscore = min(pscore0, pscore1)\n",
    "        \n",
    "        pRules.append(finalpscore)\n",
    "    return pRules\n",
    "\n",
    "def pRuleOwn(class_model, pca_model, df):\n",
    "    pRules = []\n",
    "    \n",
    "    for col in df.columns[3:]:\n",
    "        tempdfz1 = df[(df[col] == 1)]      \n",
    "        tempdfz0 = df[(df[col] == 0)]\n",
    "        \n",
    "        tempXz1 = np.array(tempdfz1['comment_text'].values.tolist())\n",
    "        tempYz1 = np.array(tempdfz1['toxicity'].values.tolist())\n",
    "        \n",
    "        tempXz0 = np.array(tempdfz0['comment_text'].values.tolist())\n",
    "        tempYz0 = np.array(tempdfz0['toxicity'].values.tolist())\n",
    "        \n",
    "        # For z=1\n",
    "        transformedtempXz1 = pca_model.transform(tempXz1)\n",
    "        prep_testloaderz1 = []\n",
    "        for i in range(len(transformedtempXz1)):\n",
    "            prep_testloaderz1.append([transformedtempXz1[i], tempYz1[i]])\n",
    "            transformedtempXz1 = pca_model.transform(tempXz1)\n",
    "        test_loaderz1 = torch.utils.data.DataLoader(prep_testloaderz1, batch_size=32, shuffle=False)\n",
    "        \n",
    "        labsz1 = []\n",
    "        predsz1 = []\n",
    "        class_model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, data in enumerate(test_loaderz1):\n",
    "                inputs, labels = data\n",
    "                inputs = inputs.to(device).float()\n",
    "                labels = labels.to(device).float()\n",
    "                outputs = class_model(inputs).squeeze()\n",
    "                labsz1.extend(labels)\n",
    "                predsz1.extend(torch.round(outputs))\n",
    "        \n",
    "        # For z=0\n",
    "        transformedtempXz0 = pca_model.transform(tempXz0)\n",
    "        prep_testloaderz0 = []\n",
    "        for i in range(len(transformedtempXz0)):\n",
    "            prep_testloaderz0.append([transformedtempXz0[i], tempYz0[i]])\n",
    "        test_loaderz0 = torch.utils.data.DataLoader(prep_testloaderz0, batch_size=32, shuffle=False)\n",
    "        \n",
    "        labsz0 = []\n",
    "        predsz0 = []\n",
    "        class_model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, data in enumerate(test_loaderz0):\n",
    "                inputs, labels = data\n",
    "                inputs = inputs.to(device).float()\n",
    "                labels = labels.to(device).float()\n",
    "                outputs = class_model(inputs).squeeze()\n",
    "                labsz0.extend(labels)\n",
    "                predsz0.extend(torch.round(outputs))\n",
    "        \n",
    "        predictionsz1 = torch.Tensor(predsz1).numpy()\n",
    "        predictionsz0 = torch.Tensor(predsz0).numpy()\n",
    "        \n",
    "        with np.errstate(divide='ignore'):\n",
    "            \n",
    "            pscore0 = (np.sum(predictionsz1)/np.sum(tempYz1))/(np.sum(predictionsz0)/np.sum(tempYz0))\n",
    "            pscore1 = (np.sum(predictionsz0)/np.sum(tempYz0))/(np.sum(predictionsz1)/np.sum(tempYz1))\n",
    "        \n",
    "        if np.isnan(pscore0) or np.isnan(pscore1):\n",
    "            finalpscore = 0\n",
    "        else:\n",
    "            finalpscore = min(pscore0, pscore1)\n",
    "        \n",
    "        pRules.append(finalpscore)\n",
    "    return pRules\n",
    "\n",
    "def MinMaxFairness(scores):\n",
    "    return np.max(scores)-np.min(scores)\n",
    "\n",
    "def VarianceFairness(scores):\n",
    "    return np.var(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-supervisor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "refined-order",
   "metadata": {},
   "source": [
    "# epsilons = []\n",
    "pathArr = []\n",
    "\n",
    "for filePath in glob.glob('PCAmodels1000/*'):\n",
    "    pathArr.append(filePath)\n",
    "    epsilons.append(filePath[14:-4].replace(',', '.'))\n",
    "\n",
    "epsilons = np.array(epsilons, dtype=float)\n",
    "pathArr = np.array(pathArr)\n",
    "\n",
    "# sort by epsilons\n",
    "sortedIndexes = np.argsort(epsilons)\n",
    "epsilons = epsilons[sortedIndexes][8:]\n",
    "pathArr = pathArr[sortedIndexes][8:]\n",
    "\n",
    "print(epsilons)\n",
    "print(pathArr)\n",
    "\n",
    "varF1 = []\n",
    "varAcc = []\n",
    "minMaxF1 = []\n",
    "minMaxAcc = []\n",
    "pRuleOwnMeanArr = []\n",
    "pRuleOwnMinArr = []\n",
    "pRuleMeanArr = []\n",
    "pRuleMinArr = []\n",
    "accuracy = []\n",
    "\n",
    "for j, path in enumerate(pathArr):\n",
    "    print(j)\n",
    "    PCAmodel = torch.load(path)\n",
    "    transformedXTrain = PCAmodel.transform(X_train)\n",
    "    transformedXVal = PCAmodel.transform(X_val)\n",
    "    \n",
    "    prepare_trainloader = []\n",
    "    for i in range(len(X_train)):\n",
    "        prepare_trainloader.append([transformedXTrain[i], Y_train[i]])\n",
    "    \n",
    "    prepare_validloader = []\n",
    "    for i in range(len(X_val)):\n",
    "        prepare_validloader.append([transformedXVal[i], Y_val[i]])\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(prepare_trainloader, batch_size=32, shuffle=True)\n",
    "    valid_loader = torch.utils.data.DataLoader(prepare_validloader, batch_size=32, shuffle=False)\n",
    "        \n",
    "    model, valLossArr , trainLossArr, epoch = Train(Net(), train_loader, valid_loader, nn.MSELoss(), 'AdamW', 0.000001, early_stopping=50, epochs=20000)\n",
    "    \n",
    "    torch.save(model, 'PrivateModels50000/private' + path[14:])\n",
    "    CreatePlot(trainLossArr, valLossArr, 'PrivateModels50000/private'+ path[14:-4] + '.png')\n",
    "    \n",
    "    demographics, f1_scores, accuracies = DemoAndF1AndAcc(model, PCAmodel, test_data)\n",
    "    \n",
    "    own = pRuleOwn(model, PCAmodel, test_data) \n",
    "    pRuleOwnMinArr.append(np.min(own))\n",
    "    pRuleOwnMeanArr.append(np.mean(own))\n",
    "    \n",
    "    official = pRule(model, PCAmodel, test_data)\n",
    "    pRuleMinArr.append(np.min(official))\n",
    "    pRuleMeanArr.append(np.mean(official))\n",
    "    \n",
    "    #F1 Min Max\n",
    "    minMaxF1.append(MinMaxFairness(f1_scores))\n",
    "    \n",
    "    #F1 Variance\n",
    "    varF1.append(VarianceFairness(f1_scores))\n",
    "    \n",
    "    transformedXtest = PCAmodel.transform(X_test)\n",
    "    prepare_testloader = []\n",
    "    for i in range(len(X_test)):\n",
    "        prepare_testloader.append([transformedXtest[i], Y_test[i]])\n",
    "    test_loader = torch.utils.data.DataLoader(prepare_testloader, batch_size=32, shuffle=False)\n",
    "    \n",
    "    labs = []\n",
    "    preds = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(test_loader):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device).float()\n",
    "            labels = labels.to(device).float()\n",
    "            outputs = model(inputs).squeeze()\n",
    "            labs.extend(labels)\n",
    "            preds.extend(torch.round(outputs))\n",
    "    testAcc = CheckAccuracy(labs, preds)\n",
    "    print(\"Accuracy on test set: \", testAcc)\n",
    "    accuracy.append(testAcc)\n",
    "    \n",
    "varF1 = np.array(varF1)\n",
    "minMaxF1 = np.array(minMaxF1)\n",
    "pRuleOwnMeanArr = np.array(pRuleOwnMeanArr)\n",
    "pRuleOwnMinArr = np.array(pRuleOwnMinArr)\n",
    "pRuleMeanArr = np.array(pRuleMeanArr)\n",
    "pRuleMinArr = np.array(pRuleMinArr)\n",
    "accuracy = np.array(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "altered-parade",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = []\n",
    "pathArrPCA = []\n",
    "\n",
    "for filePath in glob.glob('PCAmodels1000/*'):\n",
    "    pathArrPCA.append(filePath)\n",
    "    epsilons.append(filePath[14:-4].replace(',', '.'))\n",
    "\n",
    "epsilons = np.array(epsilons, dtype=float)\n",
    "pathArrPCA = np.array(pathArrPCA)\n",
    "\n",
    "# sort by epsilons\n",
    "sortedIndexes = np.argsort(epsilons)\n",
    "epsilons = epsilons[sortedIndexes]\n",
    "pathArrPCA = pathArrPCA[sortedIndexes]\n",
    "\n",
    "\n",
    "pathArrFC = []\n",
    "epsilons = []\n",
    "for filePath in glob.glob('PrivateModels50000/Models/*'):\n",
    "    epsilons.append(filePath[33:-4].replace(',', '.'))\n",
    "    pathArrFC.append(filePath)\n",
    "    \n",
    "epsilons = np.array(epsilons, dtype=float)\n",
    "pathArrFC = np.array(pathArrFC)\n",
    "\n",
    "# sort by epsilons\n",
    "sortedIndexes = np.argsort(epsilons)\n",
    "epsilons = epsilons[sortedIndexes]\n",
    "pathArrFC = pathArrFC[sortedIndexes]\n",
    "\n",
    "varF1 = []\n",
    "varAcc = []\n",
    "minMaxF1 = []\n",
    "minMaxAcc = []\n",
    "pRuleOwnMeanArr = []\n",
    "pRuleOwnMinArr = []\n",
    "pRuleMeanArr = []\n",
    "pRuleMinArr = []\n",
    "accuracy = []\n",
    "\n",
    "for i in range(len(pathArrFC)):\n",
    "    print(epsilons[i])\n",
    "    \n",
    "    PCAmodel = torch.load(pathArrPCA[i])\n",
    "    model = torch.load(pathArrFC[i])\n",
    "    \n",
    "    demographics, f1_scores, accuracies = DemoAndF1AndAcc(model, PCAmodel, test_data)\n",
    "    \n",
    "    own = pRuleOwn(model, PCAmodel, test_data) \n",
    "    pRuleOwnMinArr.append(np.min(own))\n",
    "    pRuleOwnMeanArr.append(np.mean(own))\n",
    "    \n",
    "    official = pRule(model, PCAmodel, test_data)\n",
    "    pRuleMinArr.append(np.min(official))\n",
    "    pRuleMeanArr.append(np.mean(official))\n",
    "    \n",
    "    #F1 Min Max\n",
    "    minMaxF1.append(MinMaxFairness(f1_scores))\n",
    "    \n",
    "    #F1 Variance\n",
    "    varF1.append(VarianceFairness(f1_scores))\n",
    "    \n",
    "    transformedXtest = PCAmodel.transform(X_test)\n",
    "    prepare_testloader = []\n",
    "    for i in range(len(X_test)):\n",
    "        prepare_testloader.append([transformedXtest[i], Y_test[i]])\n",
    "    test_loader = torch.utils.data.DataLoader(prepare_testloader, batch_size=32, shuffle=False)\n",
    "    \n",
    "    labs = []\n",
    "    preds = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(test_loader):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device).float()\n",
    "            labels = labels.to(device).float()\n",
    "            outputs = model(inputs).squeeze()\n",
    "            labs.extend(labels)\n",
    "            preds.extend(torch.round(outputs))\n",
    "    testAcc = CheckAccuracy(labs, preds)\n",
    "    print(\"Accuracy on test set: \", testAcc)\n",
    "    accuracy.append(testAcc)\n",
    "    \n",
    "varF1 = np.array(varF1)\n",
    "minMaxF1 = np.array(minMaxF1)\n",
    "pRuleOwnMeanArr = np.array(pRuleOwnMeanArr)\n",
    "pRuleOwnMinArr = np.array(pRuleOwnMinArr)\n",
    "pRuleMeanArr = np.array(pRuleMeanArr)\n",
    "pRuleMinArr = np.array(pRuleMinArr)\n",
    "accuracy = np.array(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "assumed-serve",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected non-empty vector for x",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-a0c478d49fe8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# PLOT OWN P-RULE MEAN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolyfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepsilons\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpRuleOwnMeanArr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mX2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_constant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepsilons\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mpolyfit\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\polynomial.py\u001b[0m in \u001b[0;36mpolyfit\u001b[1;34m(x, y, deg, rcond, full, w, cov)\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"expected 1D vector for x\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"expected non-empty vector for x\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"expected 1D or 2D array for y\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected non-empty vector for x"
     ]
    }
   ],
   "source": [
    "# PLOT OWN P-RULE MEAN\n",
    "\n",
    "m, b = np.polyfit(epsilons, pRuleOwnMeanArr, 1)\n",
    "\n",
    "X2 = sm.add_constant(epsilons)\n",
    "est = sm.OLS(pRuleOwnMeanArr, X2)\n",
    "est2 = est.fit()\n",
    "print(est2.summary())\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(epsilons, pRuleOwnMeanArr, color='r')\n",
    "plt.plot(epsilons, m*epsilons + b, color='b', label='f(x)='+\"{:.5f}\".format(m)+' * ln(x) + '+ \"{:.5f}\".format(b))\n",
    "plt.xlabel(\"Epsilon\", fontsize=18)\n",
    "plt.ylabel(\"Mean p-ruleM score\", fontsize=18)\n",
    "#plt.text(18, min(pRuleOwnMeanArr),'statistically significant with P ≤ 0.001', fontsize=15,  color='black',style='italic', bbox={'facecolor': 'grey', 'alpha': 0.01, 'pad': 5})\n",
    "plt.legend(loc=\"upper right\", fontsize=15)\n",
    "plt.savefig('PCAOwnMean.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "endangered-adventure",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected non-empty vector for x",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-f30352a39989>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# PLOT OWN P-RULE MIN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolyfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepsilons\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpRuleOwnMinArr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mX2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_constant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepsilons\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mpolyfit\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\polynomial.py\u001b[0m in \u001b[0;36mpolyfit\u001b[1;34m(x, y, deg, rcond, full, w, cov)\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"expected 1D vector for x\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"expected non-empty vector for x\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"expected 1D or 2D array for y\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected non-empty vector for x"
     ]
    }
   ],
   "source": [
    "# PLOT OWN P-RULE MIN\n",
    "\n",
    "m, b = np.polyfit(epsilons, pRuleOwnMinArr, 1)\n",
    "\n",
    "X2 = sm.add_constant(epsilons)\n",
    "est = sm.OLS(pRuleOwnMinArr, X2)\n",
    "est2 = est.fit()\n",
    "print(est2.summary())\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(epsilons, pRuleOwnMinArr, color='r')\n",
    "plt.plot(epsilons, m*epsilons + b, color='b', label='f(x)='+\"{:.5f}\".format(m)+' * ln(x) + '+ \"{:.5f}\".format(b))\n",
    "plt.xlabel(\"Epsilon\", fontsize=18)\n",
    "plt.ylabel(\"Worst p-ruleM score\", fontsize=18)\n",
    "#plt.text(18, min(pRuleOwnMinArr),'statistically significant with P ≤ 0.001', fontsize=15,  color='black',style='italic', bbox={'facecolor': 'grey', 'alpha': 0.01, 'pad': 5})\n",
    "plt.legend(loc=\"upper right\", fontsize=15)\n",
    "plt.savefig('PCAOwnMin.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "mature-ambassador",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected non-empty vector for x",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-84839e74d197>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# PLOT OFFICIAL P-RULE MIN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolyfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepsilons\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpRuleMinArr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_constant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepsilons\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOLS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpRuleMinArr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mpolyfit\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\polynomial.py\u001b[0m in \u001b[0;36mpolyfit\u001b[1;34m(x, y, deg, rcond, full, w, cov)\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"expected 1D vector for x\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"expected non-empty vector for x\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"expected 1D or 2D array for y\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected non-empty vector for x"
     ]
    }
   ],
   "source": [
    "# PLOT OFFICIAL P-RULE MIN\n",
    "m, b = np.polyfit(epsilons, pRuleMinArr, 1)\n",
    "\n",
    "X2 = sm.add_constant(epsilons)\n",
    "est = sm.OLS(pRuleMinArr, X2)\n",
    "est2 = est.fit()\n",
    "print(est2.summary())\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(epsilons, pRuleMinArr, color='r')\n",
    "plt.plot(epsilons, m*epsilons + b, color='b', label='f(x)='+\"{:.5f}\".format(m)+' * ln(x) + '+ \"{:.5f}\".format(b))\n",
    "plt.xlabel(\"Epsilon\", fontsize=18)\n",
    "plt.ylabel(\"Worst p-rule score\", fontsize=18)\n",
    "\n",
    "#plt.text(18, min(pRuleMinArr),'statistically significant with P ≤ 0.001', fontsize=15,  color='black',style='italic', bbox={'facecolor': 'grey', 'alpha': 0.01, 'pad': 5})\n",
    "\n",
    "plt.legend(loc=\"upper right\", fontsize=15)\n",
    "plt.savefig('PCAOfficialMin.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "forbidden-passing",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected non-empty vector for x",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-6d8c2f01aaa8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# PLOT OFFICIAL P-RULE Mean\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolyfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepsilons\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpRuleMeanArr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_constant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepsilons\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOLS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpRuleMeanArr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mpolyfit\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\polynomial.py\u001b[0m in \u001b[0;36mpolyfit\u001b[1;34m(x, y, deg, rcond, full, w, cov)\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"expected 1D vector for x\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"expected non-empty vector for x\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"expected 1D or 2D array for y\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected non-empty vector for x"
     ]
    }
   ],
   "source": [
    "# PLOT OFFICIAL P-RULE Mean\n",
    "m, b = np.polyfit(epsilons, pRuleMeanArr, 1)\n",
    "\n",
    "X2 = sm.add_constant(epsilons)\n",
    "est = sm.OLS(pRuleMeanArr, X2)\n",
    "est2 = est.fit()\n",
    "print(est2.summary())\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(epsilons, pRuleMeanArr, color='r')\n",
    "plt.plot(epsilons, m*epsilons + b, color='b', label='f(x)='+\"{:.5f}\".format(m)+' * ln(x) + '+ \"{:.5f}\".format(b))\n",
    "#plt.text(18, min(pRuleMeanArr),'statistically significant with P ≤ 0.001', fontsize=15,  color='black',style='italic', bbox={'facecolor': 'grey', 'alpha': 0.01, 'pad': 5})\n",
    "plt.xlabel(\"Epsilon\", fontsize=18)\n",
    "plt.ylabel(\"Mean p-rule score\", fontsize=18)\n",
    "plt.legend(loc=\"upper right\", fontsize=15)\n",
    "plt.savefig('PCAfficialMean.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "practical-justice",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected non-empty vector for x",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-55caf81e5cbe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolyfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepsilons\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvarF1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_constant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepsilons\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOLS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvarF1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mest2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mpolyfit\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\polynomial.py\u001b[0m in \u001b[0;36mpolyfit\u001b[1;34m(x, y, deg, rcond, full, w, cov)\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"expected 1D vector for x\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"expected non-empty vector for x\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"expected 1D or 2D array for y\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected non-empty vector for x"
     ]
    }
   ],
   "source": [
    "m, b = np.polyfit(epsilons, varF1, 1)\n",
    "\n",
    "X2 = sm.add_constant(epsilons)\n",
    "est = sm.OLS(varF1, X2)\n",
    "est2 = est.fit()\n",
    "print(est2.summary())\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(epsilons, varF1, color='r')\n",
    "plt.plot(epsilons, m*epsilons + b, color='b', label='f(x)='+\"{:.5f}\".format(m)+' * ln(x) + '+ \"{:.5f}\".format(b))\n",
    "plt.xlabel(\"Epsilon\", fontsize=18)\n",
    "#plt.text(18, 0.00125,'statistically significant with P ≤ 0.001', fontsize=15,  color='black',style='italic', bbox={'facecolor': 'grey', 'alpha': 0.01, 'pad': 5})\n",
    "plt.ylabel(\"Variance fairness\", fontsize=18)\n",
    "plt.legend(loc=\"upper right\", fontsize=15)\n",
    "plt.savefig('PCAvarf1.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "distant-feeling",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected non-empty vector for x",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-d1f1e1424c98>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolyfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepsilons\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminMaxF1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_constant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepsilons\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOLS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminMaxF1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mest2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mpolyfit\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\polynomial.py\u001b[0m in \u001b[0;36mpolyfit\u001b[1;34m(x, y, deg, rcond, full, w, cov)\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"expected 1D vector for x\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"expected non-empty vector for x\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"expected 1D or 2D array for y\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected non-empty vector for x"
     ]
    }
   ],
   "source": [
    "m, b = np.polyfit(epsilons, minMaxF1, 1)\n",
    "\n",
    "X2 = sm.add_constant(epsilons)\n",
    "est = sm.OLS(minMaxF1, X2)\n",
    "est2 = est.fit()\n",
    "print(est2.summary())\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(epsilons, minMaxF1, color='r')\n",
    "plt.plot(epsilons, m*epsilons + b, color='b', label='f(x)='+\"{:.5f}\".format(m)+' * ln(x) + '+ \"{:.5f}\".format(b))\n",
    "plt.xlabel(\"Epsilon\", fontsize=18)\n",
    "plt.ylabel(\"maxmin fairness\", fontsize=18)\n",
    "#plt.text(18, min(minMaxF1),'statistically significant with P ≤ 0.001', fontsize=15,  color='black',style='italic', bbox={'facecolor': 'grey', 'alpha': 0.01, 'pad': 5})\n",
    "plt.legend(loc=\"upper right\", fontsize=15)\n",
    "plt.savefig('15minmaxf1400models0to40eps.png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-taylor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-macedonia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "hydraulic-savings",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('DPPCA.npy', 'wb') as f:\n",
    "    np.save(f, epsilons)\n",
    "    np.save(f, varF1)\n",
    "    np.save(f, minMaxF1)\n",
    "    np.save(f, pRuleOwnMeanArr)\n",
    "    np.save(f, pRuleOwnMinArr)\n",
    "    np.save(f, pRuleMeanArr)\n",
    "    np.save(f, pRuleMinArr)\n",
    "    np.save(f, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "previous-carrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('DPPCA.npy', 'rb') as f:\n",
    "    epsilons = np.load(f)\n",
    "    varF1 = np.load(f)\n",
    "    minMaxF1 = np.load(f)\n",
    "    pRuleOwnMeanArr = np.load(f)\n",
    "    pRuleOwnMinArr = np.load(f)\n",
    "    pRuleMeanArr = np.load(f)\n",
    "    pRuleMinArr = np.load(f)\n",
    "    accuracy = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-melissa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upset-annual",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
