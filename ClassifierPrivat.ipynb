{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from wilds.common.data_loaders import get_train_loader\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "def CleanText(text):\n",
    "    text = text.lower() #Turn all text entries into lower-case\n",
    "    text = re.sub(r'''(https?:\\/\\/www\\.|https?:\\/\\/)?[a-z0-9]+([\\-\\.]{1}[a-z0-9]+)*\\.[a-z]{2,3}[-a-zA-Z0-9()@:%_\\+.~#?&\\//=<>]*''', \"<URL>\", text)\n",
    "    #Replace URL with tag\n",
    "    text = re.sub(r'''[0-9]+[/\\-.]+[0-9]+[/\\-.]+[0-9]+''', \"<DATE>\", text) #Replace dates with tag\n",
    "    text = re.sub(r'''[a-z0-9._%+-]+\\@[a-z0-9.-]+[a-z0-9]\\.[a-z]{1,}''', \"<EMAIL>\", text)\n",
    "    text = re.sub(r'''[0-9]+''', \"<NUM>\", text) #Replace numbers with tag\n",
    "    \n",
    "    text = re.sub(r'''[.|,|!|?|\\'|\\''|\\\"|\\n|\\t|\\-|\\(|\\)]''', '', text)\n",
    "    text = re.sub(r'''^\\s+|\\s+$''', '', text) #Remove whitespaces at the end of string\n",
    "    text = re.sub(r'''[ ][ ]+|_''', \" \", text) #Remove multiple whitespace\n",
    "    return text\n",
    "\n",
    "df = pd.read_csv(\"all_data_with_identities.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             comment_text  split  na_gender  \\\n",
      "0       OH yes - Were those evil Christian Missionarie...   test          1   \n",
      "1       Why is this black racist crap still on the G&M...    val          1   \n",
      "2                              even up here.......BLACKS!  train          1   \n",
      "3       Blame men.  There's always an excuse to blame ...  train          0   \n",
      "4       And the woman exposing herself saying grab thi...    val          0   \n",
      "...                                                   ...    ...        ...   \n",
      "447995  Another man shamming article. If white men did...  train          0   \n",
      "447996  \"no matter what is put in front of you regardi...  train          0   \n",
      "447997  The Democrat party aided and abetted by it's M...   test          1   \n",
      "447998  I just don't find her a very good representati...  train          0   \n",
      "447999  You know the Trump fanatics are trolling the G...  train          1   \n",
      "\n",
      "        toxicity      male    female  transgender  other_gender  \n",
      "0       0.800000  0.000000  0.000000     0.000000      0.000000  \n",
      "1       0.757143  0.000000  0.000000     0.000000      0.000000  \n",
      "2       0.688525  0.000000  0.000000     0.000000      0.000000  \n",
      "3       0.545455  1.000000  1.000000     0.000000      0.000000  \n",
      "4       0.728571  0.000000  1.000000     0.000000      0.000000  \n",
      "...          ...       ...       ...          ...           ...  \n",
      "447995  0.400000  0.700000  0.000000     0.000000      0.000000  \n",
      "447996  0.400000  0.600000  0.000000     0.800000      0.000000  \n",
      "447997  0.400000  0.000000  0.363636     0.000000      0.000000  \n",
      "447998  0.400000  0.000000  0.141264     0.765799      0.052045  \n",
      "447999  0.400000  0.002561  0.000000     0.000000      0.000640  \n",
      "\n",
      "[448000 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "df = df.loc[:, [\"comment_text\", \"split\", \"na_gender\", \"toxicity\", \"male\", \"female\", \"transgender\", \"other_gender\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = df[df['split'] == 'train']\n",
    "training_data = training_data[training_data['na_gender'] == 0][:70000]\n",
    "\n",
    "test_data = df[df['split'] == 'test'][:15000]\n",
    "validation_data = df[df['split'] == 'val'][:15000]\n",
    "\n",
    "training_data['comment_text'] = training_data['comment_text'].apply(lambda text: CleanText(text))\n",
    "training_data['male'] = training_data['male'].apply(lambda x: round(x))\n",
    "training_data['female'] = training_data['female'].apply(lambda x: round(x))\n",
    "training_data['transgender'] = training_data['transgender'].apply(lambda x: round(x))\n",
    "training_data['other_gender'] = training_data['transgender'].apply(lambda x: round(x))\n",
    "\n",
    "test_data['comment_text'] = test_data['comment_text'].apply(lambda text: CleanText(text))\n",
    "validation_data['comment_text'] = validation_data['comment_text'].apply(lambda text: CleanText(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingComments = training_data['comment_text']\n",
    "trainingLabels = training_data['toxicity']\n",
    "trainingComments = trainingComments.values.tolist()\n",
    "\n",
    "testComments = test_data['comment_text']\n",
    "testComments = testComments.values.tolist()\n",
    "testLabels = test_data['toxicity']\n",
    "\n",
    "valComments = validation_data['comment_text']\n",
    "valComments = valComments.values.tolist()\n",
    "valLabels = validation_data['toxicity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>split</th>\n",
       "      <th>na_gender</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "      <th>transgender</th>\n",
       "      <th>other_gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blame men theres always an excuse to blame men...</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>are you a pilgrimwhy arnt you growing your own...</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>no he was accused of being a racist white man</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>how do we fight agaisnt women who use sexual f...</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>add this small and annoying irrelevant story t...</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447978</th>\n",
       "      <td>brother williamso you are opposed to women ser...</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447987</th>\n",
       "      <td>i dont think i can picture christ ever saying ...</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447995</th>\n",
       "      <td>another man shamming article if white men did ...</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447996</th>\n",
       "      <td>no matter what is put in front of you regardin...</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447998</th>\n",
       "      <td>i just dont find her a very good representatio...</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54469 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment_text  split  na_gender  \\\n",
       "3       blame men theres always an excuse to blame men...  train          0   \n",
       "13      are you a pilgrimwhy arnt you growing your own...  train          0   \n",
       "21          no he was accused of being a racist white man  train          0   \n",
       "31      how do we fight agaisnt women who use sexual f...  train          0   \n",
       "46      add this small and annoying irrelevant story t...  train          0   \n",
       "...                                                   ...    ...        ...   \n",
       "447978  brother williamso you are opposed to women ser...  train          0   \n",
       "447987  i dont think i can picture christ ever saying ...  train          0   \n",
       "447995  another man shamming article if white men did ...  train          0   \n",
       "447996  no matter what is put in front of you regardin...  train          0   \n",
       "447998  i just dont find her a very good representatio...  train          0   \n",
       "\n",
       "        toxicity  male  female  transgender  other_gender  \n",
       "3       0.545455     1       1            0             0  \n",
       "13      0.800000     1       0            0             0  \n",
       "21      0.363636     1       0            0             0  \n",
       "31      0.800000     1       1            0             0  \n",
       "46      0.594595     0       1            0             0  \n",
       "...          ...   ...     ...          ...           ...  \n",
       "447978  0.400000     1       1            0             0  \n",
       "447987  0.400000     0       1            0             0  \n",
       "447995  0.400000     1       0            0             0  \n",
       "447996  0.400000     1       0            1             1  \n",
       "447998  0.400000     0       0            1             1  \n",
       "\n",
       "[54469 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male\n",
      "female\n",
      "transgender\n",
      "other_gender\n"
     ]
    }
   ],
   "source": [
    "for col in training_data.columns[4:]:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdalineGDTrainWorst():\n",
    "    def __init__(self, learning_rate = 0.01, n_iter = 20, w = None):\n",
    "        self.w = w\n",
    "        self.bestW = None\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iter = n_iter\n",
    "        \n",
    "    def CheckAccuracy(self, predictions, labels):\n",
    "        print(\"Percentage of toxic in predictions: \", sum(predictions)/len(predictions))\n",
    "        print(\"Percentage of toxic in labels: \", sum(labels)/len(labels))\n",
    "        acc = 0.0\n",
    "        for i in range(len(predictions)):\n",
    "            if (np.round(predictions[i]) == np.round(labels[i])):\n",
    "                acc += 1\n",
    "        return acc/len(predictions)\n",
    "    \n",
    "    def CheckLoss(self, predictions, labels):\n",
    "        predictions = np.array(predictions).reshape(len(predictions), 1)\n",
    "        labels = np.array(labels).reshape(len(labels), 1)\n",
    "        loss = np.sum(np.absolute(np.subtract(predictions, labels)))\n",
    "        return loss/len(predictions)\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        # Making sure that array is numpy array\n",
    "        X_test = np.array(X_test).reshape((len(X_test), -1))\n",
    "        \n",
    "        preds = np.dot(X_test, self.w)\n",
    "        return preds\n",
    "    \n",
    "    # For adding noise \n",
    "    def addNoise(self, X_train):\n",
    "        #Standard deviation set to 0.1\n",
    "        #Inspiration from https://www.researchgate.net/post/How-to-add-some-noise-data-to-my-classification-datasets\n",
    "        variance, scale = 0.1, 1\n",
    "        noise = np.random.normal(0, variance, len(X_train[0]))\n",
    "        #noise = noise.reshape(len(X_train[0]), 1)\n",
    "        X_train += (noise/scale)\n",
    "        return X_train\n",
    "        \n",
    "    def fit(self, dfTrain, dfVal):\n",
    "        # Making sure that arrays are numpy arrays\n",
    "        \n",
    "        X_train = dfTrain['comment_text'].values.tolist()\n",
    "        Y_train = dfTrain['toxicity'].values.tolist()\n",
    "        X_train = np.array(X_train).reshape((len(X_train), -1))\n",
    "        Y_train = np.array(Y_train).reshape((len(Y_train), 1))\n",
    "        \n",
    "        X_val = dfVal['comment_text'].values.tolist()\n",
    "        Y_val = dfVal['toxicity'].values.tolist()\n",
    "        \n",
    "        X_val = np.array(X_val).reshape((len(X_val), -1))\n",
    "        Y_val = np.array(Y_val).reshape((len(Y_val), 1))\n",
    "        \n",
    "        #Add noise to traning data\n",
    "        print('X_train before noise: ', X_train)\n",
    "        print(X_train)\n",
    "        X_train = self.addNoise(X_train)\n",
    "\n",
    "        print('X_train after noise: ', X_train)\n",
    "        print(len(X_train[0]))\n",
    "        \n",
    "        # Initializing w vector using random normal distribution\n",
    "        if self.w == None:\n",
    "            self.w = np.random.normal(0, 0.1, len(X_train[0])).reshape(len(X_train[0]), 1)\n",
    "            #self.w = np.zeros(len(X_train[0])).reshape(len(X_train[0]), 1)\n",
    "        \n",
    "        # Updating w vector for each sample\n",
    "        output = np.dot(X_train, self.w)\n",
    "        error = (Y_train - output)            \n",
    "        self.w += (1/len(Y_train)) * self.learning_rate * np.dot(X_train.T, error)\n",
    "        \n",
    "        dic = {}\n",
    "        for col in dfTrain.columns[4:]:\n",
    "            \n",
    "            tempSet = dfTrain[dfTrain[col] == 1]\n",
    "            print(tempSet)\n",
    "            tempLabels = tempSet['toxicity'].values.tolist()\n",
    "            tempVecs = tempSet['comment_text'].values.tolist()\n",
    "            dic[col] = [tempVecs, tempLabels]\n",
    "        \n",
    "        \n",
    "        tmpPredictions = self.predict(X_val)\n",
    "        for i in range(len(tmpPredictions)):\n",
    "            if tmpPredictions[i] < 0:\n",
    "                tmpPredictions[i] = 0\n",
    "            if tmpPredictions[i] > 1:\n",
    "                tmpPredictions[i] = 1\n",
    "        \n",
    "        bestLoss = self.CheckLoss(tmpPredictions, Y_val)\n",
    "        badEpoch = 0\n",
    "        self.bestW = self.w\n",
    "        early_stopping = 10\n",
    "        \n",
    "        # Using n epochs\n",
    "        for i in range(self.n_iter):\n",
    "            losses = []\n",
    "            for col in dfTrain.columns[4:]:\n",
    "                tempPredictions = self.predict(dic[col][0])\n",
    "                currentLoss = self.CheckLoss(tempPredictions, dic[col][1])\n",
    "                losses.append([currentLoss, col])\n",
    "            losses = np.array(losses)            \n",
    "            worstCol = losses[np.argmax(losses[:,0])][1]\n",
    "            \n",
    "            X_train = dic[worstCol][0]\n",
    "            Y_train = dic[worstCol][1]\n",
    "            \n",
    "            X_train = np.array(X_train).reshape((len(X_train), -1))\n",
    "            Y_train = np.array(Y_train).reshape((len(Y_train), 1))\n",
    "            \n",
    "            # Updating w vector for each sample\n",
    "            output = np.dot(X_train, self.w)\n",
    "            #print(output)\n",
    "            error = (Y_train - output)\n",
    "            self.w += (1/len(Y_train)) * (self.learning_rate) * np.dot(X_train.T, error)\n",
    "            \n",
    "            tmpPredictions = self.predict(X_val)\n",
    "            for i in range(len(tmpPredictions)):\n",
    "                if tmpPredictions[i] < 0:\n",
    "                    tmpPredictions[i] = 0\n",
    "                if tmpPredictions[i] > 1:\n",
    "                    tmpPredictions[i] = 1\n",
    "            l = self.CheckLoss(tmpPredictions, Y_val)\n",
    "            print(l)\n",
    "            # Saving the best model and also checks for Early_Stopping\n",
    "            \n",
    "            if l < bestLoss:\n",
    "                bestLoss = l\n",
    "                badEpoch = 0\n",
    "                self.bestW = self.w\n",
    "            else:\n",
    "                badEpoch += 1\n",
    "\n",
    "            if badEpoch >= early_stopping:\n",
    "                self.w = self.bestW\n",
    "                print(\"Stopped cause of bad Epoch: \", badEpoch)\n",
    "                break\n",
    "            \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-11ec48e0f06f>:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  X_trainForw2v = np.array(X_trainForw2v)\n",
      "<ipython-input-8-11ec48e0f06f>:16: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  X_testForw2v = np.array(X_testForw2v)\n",
      "<ipython-input-8-11ec48e0f06f>:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  X_valForw2v = np.array(X_valForw2v)\n"
     ]
    }
   ],
   "source": [
    "# Preparing reviews in list of lists format\n",
    "X_trainForw2v = []\n",
    "X_testForw2v = []\n",
    "X_valForw2v = []\n",
    "\n",
    "for sentence in trainingComments:\n",
    "    X_trainForw2v.append(sentence.split(' '))\n",
    "\n",
    "for sentence in testComments:\n",
    "    X_testForw2v.append(sentence.split(' '))\n",
    "    \n",
    "for sentence in valComments:\n",
    "    X_valForw2v.append(sentence.split(' '))\n",
    "\n",
    "X_trainForw2v = np.array(X_trainForw2v)\n",
    "X_testForw2v = np.array(X_testForw2v)\n",
    "X_valForw2v = np.array(X_valForw2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not want words with overall less than 3 appearances to count, generating vector of size 200 for each word\n",
    "modelw2v = Word2Vec(X_trainForw2v, min_count=3, size=50, iter=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-4ce275742b9a>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  training_data['comment_text'][ind] = X_trainForw2vTransformed[i]\n",
      "<ipython-input-10-4ce275742b9a>:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data['comment_text'][ind] = X_testForw2vTransformed[i]\n",
      "<ipython-input-10-4ce275742b9a>:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  validation_data['comment_text'][ind] = X_valForw2vTransformed[i]\n"
     ]
    }
   ],
   "source": [
    "def TransformToEmbedding(model, data):\n",
    "    transformed = np.zeros((len(data), model.vector_size))\n",
    "    for i, sentence in enumerate(data):\n",
    "        currentLst = []\n",
    "        for word in sentence:\n",
    "            if word in model.wv.vocab.keys():\n",
    "                currentLst.append(model.wv[word])\n",
    "        if (len(currentLst) > 0):\n",
    "            currentLst = np.mean(np.array(currentLst), axis=0)\n",
    "        else:\n",
    "            currentLst = np.zeros(model.vector_size)\n",
    "        transformed[i] = np.array(currentLst)\n",
    "    return np.array(transformed)\n",
    "\n",
    "\n",
    "X_trainForw2vTransformed = TransformToEmbedding(modelw2v, X_trainForw2v)\n",
    "X_testForw2vTransformed = TransformToEmbedding(modelw2v, X_testForw2v)\n",
    "X_valForw2vTransformed = TransformToEmbedding(modelw2v, X_valForw2v)\n",
    "\n",
    "for i, ind in enumerate(training_data.index):\n",
    "    training_data['comment_text'][ind] = X_trainForw2vTransformed[i]\n",
    "    \n",
    "for i, ind in enumerate(test_data.index):\n",
    "    test_data['comment_text'][ind] = X_testForw2vTransformed[i]\n",
    "\n",
    "for i, ind in enumerate(validation_data.index):\n",
    "    validation_data['comment_text'][ind] = X_valForw2vTransformed[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train before noise:  [[-0.00440381  1.11829698  0.19813064 ... -0.13744467 -1.1535815\n",
      "   1.17816341]\n",
      " [-0.14739849  0.99233359  0.09774414 ...  0.16407396 -0.21717675\n",
      "   0.74825835]\n",
      " [ 1.55605376  3.10024405  1.22731507 ...  0.98942661 -0.3961421\n",
      "   1.8101908 ]\n",
      " ...\n",
      " [-0.078603    1.68041027 -0.31494296 ...  0.28787455 -0.39276916\n",
      "   1.27385104]\n",
      " [ 0.63559914  0.80228806 -0.18537697 ... -0.3118881   0.18443312\n",
      "   0.9250825 ]\n",
      " [-0.56343591  0.94692969  0.28899601 ... -0.61391854  0.0803479\n",
      "   0.02154604]]\n",
      "[[-0.00440381  1.11829698  0.19813064 ... -0.13744467 -1.1535815\n",
      "   1.17816341]\n",
      " [-0.14739849  0.99233359  0.09774414 ...  0.16407396 -0.21717675\n",
      "   0.74825835]\n",
      " [ 1.55605376  3.10024405  1.22731507 ...  0.98942661 -0.3961421\n",
      "   1.8101908 ]\n",
      " ...\n",
      " [-0.078603    1.68041027 -0.31494296 ...  0.28787455 -0.39276916\n",
      "   1.27385104]\n",
      " [ 0.63559914  0.80228806 -0.18537697 ... -0.3118881   0.18443312\n",
      "   0.9250825 ]\n",
      " [-0.56343591  0.94692969  0.28899601 ... -0.61391854  0.0803479\n",
      "   0.02154604]]\n",
      "X_train after noise:  [[ 0.00889024  0.97112567  0.01032623 ... -0.26949515 -1.05893392\n",
      "   1.23256225]\n",
      " [-0.13410444  0.84516228 -0.09006027 ...  0.03202348 -0.12252917\n",
      "   0.80265719]\n",
      " [ 1.5693478   2.95307273  1.03951066 ...  0.85737614 -0.30149451\n",
      "   1.86458963]\n",
      " ...\n",
      " [-0.06530895  1.53323895 -0.50274737 ...  0.15582407 -0.29812157\n",
      "   1.32824987]\n",
      " [ 0.64889318  0.65511674 -0.37318138 ... -0.44393858  0.2790807\n",
      "   0.97948134]\n",
      " [-0.55014187  0.79975838  0.1011916  ... -0.74596902  0.17499549\n",
      "   0.07594488]]\n",
      "50\n",
      "                                             comment_text  split  na_gender  \\\n",
      "3       [-0.0044038062915205956, 1.1182969808578491, 0...  train          0   \n",
      "13      [-0.14739848673343658, 0.9923335909843445, 0.0...  train          0   \n",
      "21      [1.5560537576675415, 3.1002440452575684, 1.227...  train          0   \n",
      "31      [0.44515857100486755, 1.0837377309799194, -0.0...  train          0   \n",
      "53      [0.351369172334671, 0.4842054545879364, 0.3448...  train          0   \n",
      "...                                                   ...    ...        ...   \n",
      "447964  [0.4290074408054352, 0.991285502910614, 1.0155...  train          0   \n",
      "447966  [0.9394441843032837, 0.17871500551700592, 0.41...  train          0   \n",
      "447978  [0.15976859629154205, 0.8210107088088989, -0.1...  train          0   \n",
      "447995  [-0.07860299944877625, 1.6804102659225464, -0....  train          0   \n",
      "447996  [0.6355991363525391, 0.8022880554199219, -0.18...  train          0   \n",
      "\n",
      "        toxicity  male  female  transgender  other_gender  \n",
      "3       0.545455     1       1            0             0  \n",
      "13      0.800000     1       0            0             0  \n",
      "21      0.363636     1       0            0             0  \n",
      "31      0.800000     1       1            0             0  \n",
      "53      0.800000     1       1            0             0  \n",
      "...          ...   ...     ...          ...           ...  \n",
      "447964  0.400000     1       0            0             0  \n",
      "447966  0.400000     1       0            0             0  \n",
      "447978  0.400000     1       1            0             0  \n",
      "447995  0.400000     1       0            0             0  \n",
      "447996  0.400000     1       0            1             1  \n",
      "\n",
      "[26894 rows x 8 columns]\n",
      "                                             comment_text  split  na_gender  \\\n",
      "3       [-0.0044038062915205956, 1.1182969808578491, 0...  train          0   \n",
      "31      [0.44515857100486755, 1.0837377309799194, -0.0...  train          0   \n",
      "46      [0.18173934519290924, 0.7181287407875061, 0.39...  train          0   \n",
      "53      [0.351369172334671, 0.4842054545879364, 0.3448...  train          0   \n",
      "62      [0.627208411693573, 1.0298540592193604, 0.6602...  train          0   \n",
      "...                                                   ...    ...        ...   \n",
      "447952  [-0.890811562538147, 1.3063077926635742, -0.34...  train          0   \n",
      "447962  [0.010670044459402561, 0.7054192423820496, 0.4...  train          0   \n",
      "447974  [0.002694771159440279, 0.6608575582504272, 0.2...  train          0   \n",
      "447978  [0.15976859629154205, 0.8210107088088989, -0.1...  train          0   \n",
      "447987  [0.22427427768707275, 0.5230295062065125, -0.2...  train          0   \n",
      "\n",
      "        toxicity  male  female  transgender  other_gender  \n",
      "3       0.545455     1       1            0             0  \n",
      "31      0.800000     1       1            0             0  \n",
      "46      0.594595     0       1            0             0  \n",
      "53      0.800000     1       1            0             0  \n",
      "62      0.814286     0       1            0             0  \n",
      "...          ...   ...     ...          ...           ...  \n",
      "447952  0.400000     0       1            0             0  \n",
      "447962  0.400000     1       1            1             1  \n",
      "447974  0.400000     0       1            0             0  \n",
      "447978  0.400000     1       1            0             0  \n",
      "447987  0.400000     0       1            0             0  \n",
      "\n",
      "[34305 rows x 8 columns]\n",
      "                                             comment_text  split  na_gender  \\\n",
      "297     [0.6662154197692871, -0.4409139156341553, 0.46...  train          0   \n",
      "582     [0.29820045828819275, 1.0547945499420166, 0.17...  train          0   \n",
      "652     [0.5880008339881897, 1.4190740585327148, 0.418...  train          0   \n",
      "734     [0.9107307195663452, 1.9521220922470093, 0.710...  train          0   \n",
      "1632    [0.4442620277404785, 0.9426950812339783, 0.845...  train          0   \n",
      "...                                                   ...    ...        ...   \n",
      "447868  [0.4054655432701111, 0.14272238314151764, 0.68...  train          0   \n",
      "447909  [0.5788114666938782, 0.1383405327796936, 0.355...  train          0   \n",
      "447962  [0.010670044459402561, 0.7054192423820496, 0.4...  train          0   \n",
      "447996  [0.6355991363525391, 0.8022880554199219, -0.18...  train          0   \n",
      "447998  [-0.5634359121322632, 0.9469296932220459, 0.28...  train          0   \n",
      "\n",
      "        toxicity  male  female  transgender  other_gender  \n",
      "297     0.446154     0       0            1             1  \n",
      "582     0.142857     0       0            1             1  \n",
      "652     0.520000     0       0            1             1  \n",
      "734     0.657895     1       0            1             1  \n",
      "1632    0.562500     0       0            1             1  \n",
      "...          ...   ...     ...          ...           ...  \n",
      "447868  0.400000     1       1            1             1  \n",
      "447909  0.400000     0       0            1             1  \n",
      "447962  0.400000     1       1            1             1  \n",
      "447996  0.400000     1       0            1             1  \n",
      "447998  0.400000     0       0            1             1  \n",
      "\n",
      "[1503 rows x 8 columns]\n",
      "                                             comment_text  split  na_gender  \\\n",
      "297     [0.6662154197692871, -0.4409139156341553, 0.46...  train          0   \n",
      "582     [0.29820045828819275, 1.0547945499420166, 0.17...  train          0   \n",
      "652     [0.5880008339881897, 1.4190740585327148, 0.418...  train          0   \n",
      "734     [0.9107307195663452, 1.9521220922470093, 0.710...  train          0   \n",
      "1632    [0.4442620277404785, 0.9426950812339783, 0.845...  train          0   \n",
      "...                                                   ...    ...        ...   \n",
      "447868  [0.4054655432701111, 0.14272238314151764, 0.68...  train          0   \n",
      "447909  [0.5788114666938782, 0.1383405327796936, 0.355...  train          0   \n",
      "447962  [0.010670044459402561, 0.7054192423820496, 0.4...  train          0   \n",
      "447996  [0.6355991363525391, 0.8022880554199219, -0.18...  train          0   \n",
      "447998  [-0.5634359121322632, 0.9469296932220459, 0.28...  train          0   \n",
      "\n",
      "        toxicity  male  female  transgender  other_gender  \n",
      "297     0.446154     0       0            1             1  \n",
      "582     0.142857     0       0            1             1  \n",
      "652     0.520000     0       0            1             1  \n",
      "734     0.657895     1       0            1             1  \n",
      "1632    0.562500     0       0            1             1  \n",
      "...          ...   ...     ...          ...           ...  \n",
      "447868  0.400000     1       1            1             1  \n",
      "447909  0.400000     0       0            1             1  \n",
      "447962  0.400000     1       1            1             1  \n",
      "447996  0.400000     1       0            1             1  \n",
      "447998  0.400000     0       0            1             1  \n",
      "\n",
      "[1503 rows x 8 columns]\n",
      "0.3201891333921759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29376601689165666\n",
      "0.2846621716415124\n",
      "0.2789867271171605\n",
      "0.27417351537966195\n",
      "0.2697449238416346\n",
      "0.265594118567031\n",
      "0.26169914521041715\n",
      "0.25802694416505834\n",
      "0.2545541051853694\n",
      "Stopped cause of bad Epoch:  10\n",
      "Loss on testSet:  0.34402342527116403\n",
      "Percentage of toxic in predictions:  [0.20619341]\n",
      "Percentage of toxic in labels:  [0.36633042]\n",
      "Accuracy on testSet after round 0.5588\n"
     ]
    }
   ],
   "source": [
    "modelEmbed = AdalineGDTrainWorst(learning_rate = 0.1, n_iter = 200)\n",
    "\n",
    "modelEmbed.fit(training_data, validation_data)\n",
    "\n",
    "predictions = modelEmbed.predict(X_testForw2vTransformed)\n",
    "\n",
    "Y_test = np.array(testLabels.values.tolist())\n",
    "\n",
    "Y_test = Y_test.reshape(len(Y_test), 1)\n",
    "\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i] < 0:\n",
    "        predictions[i] = 0\n",
    "    if predictions[i] > 1:\n",
    "        predictions[i] = 1\n",
    "        \n",
    "\n",
    "print(\"Loss on testSet: \", modelEmbed.CheckLoss(predictions, Y_test))\n",
    "print(\"Accuracy on testSet after round\", modelEmbed.CheckAccuracy(predictions, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
