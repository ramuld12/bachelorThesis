{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turkish-river",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import re\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-egyptian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "df = pd.read_csv(\"../CSVFiles/smallDomainDataNotEmbedded.csv\")\n",
    "\n",
    "\n",
    "bertweet = AutoModel.from_pretrained(\"vinai/bertweet-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False, normalization=True)                     \n",
    "bertweet.eval()\n",
    "bertweet.to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, idx in enumerate(df.index):\n",
    "        embeds = bertweet(torch.tensor(tokenizer.encode(df['comment_text'][idx], add_special_tokens=True,\n",
    "                                                                   truncation=True)).to('cuda').unsqueeze(0))[0].squeeze(0)\n",
    "        if embeds.shape[0] < 100:\n",
    "            embeds = torch.cat((embeds, torch.zeros((100-embeds.shape[0], 768)).to('cuda')))\n",
    "            \n",
    "        elif embeds.shape[0] > 100:\n",
    "            embeds = embeds[0:100]\n",
    "        \n",
    "        df.at[idx, 'comment_text'] = embeds.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-fleet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-scanner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating values for training_data\n",
    "training_data = df[df['split'] == 'train']\n",
    "\n",
    "# Getting test_data\n",
    "test_data = df[df['split'] == 'test']\n",
    "\n",
    "# Getting validation_data\n",
    "validation_data = df[df['split'] == 'val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-diabetes",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "about-advertiser",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating data loaders\n",
    "X_train = np.array(training_data['comment_text'].values.tolist())\n",
    "Y_train = np.array(training_data['toxicity'].values.tolist())\n",
    "\n",
    "X_test = np.array(test_data['comment_text'].values.tolist())\n",
    "Y_test = np.array(test_data['toxicity'].values.tolist())\n",
    "\n",
    "X_val = np.array(validation_data['comment_text'].values.tolist())\n",
    "Y_val = np.array(validation_data['toxicity'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-routine",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(len(X_train))\n",
    "print(len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-instrument",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chief-conversion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-elder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CleanText(text):\n",
    "    text = text.lower() #Turn all text entries into lower-case\n",
    "    text = re.sub(r'''(https?:\\/\\/www\\.|https?:\\/\\/)?[a-z0-9]+([\\-\\.]{1}[a-z0-9]+)*\\.[a-z]{2,3}[-a-zA-Z0-9()@:%_\\+.~#?&\\//=<>]*''', \"<URL>\", text)\n",
    "    #Replace URL with tag\n",
    "    text = re.sub(r'''[0-9]+[/\\-.]+[0-9]+[/\\-.]+[0-9]+''', \"<DATE>\", text) #Replace dates with tag\n",
    "    text = re.sub(r'''[a-z0-9._%+-]+\\@[a-z0-9.-]+[a-z0-9]\\.[a-z]{1,}''', \"<EMAIL>\", text)\n",
    "    text = re.sub(r'''[0-9]+''', \"<NUM>\", text) #Replace numbers with tag\n",
    "    text = re.sub(r'''[.|,|!|?|\\'|\\''|\\\"|\\n|\\t|\\-|\\(|\\)]''', '', text)\n",
    "    text = re.sub(r'''^\\s+|\\s+$''', '', text) #Remove whitespaces at the end and start of string\n",
    "    text = re.sub(r'''[ ][ ]+|_''', \" \", text) #Remove multiple whitespace\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-intermediate",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.eval()\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-workshop",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_training = []\n",
    "prep_test = []\n",
    "prep_val = []\n",
    "\n",
    "for i, text in enumerate(X_train):\n",
    "    prep_training.append([torch.tensor(tokenizer.encode(text, add_special_tokens=True, max_length=100, truncation=True, padding=\"max_length\")), Y_train[i]])\n",
    "\n",
    "for i, text in enumerate(X_test):\n",
    "    prep_test.append([torch.tensor(tokenizer.encode(text, add_special_tokens=True, max_length=100, truncation=True, padding=\"max_length\")), Y_test[i]])\n",
    "\n",
    "for i, text in enumerate(X_val):\n",
    "    prep_val.append([torch.tensor(tokenizer.encode(text, add_special_tokens=True, max_length=100, truncation=True, padding=\"max_length\")), Y_val[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-locator",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-marker",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(prep_training, batch_size=16, shuffle=True)\n",
    "valid_loader = DataLoader(prep_val, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(prep_test, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-pierce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CheckAccuracy(predictions, labels):\n",
    "        acc = 0.0\n",
    "        for i in range(len(predictions)):\n",
    "            if (predictions[i] == labels[i]):\n",
    "                acc += 1\n",
    "        return acc/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-cross",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "lr = 0.00005\n",
    "\n",
    "cuda = True # Set this if training on GPU\n",
    "cuda = cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-flashing",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_training = []\n",
    "prep_test = []\n",
    "prep_val = []\n",
    "\n",
    "for i, text in enumerate(X_train):\n",
    "    prep_training.append([X_train[i], Y_train[i]])\n",
    "\n",
    "for i, text in enumerate(X_test):\n",
    "    prep_test.append([X_test[i], Y_test[i]])\n",
    "\n",
    "for i, text in enumerate(X_val):\n",
    "    prep_val.append([X_val[i], Y_val[i]])\n",
    "    \n",
    "train_loader = DataLoader(prep_training, batch_size=16, shuffle=True)\n",
    "valid_loader = DataLoader(prep_val, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(prep_test, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-medication",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(LSTM_Net, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=768, hidden_size=768, num_layers=1, batch_first=True, bidirectional=True) #bidirectional=True\n",
    "        self.fc1 = nn.Sequential(nn.Linear(768, 256), nn.ReLU(), nn.Dropout(p=0.8))\n",
    "        self.fc2 = nn.Linear(768, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = model(x)[0]\n",
    "        lstm_out, (ht, ct) = self.lstm(x)\n",
    "        #print(lstm_out.shape)\n",
    "        #print(ht.shape)\n",
    "        #print(ht[-1, :, :].shape)\n",
    "        output = self.fc1(ht[-1, :, :])\n",
    "        output = self.fc2(ht[-1, :, :])\n",
    "        #print(output.shape)\n",
    "        output = self.sigmoid(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collect-pottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up model parameters\n",
    "lstm_model = LSTM_Net().to(device)\n",
    "loss_function = nn.BCELoss()\n",
    "optimizer = torch.optim.AdamW(lstm_model.parameters(), lr=lr)\n",
    "\n",
    "early_stopping = 5\n",
    "notImproved = 0\n",
    "bestLoss = None\n",
    "bestModel = None\n",
    "bestEpoch = 0\n",
    "\n",
    "trainArr = []\n",
    "valArr = []\n",
    "\n",
    "for epoch in range(1, epochs + 1): \n",
    "    \n",
    "    train_loss = 0.0\n",
    "    lstm_model.train()\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        \n",
    "        # get the input\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device).float()\n",
    "        \n",
    "        optimizer.zero_grad()        \n",
    "        outputs = lstm_model(inputs)\n",
    "        \n",
    "        outputs = outputs.squeeze(1)\n",
    "        \n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    \n",
    "    trainArr.append(train_loss)\n",
    "    \n",
    "    valid_loss = 0\n",
    "    labs = []\n",
    "    preds = []\n",
    "    \n",
    "    lstm_model.eval()\n",
    "    with torch.no_grad():        \n",
    "        for batch_idx, data in enumerate(valid_loader):\n",
    "            # get the input\n",
    "            inputs, labels = data\n",
    "        \n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device).float()\n",
    "            \n",
    "            outputs = lstm_model(inputs)\n",
    "            outputs = outputs.squeeze(1)\n",
    "        \n",
    "            labs.extend(labels)\n",
    "            preds.extend(torch.round(outputs))\n",
    "            valid_loss += loss_function(outputs, labels).item()\n",
    "            \n",
    "    valid_loss /= len(valid_loader.dataset)\n",
    "    \n",
    "    valArr.append(valid_loss)\n",
    "    print(\"Accuracy on validation set: \", CheckAccuracy(labs, preds))\n",
    "    \n",
    "    if bestLoss == None:\n",
    "        bestLoss = valid_loss\n",
    "    \n",
    "    if valid_loss <= bestLoss:\n",
    "        bestLoss = valid_loss\n",
    "        bestModel = lstm_model\n",
    "        notImproved = 0\n",
    "        bestEpoch = epoch\n",
    "    else:\n",
    "        notImproved +=1\n",
    "        \n",
    "    if notImproved >= early_stopping:\n",
    "        break\n",
    "    \n",
    "print(bestEpoch)\n",
    "\n",
    "lstm_model = bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-trouble",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-sucking",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.scatter(np.arange(0,len(trainArr)), trainArr, color='r', label='Training loss')\n",
    "plt.scatter(np.arange(0,len(valArr)), valArr, color='g', label='Validation loss')\n",
    "plt.title(\"Training loss vs Validation loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-teaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_Scores(preds, labels):\n",
    "    true_positives = 0\n",
    "    true_negatives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "    for i in range(len(labs)):\n",
    "        if labels[i]==1 and preds[i]==1:\n",
    "            true_positives += 1\n",
    "        if labels[i]==0 and preds[i]==0:\n",
    "            true_negatives += 1\n",
    "        if labels[i]==0 and preds[i]==1:\n",
    "            false_positives += 1\n",
    "        if labels[i]==1 and preds[i]==0:\n",
    "            false_negatives += 1\n",
    "    print(\"true_positives\", true_positives)\n",
    "    print(\"true_negatives\", true_negatives)\n",
    "    print(\"false_positives\", false_positives)\n",
    "    print(\"false_negatives\", false_negatives)\n",
    "    \n",
    "    return true_positives, true_negatives, false_positives, false_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-ownership",
   "metadata": {},
   "outputs": [],
   "source": [
    "labs = []\n",
    "preds = []\n",
    "lstm_model.eval()\n",
    "with torch.no_grad():        \n",
    "    for batch_idx, data in enumerate(test_loader):\n",
    "        # get the input\n",
    "        inputs, labels = data\n",
    "        \n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device).float()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = lstm_model(inputs)\n",
    "        outputs = outputs.squeeze(1)\n",
    "        \n",
    "        labs.extend(labels)\n",
    "        preds.extend(torch.round(outputs))\n",
    "print(\"Accuracy on test set: \", CheckAccuracy(labs, preds))\n",
    "\n",
    "labs = []\n",
    "preds = []\n",
    "lstm_model.eval()\n",
    "with torch.no_grad():        \n",
    "    for batch_idx, data in enumerate(valid_loader):\n",
    "        # get the input\n",
    "        inputs, labels = data\n",
    "        \n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device).float()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = lstm_model(inputs)\n",
    "        outputs = outputs.squeeze(1)\n",
    "        \n",
    "        labs.extend(labels)\n",
    "        preds.extend(torch.round(outputs))\n",
    "print(\"Accuracy on val set: \", CheckAccuracy(labs, preds))\n",
    "\n",
    "labs = []\n",
    "preds = []\n",
    "lstm_model.eval()\n",
    "with torch.no_grad():        \n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        # get the input\n",
    "        inputs, labels = data\n",
    "        \n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device).float()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = lstm_model(inputs)\n",
    "        outputs = outputs.squeeze(1)\n",
    "        \n",
    "        labs.extend(labels)\n",
    "        preds.extend(torch.round(outputs))\n",
    "print(\"Accuracy on train set: \", CheckAccuracy(labs, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-soviet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-compromise",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-shelter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-scanner",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
