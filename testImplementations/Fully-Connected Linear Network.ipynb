{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-mineral",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn, optim\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-sight",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CleanText(text):\n",
    "    text = re.sub(r'''[\\[|\\]]''', \"\", text).split()\n",
    "    text = np.array(text, dtype=\"float64\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-praise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal dataset\n",
    "df = pd.read_csv('../CSVFiles/small10000DomainDataBertweetEmbedded.csv')\n",
    "df['comment_text'] = df['comment_text'].apply(lambda text: CleanText(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-inspiration",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-candle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating values for training_data\n",
    "training_data = df[df['split'] == 'train']\n",
    "\n",
    "# Getting test_data\n",
    "test_data = df[df['split'] == 'test']\n",
    "\n",
    "# Getting validation_data\n",
    "validation_data = df[df['split'] == 'val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polyphonic-jaguar",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Toxic samples training data: ', sum(training_data['toxicity']))\n",
    "print('None-toxic samples training data: ', len(training_data['toxicity'])-sum(training_data['toxicity']))\n",
    "\n",
    "print(\"\\n\")\n",
    "print('Toxic samples validation data: ', sum(validation_data['toxicity']))\n",
    "print('None-toxic samples validation data: ', len(validation_data['toxicity'])-sum(validation_data['toxicity']))\n",
    "\n",
    "print(\"\\n\")\n",
    "print('Toxic samples test data: ', sum(test_data['toxicity']))\n",
    "print('None-toxic samples test data: ', len(test_data['toxicity'])-sum(test_data['toxicity']))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "for col in training_data.columns[3:]:\n",
    "    print(col + \": \" + str(np.sum(training_data[col])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-athens",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CheckAccuracy(predictions, labels):\n",
    "        acc = 0.0\n",
    "        for i in range(len(predictions)):\n",
    "            if (predictions[i] == labels[i]):\n",
    "                acc += 1\n",
    "        return acc/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set parameters for the model\n",
    "#torch.manual_seed(2) # set fixed random seed for reproducibility\n",
    "\n",
    "cuda = True # Set this if training on GPU\n",
    "cuda = cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "print(\"Using \"+repr(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-stream",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating data loaders\n",
    "X_train = np.array(training_data['comment_text'].values.tolist())\n",
    "Y_train = np.array(training_data['toxicity'].values.tolist())\n",
    "\n",
    "X_test = np.array(test_data['comment_text'].values.tolist())\n",
    "Y_test = np.array(test_data['toxicity'].values.tolist())\n",
    "\n",
    "X_val = np.array(validation_data['comment_text'].values.tolist())\n",
    "Y_val = np.array(validation_data['toxicity'].values.tolist())\n",
    "\n",
    "prepare_trainloader = []\n",
    "for i in range(len(X_train)):\n",
    "    prepare_trainloader.append([X_train[i], Y_train[i]])\n",
    "    \n",
    "prepare_testloader = []\n",
    "for i in range(len(X_test)):\n",
    "    prepare_testloader.append([X_test[i], Y_test[i]])\n",
    "    \n",
    "prepare_validloader = []\n",
    "for i in range(len(X_val)):\n",
    "    prepare_validloader.append([X_val[i], Y_val[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-glucose",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Sequential(nn.Linear(768, 64), nn.ReLU())\n",
    "        self.fc2 = nn.Sequential(nn.Linear(64, 32), nn.ReLU())\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-liver",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Train(model, train_loader, valid_loader, loss_function, optimizer, learning_rate, early_stopping=50, epochs=1000):\n",
    "    # Setting up model parameters\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    if optimizer == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    if optimizer == 'AdamW':\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    if optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    loss_function = loss_function\n",
    "\n",
    "    # Initialising early stopping criterias\n",
    "    early_stopping = early_stopping\n",
    "    notImproved = 0\n",
    "    \n",
    "    bestLoss = None\n",
    "    bestModel = None\n",
    "\n",
    "    trainArr = []\n",
    "    valArr = []\n",
    "\n",
    "    bestf1 = 0\n",
    "    bestEpoch = 0\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "    \n",
    "        train_loss = 0.0\n",
    "        for batch_idx, data in enumerate(train_loader):\n",
    "        \n",
    "            # get the input\n",
    "            inputs, labels = data\n",
    "    \n",
    "            inputs = inputs.to(device).float()\n",
    "            labels = labels.to(device).float()\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.squeeze(1)\n",
    "        \n",
    "            loss = loss_function(outputs, labels)\n",
    "        \n",
    "            loss.backward()\n",
    "        \n",
    "            optimizer.step()\n",
    "        \n",
    "            train_loss += loss.item()\n",
    "    \n",
    "        train_loss /= len(train_loader.dataset)    \n",
    "        trainArr.append(train_loss)\n",
    "    \n",
    "        valid_loss = 0\n",
    "        labs = []\n",
    "        preds = []\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():        \n",
    "            for batch_idx, data in enumerate(valid_loader):\n",
    "                # get the input\n",
    "                inputs, labels = data           \n",
    "            \n",
    "                inputs = inputs.to(device).float()\n",
    "                labels = labels.to(device).float()\n",
    "                \n",
    "                outputs = model(inputs).squeeze()\n",
    "                \n",
    "                labs.extend(labels)\n",
    "                preds.extend(torch.round(outputs))\n",
    "            \n",
    "                valid_loss += loss_function(outputs, labels).item()\n",
    "        \n",
    "        valid_loss /= len(valid_loader.dataset)    \n",
    "        valArr.append(valid_loss)\n",
    "        \n",
    "        if bestLoss == None:\n",
    "            bestLoss = valid_loss\n",
    "    \n",
    "        if valid_loss <= bestLoss:\n",
    "            bestModel = torch.save(model, 'currentModel.pth')\n",
    "            bestLoss = valid_loss\n",
    "            notImproved = 0\n",
    "            bestEpoch = epoch\n",
    "        else:\n",
    "            notImproved +=1\n",
    "        \n",
    "        if notImproved >= early_stopping:\n",
    "            break\n",
    "\n",
    "    model = torch.load('currentModel.pth')\n",
    "    return model, valArr, trainArr, epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-graphic",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.001, 0.0001, 0.00005, 0.00001, 0.000005, 0.000001]\n",
    "loss_functions = [nn.BCELoss(), nn.MSELoss()]\n",
    "optimizers = ['AdamW', 'Adam']\n",
    "batch_sizes = [4, 8, 16, 32, 64]\n",
    "\n",
    "valArr = None\n",
    "trainArr = None\n",
    "bestLoss = None\n",
    "bestAcc = 0\n",
    "\n",
    "with open('GridSearchResults', 'w') as f:\n",
    "    f.write('epoch, learning rate, loss_function, optimizer, batch_size, Val accuracy, Test accuracy')\n",
    "    f.write('\\n')\n",
    "    f.close()\n",
    "    \n",
    "    for lr in learning_rates:\n",
    "        for loss_function in loss_functions:\n",
    "            for optimizer in optimizers:\n",
    "                for batch_size in batch_sizes:\n",
    "\n",
    "                    # Creating loaders\n",
    "                    train_loader = torch.utils.data.DataLoader(prepare_trainloader, batch_size=batch_size, shuffle=True)\n",
    "                    valid_loader = torch.utils.data.DataLoader(prepare_validloader, batch_size=batch_size, shuffle=False)\n",
    "                    test_loader = torch.utils.data.DataLoader(prepare_testloader, batch_size=batch_size, shuffle=False)               \n",
    "\n",
    "                    model, valLossArr , trainLossArr, epoch = Train(Net(), train_loader,\n",
    "                                                                 valid_loader, loss_function,\n",
    "                                                                 optimizer, lr, early_stopping=50, epochs=5000)\n",
    "\n",
    "                    labs = []\n",
    "                    preds = []\n",
    "                    model.eval()\n",
    "                    with torch.no_grad():        \n",
    "                        for batch_idx, data in enumerate(valid_loader):\n",
    "                            inputs, labels = data\n",
    "                            inputs = inputs.to(device).float()\n",
    "                            labels = labels.to(device).float()\n",
    "                            outputs = model(inputs).squeeze()\n",
    "                            labs.extend(labels)\n",
    "                            preds.extend(torch.round(outputs))\n",
    "                    accVal = CheckAccuracy(labs, preds)\n",
    "                    #print(\"Accuracy on validation set: \", accVal)\n",
    "\n",
    "                    labs = []\n",
    "                    preds = []\n",
    "                    model.eval()\n",
    "                    with torch.no_grad():        \n",
    "                        for batch_idx, data in enumerate(test_loader):\n",
    "                            inputs, labels = data\n",
    "                            inputs = inputs.to(device).float()\n",
    "                            labels = labels.to(device).float()\n",
    "                            outputs = model(inputs).squeeze()\n",
    "                            labs.extend(labels)\n",
    "                            preds.extend(torch.round(outputs))\n",
    "                    accTest = CheckAccuracy(labs, preds)\n",
    "                    #print(\"Accuracy on Test set: \", accTest)\n",
    "\n",
    "                    currModelValLoss = np.min(valLossArr)    \n",
    "                    if bestLoss == None:\n",
    "                        bestLoss = currModelValLoss\n",
    "\n",
    "                    if accVal > bestAcc:\n",
    "                        bestAcc = accVal\n",
    "                        bestLoss = currModelValLoss\n",
    "                        valArr = valLossArr\n",
    "                        trainArr = trainLossArr\n",
    "\n",
    "                    elif accVal >= bestAcc and currModelValLoss < bestLoss:\n",
    "                        bestAcc = accVal\n",
    "                        bestLoss = currModelValLoss\n",
    "                        valArr = valLossArr\n",
    "                        trainArr = trainLossArr\n",
    "                    \n",
    "                    with open('GridSearchResults', 'a') as f:\n",
    "                        print(str(epoch)+\",\"+str(lr)+\",\"+ str(loss_function) + \",\" + optimizer + \",\" + str(batch_size) + \",\" + str(accVal) + \",\" + str(accTest))\n",
    "                        f.write(str(epoch)+\",\"+str(lr)+\",\"+ str(loss_function) + \",\" + optimizer + \",\" + str(batch_size) + \",\" + str(accVal) + \",\" + str(accTest))\n",
    "                        f.write('\\n')\n",
    "                        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-moderator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the best model from the generated csv file\n",
    "results = pd.read_csv('GridSearchResultsFinal')\n",
    "\n",
    "results.loc[np.argmax(results['Val accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-dryer",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.scatter(np.arange(0,len(trainArr)), trainArr, color='r', label='Training loss')\n",
    "plt.scatter(np.arange(0,len(valArr)), valArr, color='g', label='Validation loss')\n",
    "plt.title(\"Training loss vs Validation loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-consultation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_Scores(preds, labels):\n",
    "    true_positives = 0\n",
    "    true_negatives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "    for i in range(len(labs)):\n",
    "        if labels[i]==1 and preds[i]==1:\n",
    "            true_positives += 1\n",
    "        if labels[i]==0 and preds[i]==0:\n",
    "            true_negatives += 1\n",
    "        if labels[i]==0 and preds[i]==1:\n",
    "            false_positives += 1\n",
    "        if labels[i]==1 and preds[i]==0:\n",
    "            false_negatives += 1\n",
    "    print(\"true_positives\", true_positives)\n",
    "    print(\"true_negatives\", true_negatives)\n",
    "    print(\"false_positives\", false_positives)\n",
    "    print(\"false_negatives\", false_negatives)\n",
    "    \n",
    "    return true_positives, true_negatives, false_positives, false_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-shanghai",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labs = []\n",
    "preds = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():        \n",
    "    for batch_idx, data in enumerate(test_loader):\n",
    "        # get the input\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.unsqueeze(1)\n",
    "        inputs = inputs.to(device).float()\n",
    "        labels = labels.to(device).float()\n",
    "        \n",
    "        outputs = model(inputs).squeeze()\n",
    "        \n",
    "        labs.extend(labels)\n",
    "        preds.extend(torch.round(outputs))\n",
    "        \n",
    "print(\"Accuracy on test set: \", CheckAccuracy(labs, preds))\n",
    "\n",
    "labs = []\n",
    "preds = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():        \n",
    "    for batch_idx, data in enumerate(valid_loader):\n",
    "        # get the input\n",
    "        inputs, labels = data\n",
    "        \n",
    "        inputs = inputs.to(device).float()\n",
    "        labels = labels.to(device).float()\n",
    "        \n",
    "        outputs = model(inputs).squeeze()\n",
    "        \n",
    "        labs.extend(labels)\n",
    "        preds.extend(torch.round(outputs))\n",
    "        \n",
    "print(\"Accuracy on validation set: \", CheckAccuracy(labs, preds))\n",
    "labs = []\n",
    "preds = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():        \n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        # get the input\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.unsqueeze(1)\n",
    "        inputs = inputs.to(device).float()\n",
    "        labels = labels.to(device).float()\n",
    "        \n",
    "        outputs = model(inputs).squeeze()\n",
    "        \n",
    "        labs.extend(labels)\n",
    "        preds.extend(torch.round(outputs))\n",
    "        \n",
    "print(\"Accuracy on train set: \", CheckAccuracy(labs, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-central",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-powder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-title",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-working",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-belize",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
