{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn, optim\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CleanText(text):\n",
    "    text = re.sub(r'''[\\[|\\]]''', \"\", text).split()\n",
    "    text = np.array(text, dtype=\"float64\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal dataset\n",
    "#df = pd.read_csv('CSVFiles/smallDomainDataBertweetEmbedded.csv')\n",
    "df = pd.read_csv('CSVFiles/small10000DomainDataBertweetEmbedded.csv')\n",
    "#df = pd.read_csv('CSVFiles/small50000DomainDataBertweetEmbedded.csv')\n",
    "df['comment_text'] = df['comment_text'].apply(lambda text: CleanText(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating values for training_data\n",
    "training_data = df[df['split'] == 'train']\n",
    "\n",
    "# Getting test_data\n",
    "test_data = df[df['split'] == 'test']\n",
    "\n",
    "# Getting validation_data\n",
    "validation_data = df[df['split'] == 'val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxic samples training data:  3510.0\n",
      "None-toxic samples training data:  3510.0\n",
      "\n",
      "\n",
      "Toxic samples validation data:  710.0\n",
      "None-toxic samples validation data:  710.0\n",
      "\n",
      "\n",
      "Toxic samples test data:  710.0\n",
      "None-toxic samples test data:  710.0\n",
      "\n",
      "\n",
      "male: 1645.0\n",
      "female: 1450.0\n",
      "LGBTQ: 1153.0\n",
      "christian: 1048.0\n",
      "muslim: 1167.0\n",
      "other_religion: 20.0\n",
      "black: 1265.0\n",
      "white: 1842.0\n"
     ]
    }
   ],
   "source": [
    "print('Toxic samples training data: ', sum(training_data['toxicity']))\n",
    "print('None-toxic samples training data: ', len(training_data['toxicity'])-sum(training_data['toxicity']))\n",
    "\n",
    "print(\"\\n\")\n",
    "print('Toxic samples validation data: ', sum(validation_data['toxicity']))\n",
    "print('None-toxic samples validation data: ', len(validation_data['toxicity'])-sum(validation_data['toxicity']))\n",
    "\n",
    "print(\"\\n\")\n",
    "print('Toxic samples test data: ', sum(test_data['toxicity']))\n",
    "print('None-toxic samples test data: ', len(test_data['toxicity'])-sum(test_data['toxicity']))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "for col in training_data.columns[3:]:\n",
    "    print(col + \": \" + str(np.sum(training_data[col])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CheckAccuracy(predictions, labels):\n",
    "        acc = 0.0\n",
    "        for i in range(len(predictions)):\n",
    "            if (predictions[i] == labels[i]):\n",
    "                acc += 1\n",
    "        return acc/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device(type='cuda')\n"
     ]
    }
   ],
   "source": [
    "### Set parameters for the model\n",
    "#torch.manual_seed(2) # set fixed random seed for reproducibility\n",
    "\n",
    "cuda = True # Set this if training on GPU\n",
    "cuda = cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "print(\"Using \"+repr(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-09aca7a86da8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Creating data loaders\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'comment_text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mY_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'toxicity'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'comment_text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'training_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Creating data loaders\n",
    "X_train = np.array(training_data['comment_text'].values.tolist())\n",
    "Y_train = np.array(training_data['toxicity'].values.tolist())\n",
    "\n",
    "X_test = np.array(test_data['comment_text'].values.tolist())\n",
    "Y_test = np.array(test_data['toxicity'].values.tolist())\n",
    "\n",
    "X_val = np.array(validation_data['comment_text'].values.tolist())\n",
    "Y_val = np.array(validation_data['toxicity'].values.tolist())\n",
    "\n",
    "prepare_trainloader = []\n",
    "for i in range(len(X_train)):\n",
    "    prepare_trainloader.append([X_train[i], Y_train[i]])\n",
    "    \n",
    "prepare_testloader = []\n",
    "for i in range(len(X_test)):\n",
    "    prepare_testloader.append([X_test[i], Y_test[i]])\n",
    "    \n",
    "prepare_validloader = []\n",
    "for i in range(len(X_val)):\n",
    "    prepare_validloader.append([X_val[i], Y_val[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Sequential(nn.Linear(768, 64), nn.ReLU())\n",
    "        self.fc2 = nn.Sequential(nn.Linear(64, 32), nn.ReLU())\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Train(model, train_loader, valid_loader, loss_function, optimizer, learning_rate, early_stopping=50, epochs=1000):\n",
    "    # Setting up model parameters\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    if optimizer == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    if optimizer == 'AdamW':\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    if optimizer == 'SGD':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    loss_function = loss_function\n",
    "\n",
    "    # Initialising early stopping criterias\n",
    "    early_stopping = early_stopping\n",
    "    notImproved = 0\n",
    "    \n",
    "    bestLoss = None\n",
    "    bestModel = None\n",
    "\n",
    "    trainArr = []\n",
    "    valArr = []\n",
    "\n",
    "    bestf1 = 0\n",
    "    bestEpoch = 0\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "    \n",
    "        train_loss = 0.0\n",
    "        for batch_idx, data in enumerate(train_loader):\n",
    "        \n",
    "            # get the input\n",
    "            inputs, labels = data\n",
    "    \n",
    "            inputs = inputs.to(device).float()\n",
    "            labels = labels.to(device).float()\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.squeeze(1)\n",
    "        \n",
    "            loss = loss_function(outputs, labels)\n",
    "        \n",
    "            loss.backward()\n",
    "        \n",
    "            optimizer.step()\n",
    "        \n",
    "            train_loss += loss.item()\n",
    "    \n",
    "        train_loss /= len(train_loader.dataset)    \n",
    "        trainArr.append(train_loss)\n",
    "    \n",
    "        valid_loss = 0\n",
    "        labs = []\n",
    "        preds = []\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():        \n",
    "            for batch_idx, data in enumerate(valid_loader):\n",
    "                # get the input\n",
    "                inputs, labels = data           \n",
    "            \n",
    "                inputs = inputs.to(device).float()\n",
    "                labels = labels.to(device).float()\n",
    "                \n",
    "                outputs = model(inputs).squeeze()\n",
    "                \n",
    "                labs.extend(labels)\n",
    "                preds.extend(torch.round(outputs))\n",
    "            \n",
    "                valid_loss += loss_function(outputs, labels).item()\n",
    "        \n",
    "        valid_loss /= len(valid_loader.dataset)    \n",
    "        valArr.append(valid_loss)\n",
    "        \n",
    "        if bestLoss == None:\n",
    "            bestLoss = valid_loss\n",
    "    \n",
    "        if valid_loss <= bestLoss:\n",
    "            bestModel = torch.save(model, 'currentModel.pth')\n",
    "            bestLoss = valid_loss\n",
    "            notImproved = 0\n",
    "            bestEpoch = epoch\n",
    "        else:\n",
    "            notImproved +=1\n",
    "        \n",
    "        if notImproved >= early_stopping:\n",
    "            break\n",
    "\n",
    "    model = torch.load('currentModel.pth')\n",
    "    return model, valArr, trainArr, epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58,0.001,BCELoss(),AdamW,4,0.5791666666666667,0.5944444444444444\n",
      "56,0.001,BCELoss(),AdamW,8,0.5777777777777777,0.6208333333333333\n",
      "57,0.001,BCELoss(),AdamW,16,0.5694444444444444,0.5958333333333333\n",
      "61,0.001,BCELoss(),AdamW,32,0.5694444444444444,0.5916666666666667\n",
      "64,0.001,BCELoss(),AdamW,64,0.5708333333333333,0.5958333333333333\n",
      "73,0.001,BCELoss(),Adam,4,0.5847222222222223,0.6152777777777778\n",
      "58,0.001,BCELoss(),Adam,8,0.5763888888888888,0.6166666666666667\n",
      "55,0.001,BCELoss(),Adam,16,0.5888888888888889,0.5861111111111111\n",
      "57,0.001,BCELoss(),Adam,32,0.5652777777777778,0.5819444444444445\n",
      "58,0.001,BCELoss(),Adam,64,0.5486111111111112,0.5708333333333333\n",
      "59,0.001,MSELoss(),AdamW,4,0.5791666666666667,0.6041666666666666\n",
      "57,0.001,MSELoss(),AdamW,8,0.5819444444444445,0.6097222222222223\n",
      "56,0.001,MSELoss(),AdamW,16,0.5791666666666667,0.6166666666666667\n",
      "60,0.001,MSELoss(),AdamW,32,0.5708333333333333,0.5944444444444444\n",
      "65,0.001,MSELoss(),AdamW,64,0.5736111111111111,0.6194444444444445\n",
      "57,0.001,MSELoss(),Adam,4,0.5569444444444445,0.6027777777777777\n",
      "75,0.001,MSELoss(),Adam,8,0.5944444444444444,0.5875\n",
      "66,0.001,MSELoss(),Adam,16,0.5763888888888888,0.6125\n",
      "63,0.001,MSELoss(),Adam,32,0.5875,0.6194444444444445\n",
      "60,0.001,MSELoss(),Adam,64,0.5791666666666667,0.6111111111111112\n",
      "70,0.0001,BCELoss(),AdamW,4,0.5888888888888889,0.6013888888888889\n",
      "70,0.0001,BCELoss(),AdamW,8,0.5819444444444445,0.6083333333333333\n",
      "76,0.0001,BCELoss(),AdamW,16,0.5861111111111111,0.6083333333333333\n",
      "81,0.0001,BCELoss(),AdamW,32,0.5791666666666667,0.6152777777777778\n",
      "90,0.0001,BCELoss(),AdamW,64,0.5652777777777778,0.6\n",
      "66,0.0001,BCELoss(),Adam,4,0.575,0.6111111111111112\n",
      "67,0.0001,BCELoss(),Adam,8,0.5736111111111111,0.6111111111111112\n",
      "71,0.0001,BCELoss(),Adam,16,0.5902777777777778,0.6111111111111112\n",
      "77,0.0001,BCELoss(),Adam,32,0.5791666666666667,0.6138888888888889\n",
      "90,0.0001,BCELoss(),Adam,64,0.575,0.6083333333333333\n",
      "67,0.0001,MSELoss(),AdamW,4,0.5791666666666667,0.6111111111111112\n",
      "68,0.0001,MSELoss(),AdamW,8,0.5902777777777778,0.6138888888888889\n",
      "72,0.0001,MSELoss(),AdamW,16,0.5875,0.6097222222222223\n",
      "78,0.0001,MSELoss(),AdamW,32,0.575,0.6027777777777777\n",
      "101,0.0001,MSELoss(),AdamW,64,0.5638888888888889,0.5972222222222222\n",
      "68,0.0001,MSELoss(),Adam,4,0.5777777777777777,0.6111111111111112\n",
      "68,0.0001,MSELoss(),Adam,8,0.5708333333333333,0.6111111111111112\n",
      "72,0.0001,MSELoss(),Adam,16,0.5777777777777777,0.6055555555555555\n",
      "81,0.0001,MSELoss(),Adam,32,0.5722222222222222,0.6180555555555556\n",
      "92,0.0001,MSELoss(),Adam,64,0.5625,0.5972222222222222\n",
      "76,5e-05,BCELoss(),AdamW,4,0.5791666666666667,0.6138888888888889\n",
      "80,5e-05,BCELoss(),AdamW,8,0.5847222222222223,0.6125\n",
      "94,5e-05,BCELoss(),AdamW,16,0.5805555555555556,0.6125\n",
      "102,5e-05,BCELoss(),AdamW,32,0.575,0.6180555555555556\n",
      "135,5e-05,BCELoss(),AdamW,64,0.5708333333333333,0.6083333333333333\n",
      "77,5e-05,BCELoss(),Adam,4,0.5708333333333333,0.6138888888888889\n",
      "83,5e-05,BCELoss(),Adam,8,0.5763888888888888,0.6125\n",
      "92,5e-05,BCELoss(),Adam,16,0.5736111111111111,0.6069444444444444\n",
      "101,5e-05,BCELoss(),Adam,32,0.5722222222222222,0.6041666666666666\n",
      "125,5e-05,BCELoss(),Adam,64,0.575,0.6055555555555555\n",
      "85,5e-05,MSELoss(),AdamW,4,0.5902777777777778,0.6166666666666667\n",
      "79,5e-05,MSELoss(),AdamW,8,0.5708333333333333,0.6166666666666667\n",
      "96,5e-05,MSELoss(),AdamW,16,0.5777777777777777,0.6111111111111112\n",
      "104,5e-05,MSELoss(),AdamW,32,0.575,0.6027777777777777\n",
      "135,5e-05,MSELoss(),AdamW,64,0.5722222222222222,0.6152777777777778\n",
      "76,5e-05,MSELoss(),Adam,4,0.5694444444444444,0.6152777777777778\n",
      "94,5e-05,MSELoss(),Adam,8,0.5833333333333334,0.6111111111111112\n",
      "93,5e-05,MSELoss(),Adam,16,0.5888888888888889,0.6138888888888889\n",
      "110,5e-05,MSELoss(),Adam,32,0.5763888888888888,0.6027777777777777\n",
      "141,5e-05,MSELoss(),Adam,64,0.5736111111111111,0.6138888888888889\n",
      "171,1e-05,BCELoss(),AdamW,4,0.5819444444444445,0.6125\n",
      "215,1e-05,BCELoss(),AdamW,8,0.5930555555555556,0.6125\n",
      "295,1e-05,BCELoss(),AdamW,16,0.5847222222222223,0.6111111111111112\n",
      "303,1e-05,BCELoss(),AdamW,32,0.5805555555555556,0.6152777777777778\n",
      "53,1e-05,BCELoss(),AdamW,64,0.5,0.5\n",
      "155,1e-05,BCELoss(),Adam,4,0.5847222222222223,0.6125\n",
      "215,1e-05,BCELoss(),Adam,8,0.5916666666666667,0.6166666666666667\n",
      "313,1e-05,BCELoss(),Adam,16,0.5888888888888889,0.6013888888888889\n",
      "347,1e-05,BCELoss(),Adam,32,0.5736111111111111,0.6069444444444444\n",
      "65,1e-05,BCELoss(),Adam,64,0.5,0.5\n",
      "162,1e-05,MSELoss(),AdamW,4,0.5777777777777777,0.6152777777777778\n",
      "207,1e-05,MSELoss(),AdamW,8,0.5819444444444445,0.6111111111111112\n",
      "263,1e-05,MSELoss(),AdamW,16,0.5902777777777778,0.6166666666666667\n",
      "393,1e-05,MSELoss(),AdamW,32,0.5847222222222223,0.6097222222222223\n",
      "57,1e-05,MSELoss(),AdamW,64,0.5,0.5\n",
      "162,1e-05,MSELoss(),Adam,4,0.5888888888888889,0.6138888888888889\n",
      "202,1e-05,MSELoss(),Adam,8,0.5791666666666667,0.6125\n",
      "295,1e-05,MSELoss(),Adam,16,0.5833333333333334,0.6166666666666667\n",
      "363,1e-05,MSELoss(),Adam,32,0.5875,0.6055555555555555\n",
      "442,1e-05,MSELoss(),Adam,64,0.575,0.6138888888888889\n",
      "299,5e-06,BCELoss(),AdamW,4,0.5805555555555556,0.6166666666666667\n",
      "365,5e-06,BCELoss(),AdamW,8,0.5777777777777777,0.6236111111111111\n",
      "546,5e-06,BCELoss(),AdamW,16,0.5875,0.6111111111111112\n",
      "790,5e-06,BCELoss(),AdamW,32,0.5888888888888889,0.6125\n",
      "945,5e-06,BCELoss(),AdamW,64,0.575,0.6097222222222223\n",
      "308,5e-06,BCELoss(),Adam,4,0.5819444444444445,0.6111111111111112\n",
      "411,5e-06,BCELoss(),Adam,8,0.5916666666666667,0.6111111111111112\n",
      "479,5e-06,BCELoss(),Adam,16,0.5777777777777777,0.6166666666666667\n",
      "676,5e-06,BCELoss(),Adam,32,0.5777777777777777,0.6111111111111112\n",
      "51,5e-06,BCELoss(),Adam,64,0.5,0.5\n",
      "289,5e-06,MSELoss(),AdamW,4,0.5819444444444445,0.6013888888888889\n",
      "425,5e-06,MSELoss(),AdamW,8,0.5819444444444445,0.6152777777777778\n",
      "475,5e-06,MSELoss(),AdamW,16,0.5902777777777778,0.6027777777777777\n",
      "782,5e-06,MSELoss(),AdamW,32,0.5791666666666667,0.6194444444444445\n",
      "51,5e-06,MSELoss(),AdamW,64,0.5,0.5\n",
      "275,5e-06,MSELoss(),Adam,4,0.5833333333333334,0.6166666666666667\n",
      "383,5e-06,MSELoss(),Adam,8,0.5847222222222223,0.6138888888888889\n",
      "486,5e-06,MSELoss(),Adam,16,0.5861111111111111,0.6097222222222223\n",
      "708,5e-06,MSELoss(),Adam,32,0.5861111111111111,0.6097222222222223\n",
      "51,5e-06,MSELoss(),Adam,64,0.5,0.5\n",
      "1299,1e-06,BCELoss(),AdamW,4,0.5861111111111111,0.6208333333333333\n",
      "1608,1e-06,BCELoss(),AdamW,8,0.5861111111111111,0.6138888888888889\n",
      "2267,1e-06,BCELoss(),AdamW,16,0.5958333333333333,0.6097222222222223\n",
      "3341,1e-06,BCELoss(),AdamW,32,0.5805555555555556,0.6097222222222223\n",
      "105,1e-06,BCELoss(),AdamW,64,0.5,0.5\n",
      "1289,1e-06,BCELoss(),Adam,4,0.5888888888888889,0.6152777777777778\n",
      "1595,1e-06,BCELoss(),Adam,8,0.5888888888888889,0.6097222222222223\n",
      "2753,1e-06,BCELoss(),Adam,16,0.5875,0.6069444444444444\n",
      "2981,1e-06,BCELoss(),Adam,32,0.5888888888888889,0.5986111111111111\n",
      "90,1e-06,BCELoss(),Adam,64,0.5,0.5\n",
      "1239,1e-06,MSELoss(),AdamW,4,0.5833333333333334,0.6055555555555555\n",
      "1870,1e-06,MSELoss(),AdamW,8,0.5819444444444445,0.6097222222222223\n",
      "2609,1e-06,MSELoss(),AdamW,16,0.5930555555555556,0.6111111111111112\n",
      "2979,1e-06,MSELoss(),AdamW,32,0.6,0.6083333333333333\n",
      "3122,1e-06,MSELoss(),AdamW,64,0.5875,0.6027777777777777\n",
      "1197,1e-06,MSELoss(),Adam,4,0.5875,0.6097222222222223\n",
      "1932,1e-06,MSELoss(),Adam,8,0.5930555555555556,0.6166666666666667\n",
      "2233,1e-06,MSELoss(),Adam,16,0.5958333333333333,0.6138888888888889\n",
      "3731,1e-06,MSELoss(),Adam,32,0.5708333333333333,0.6208333333333333\n",
      "51,1e-06,MSELoss(),Adam,64,0.5,0.5\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.001, 0.0001, 0.00005, 0.00001, 0.000005, 0.000001]\n",
    "loss_functions = [nn.BCELoss(), nn.MSELoss()]\n",
    "optimizers = ['AdamW', 'Adam']\n",
    "batch_sizes = [4, 8, 16, 32, 64]\n",
    "\n",
    "valArr = None\n",
    "trainArr = None\n",
    "bestLoss = None\n",
    "bestAcc = 0\n",
    "\n",
    "with open('GridSearchResults', 'w') as f:\n",
    "    f.write('epoch, learning rate, loss_function, optimizer, batch_size, Val accuracy, Test accuracy')\n",
    "    f.write('\\n')\n",
    "    f.close()\n",
    "    \n",
    "    for lr in learning_rates:\n",
    "        for loss_function in loss_functions:\n",
    "            for optimizer in optimizers:\n",
    "                for batch_size in batch_sizes:\n",
    "\n",
    "                    # Creating loaders\n",
    "                    train_loader = torch.utils.data.DataLoader(prepare_trainloader, batch_size=batch_size, shuffle=True)\n",
    "                    valid_loader = torch.utils.data.DataLoader(prepare_validloader, batch_size=batch_size, shuffle=False)\n",
    "                    test_loader = torch.utils.data.DataLoader(prepare_testloader, batch_size=batch_size, shuffle=False)               \n",
    "\n",
    "                    model, valLossArr , trainLossArr, epoch = Train(Net(), train_loader,\n",
    "                                                                 valid_loader, loss_function,\n",
    "                                                                 optimizer, lr, early_stopping=50, epochs=5000)\n",
    "\n",
    "                    labs = []\n",
    "                    preds = []\n",
    "                    model.eval()\n",
    "                    with torch.no_grad():        \n",
    "                        for batch_idx, data in enumerate(valid_loader):\n",
    "                            inputs, labels = data\n",
    "                            inputs = inputs.to(device).float()\n",
    "                            labels = labels.to(device).float()\n",
    "                            outputs = model(inputs).squeeze()\n",
    "                            labs.extend(labels)\n",
    "                            preds.extend(torch.round(outputs))\n",
    "                    accVal = CheckAccuracy(labs, preds)\n",
    "                    #print(\"Accuracy on validation set: \", accVal)\n",
    "\n",
    "                    labs = []\n",
    "                    preds = []\n",
    "                    model.eval()\n",
    "                    with torch.no_grad():        \n",
    "                        for batch_idx, data in enumerate(test_loader):\n",
    "                            inputs, labels = data\n",
    "                            inputs = inputs.to(device).float()\n",
    "                            labels = labels.to(device).float()\n",
    "                            outputs = model(inputs).squeeze()\n",
    "                            labs.extend(labels)\n",
    "                            preds.extend(torch.round(outputs))\n",
    "                    accTest = CheckAccuracy(labs, preds)\n",
    "                    #print(\"Accuracy on Test set: \", accTest)\n",
    "\n",
    "                    currModelValLoss = np.min(valLossArr)    \n",
    "                    if bestLoss == None:\n",
    "                        bestLoss = currModelValLoss\n",
    "\n",
    "                    if accVal > bestAcc:\n",
    "                        bestAcc = accVal\n",
    "                        bestLoss = currModelValLoss\n",
    "                        valArr = valLossArr\n",
    "                        trainArr = trainLossArr\n",
    "\n",
    "                    elif accVal >= bestAcc and currModelValLoss < bestLoss:\n",
    "                        bestAcc = accVal\n",
    "                        bestLoss = currModelValLoss\n",
    "                        valArr = valLossArr\n",
    "                        trainArr = trainLossArr\n",
    "                    \n",
    "                    with open('GridSearchResults', 'a') as f:\n",
    "                        print(str(epoch)+\",\"+str(lr)+\",\"+ str(loss_function) + \",\" + optimizer + \",\" + str(batch_size) + \",\" + str(accVal) + \",\" + str(accTest))\n",
    "                        f.write(str(epoch)+\",\"+str(lr)+\",\"+ str(loss_function) + \",\" + optimizer + \",\" + str(batch_size) + \",\" + str(accVal) + \",\" + str(accTest))\n",
    "                        f.write('\\n')\n",
    "                        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "epoch                 2979\n",
       "learning rate        1e-06\n",
       "loss_function    MSELoss()\n",
       "optimizer            AdamW\n",
       "batch_size              32\n",
       "Val accuracy           0.6\n",
       "Test accuracy     0.608333\n",
       "Name: 113, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the best model from the generated csv file\n",
    "results = pd.read_csv('GridSearchResultsFinal')\n",
    "\n",
    "results.loc[np.argmax(results['Val accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.scatter(np.arange(0,len(trainArr)), trainArr, color='r', label='Training loss')\n",
    "plt.scatter(np.arange(0,len(valArr)), valArr, color='g', label='Validation loss')\n",
    "plt.title(\"Training loss vs Validation loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_Scores(preds, labels):\n",
    "    true_positives = 0\n",
    "    true_negatives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "    for i in range(len(labs)):\n",
    "        if labels[i]==1 and preds[i]==1:\n",
    "            true_positives += 1\n",
    "        if labels[i]==0 and preds[i]==0:\n",
    "            true_negatives += 1\n",
    "        if labels[i]==0 and preds[i]==1:\n",
    "            false_positives += 1\n",
    "        if labels[i]==1 and preds[i]==0:\n",
    "            false_negatives += 1\n",
    "    print(\"true_positives\", true_positives)\n",
    "    print(\"true_negatives\", true_negatives)\n",
    "    print(\"false_positives\", false_positives)\n",
    "    print(\"false_negatives\", false_negatives)\n",
    "    \n",
    "    return true_positives, true_negatives, false_positives, false_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set:  0.6138888888888889\n",
      "Accuracy on validation set:  0.5805555555555556\n",
      "Accuracy on train set:  0.643661971830986\n"
     ]
    }
   ],
   "source": [
    "labs = []\n",
    "preds = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():        \n",
    "    for batch_idx, data in enumerate(test_loader):\n",
    "        # get the input\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.unsqueeze(1)\n",
    "        inputs = inputs.to(device).float()\n",
    "        labels = labels.to(device).float()\n",
    "        \n",
    "        outputs = model(inputs).squeeze()\n",
    "        \n",
    "        labs.extend(labels)\n",
    "        preds.extend(torch.round(outputs))\n",
    "        \n",
    "print(\"Accuracy on test set: \", CheckAccuracy(labs, preds))\n",
    "#f1 = f1_score(torch.Tensor(labs).numpy(), torch.Tensor(preds).numpy(), zero_division=1)\n",
    "#print(\"F1_score test: \", f1)\n",
    "#true_positives, true_negatives, false_positives, false_negatives = F1_Scores(preds, labs)\n",
    "\n",
    "labs = []\n",
    "preds = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():        \n",
    "    for batch_idx, data in enumerate(valid_loader):\n",
    "        # get the input\n",
    "        inputs, labels = data\n",
    "        \n",
    "        inputs = inputs.to(device).float()\n",
    "        labels = labels.to(device).float()\n",
    "        \n",
    "        outputs = model(inputs).squeeze()\n",
    "        \n",
    "        labs.extend(labels)\n",
    "        preds.extend(torch.round(outputs))\n",
    "        \n",
    "print(\"Accuracy on validation set: \", CheckAccuracy(labs, preds))\n",
    "#f1 = f1_score(torch.Tensor(labs).numpy(), torch.Tensor(preds).numpy(), zero_division=1)\n",
    "#print(\"F1_score val: \", f1)\n",
    "#true_positives, true_negatives, false_positives, false_negatives = F1_Scores(preds, labs)\n",
    "\n",
    "labs = []\n",
    "preds = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():        \n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        # get the input\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.unsqueeze(1)\n",
    "        inputs = inputs.to(device).float()\n",
    "        labels = labels.to(device).float()\n",
    "        \n",
    "        outputs = model(inputs).squeeze()\n",
    "        \n",
    "        labs.extend(labels)\n",
    "        preds.extend(torch.round(outputs))\n",
    "        \n",
    "print(\"Accuracy on train set: \", CheckAccuracy(labs, preds))\n",
    "#f1 = f1_score(torch.Tensor(labs).numpy(), torch.Tensor(preds).numpy(), zero_division=1)\n",
    "#print(\"F1_score train: \", f1)\n",
    "#true_positives, true_negatives, false_positives, false_negatives = F1_Scores(preds, labs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
