{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "boxed-burns",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import AutoModel, AutoTokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adjustable-experiment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CleanText(text):\n",
    "    text = re.sub(r'''[\\[|\\]]''', \"\", text).split()\n",
    "    text = np.array(text, dtype=\"float64\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "raw",
   "id": "stunning-invitation",
   "metadata": {},
   "source": [
    "def CleanText(text):\n",
    "    text = text.lower() #Turn all text entries into lower-case\n",
    "    text = re.sub(r'''(https?:\\/\\/www\\.|https?:\\/\\/)?[a-z0-9]+([\\-\\.]{1}[a-z0-9]+)*\\.[a-z]{2,3}[-a-zA-Z0-9()@:%_\\+.~#?&\\//=<>]*''', \"<URL>\", text)\n",
    "    #Replace URL with tag\n",
    "    text = re.sub(r'''[0-9]+[/\\-.]+[0-9]+[/\\-.]+[0-9]+''', \"<DATE>\", text) #Replace dates with tag\n",
    "    text = re.sub(r'''[a-z0-9._%+-]+\\@[a-z0-9.-]+[a-z0-9]\\.[a-z]{1,}''', \"<EMAIL>\", text)\n",
    "    #text = re.sub(r'''[0-9]+''', \"<NUM>\", text) #Replace numbers with tag\n",
    "    text = re.sub(r'''[.|,|!|?|\\'|\\''|\\\"|\\n|\\t|\\-|\\(|\\)]''', '', text)\n",
    "    text = re.sub(r'''^\\s+|\\s+$''', '', text) #Remove whitespaces at the end and start of string\n",
    "    text = re.sub(r'''[ ][ ]+|_''', \" \", text) #Remove multiple whitespace\n",
    "    if len(text) <= 0:\n",
    "        text = re.sub(r'''''', \"0\", text) #Remove multiple whitespace\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-soviet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-weather",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "nasty-horse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal dataset\n",
    "df = pd.read_csv('smallDomainDataBertweetEmbedded.csv')\n",
    "\n",
    "# Epsilon 0,1 fair dataset\n",
    "#df = pd.read_csv(\"domain_data_with_identities_private_xtrain0,1.csv\")\n",
    "\n",
    "# Epsilon 0,01 fair dataset\n",
    "#df = pd.read_csv(\"domain_data_with_identities_private_xtrain0,1.csv\")\n",
    "\n",
    "df['comment_text'] = df['comment_text'].apply(lambda text: CleanText(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "damaged-electronics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dimensional-aerospace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating values for training_data\n",
    "training_data = df[df['split'] == 'train']\n",
    "#training_data = training_data.drop(training_data.query('toxicity==0').sample(frac=.85).index)\n",
    "\n",
    "# Getting test_data\n",
    "test_data = df[df['split'] == 'test']\n",
    "\n",
    "# Getting validation_data\n",
    "validation_data = df[df['split'] == 'val']\n",
    "#validation_data = validation_data.drop(validation_data.query('toxicity==0').sample(frac=.85).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "identical-rendering",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxic samples training data:  710\n",
      "None-toxic samples training data:  710\n",
      "\n",
      "\n",
      "Toxic samples validation data:  360\n",
      "None-toxic samples validation data:  360\n",
      "\n",
      "\n",
      "Toxic samples test data:  360\n",
      "None-toxic samples test data:  360\n",
      "\n",
      "\n",
      "male: 322.0\n",
      "female: 276.0\n",
      "LGBTQ: 234.0\n",
      "christian: 214.0\n",
      "muslim: 236.0\n",
      "other_religion: 20.0\n",
      "black: 250.0\n",
      "white: 370.0\n"
     ]
    }
   ],
   "source": [
    "print('Toxic samples training data: ', sum(training_data['toxicity']))\n",
    "print('None-toxic samples training data: ', len(training_data['toxicity'])-sum(training_data['toxicity']))\n",
    "\n",
    "print(\"\\n\")\n",
    "print('Toxic samples validation data: ', sum(validation_data['toxicity']))\n",
    "print('None-toxic samples validation data: ', len(validation_data['toxicity'])-sum(validation_data['toxicity']))\n",
    "\n",
    "print(\"\\n\")\n",
    "print('Toxic samples test data: ', sum(test_data['toxicity']))\n",
    "print('None-toxic samples test data: ', len(test_data['toxicity'])-sum(test_data['toxicity']))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "for col in training_data.columns[3:]:\n",
    "    print(col + \": \" + str(np.sum(training_data[col])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-school",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "renewable-conservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating data loaders\n",
    "X_train = np.array(training_data['comment_text'].values.tolist())\n",
    "Y_train = np.array(training_data['toxicity'].values.tolist())\n",
    "\n",
    "X_test = np.array(test_data['comment_text'].values.tolist())\n",
    "Y_test = np.array(test_data['toxicity'].values.tolist())\n",
    "\n",
    "X_val = np.array(validation_data['comment_text'].values.tolist())\n",
    "Y_val = np.array(validation_data['toxicity'].values.tolist())\n",
    "\n",
    "prepare_trainloader = []\n",
    "for i in range(len(X_train)):\n",
    "    prepare_trainloader.append([X_train[i], Y_train[i]])\n",
    "    \n",
    "prepare_testloader = []\n",
    "for i in range(len(X_test)):\n",
    "    prepare_testloader.append([X_test[i], Y_test[i]])\n",
    "    \n",
    "prepare_validloader = []\n",
    "for i in range(len(X_val)):\n",
    "    prepare_validloader.append([X_val[i], Y_val[i]])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(prepare_trainloader, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(prepare_validloader, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(prepare_testloader, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-determination",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-grounds",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-quality",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "starting-index",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device(type='cuda')\n"
     ]
    }
   ],
   "source": [
    "### Set parameters for the model\n",
    "#torch.manual_seed(42) # set fixed random seed for reproducibility\n",
    "batch_size = 16\n",
    "epochs = 1000\n",
    "lr = 0.00001\n",
    "\n",
    "cuda = True # Set this if training on GPU\n",
    "cuda = cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "print(\"Using \"+repr(device))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "completed-australia",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-angel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "handmade-cleveland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CheckAccuracy(predictions, labels):\n",
    "        acc = 0.0\n",
    "        for i in range(len(predictions)):\n",
    "            if (predictions[i] == labels[i]):\n",
    "                acc += 1\n",
    "        return acc/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "returning-equilibrium",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Sequential(nn.Linear(768, 64), nn.ReLU(), nn.Dropout(p=0.8))\n",
    "        self.fc2 = nn.Sequential(nn.Linear(64, 32), nn.ReLU())\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        #self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "electrical-consumption",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233\n"
     ]
    }
   ],
   "source": [
    "# Setting up model parameters\n",
    "model = Net().to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "loss_function = nn.BCELoss()\n",
    "#loss_function = nn.MSELoss()\n",
    "#loss_function = nn.NLLLoss()\n",
    "\n",
    "# Initialising early stopping criterias\n",
    "early_stopping = 50\n",
    "notImproved = 0\n",
    "bestLoss = None\n",
    "bestModel = None\n",
    "\n",
    "trainArr = []\n",
    "valArr = []\n",
    "\n",
    "bestf1 = 0\n",
    "bestEpoch = 0\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    \n",
    "    train_loss = 0.0\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        \n",
    "        # get the input\n",
    "        inputs, labels = data\n",
    "    \n",
    "        inputs = inputs.to(device).float()\n",
    "        labels = labels.to(device).float()\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs.squeeze(1)\n",
    "        \n",
    "        loss = loss_function(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    \n",
    "    \n",
    "    trainArr.append(train_loss)\n",
    "    \n",
    "    valid_loss = 0\n",
    "    labs = []\n",
    "    preds = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():        \n",
    "        for batch_idx, data in enumerate(valid_loader):\n",
    "            # get the input\n",
    "            inputs, labels = data\n",
    "            \n",
    "            inputs = inputs.to(device).float()\n",
    "            #labels = labels.to(device).long()\n",
    "            labels = labels.to(device).float()\n",
    "            \n",
    "            outputs = model(inputs).squeeze()\n",
    "            \n",
    "            labs.extend(labels)\n",
    "            preds.extend(torch.round(outputs))\n",
    "            #preds.extend(outputs.argmax(axis=1))\n",
    "            \n",
    "            valid_loss += loss_function(outputs, labels).item()\n",
    "    \n",
    "    valid_loss /= len(valid_loader.dataset)\n",
    "    \n",
    "    valArr.append(valid_loss)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #if epoch % 10 == 0:\n",
    "        #print('====> Validation set loss: {:.6f}'.format(valid_loss))\n",
    "    \n",
    "        #print(\"Accuracy on Validation set: \", CheckAccuracy(labs, preds))\n",
    "    \n",
    "    #f1 = f1_score(torch.Tensor(labs).numpy(), torch.Tensor(preds).numpy(), zero_division=1)\n",
    "    #print(\"F1_score: \", f1)\n",
    "    \n",
    "    #if f1 > bestf1:\n",
    "    #    bestModel = model\n",
    "    #    bestf1 = f1\n",
    "    #    notImproved = 0\n",
    "    #    bestEpoch = epoch\n",
    "    \n",
    "    if bestLoss == None:\n",
    "        bestLoss = valid_loss\n",
    "    \n",
    "    \n",
    "    if valid_loss <= bestLoss:\n",
    "        bestModel = model\n",
    "        bestLoss = valid_loss\n",
    "        notImproved = 0\n",
    "        bestEpoch = epoch\n",
    "    \n",
    "    else:\n",
    "        notImproved +=1\n",
    "        \n",
    "    if notImproved >= early_stopping:\n",
    "        break\n",
    "        \n",
    "    \n",
    "    # Initialising params for early stopping\n",
    "    #if bestLoss == None:\n",
    "    #    bestLoss = valid_loss\n",
    "        \n",
    "    # Checks for early stopping\n",
    "    #if f1 < bestf1:\n",
    "    #    bestLoss = valid_loss\n",
    "        \n",
    "    # Converges if the training has not improved for a certain amount of iterations\n",
    "    \n",
    "\n",
    "model = bestModel\n",
    "\n",
    "print(bestEpoch)\n",
    "\n",
    "#torch.save(model, 'bestModelFullyConnectedNetwork0,1Fair.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "announced-family",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.scatter(np.arange(0,len(trainArr)), trainArr, color='r', label='Training loss')\n",
    "plt.scatter(np.arange(0,len(valArr)), valArr, color='g', label='Validation loss')\n",
    "plt.title(\"Training loss vs Validation loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "approved-direction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_Scores(preds, labels):\n",
    "    true_positives = 0\n",
    "    true_negatives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "    for i in range(len(labs)):\n",
    "        if labels[i]==1 and preds[i]==1:\n",
    "            true_positives += 1\n",
    "        if labels[i]==0 and preds[i]==0:\n",
    "            true_negatives += 1\n",
    "        if labels[i]==0 and preds[i]==1:\n",
    "            false_positives += 1\n",
    "        if labels[i]==1 and preds[i]==0:\n",
    "            false_negatives += 1\n",
    "    print(\"true_positives\", true_positives)\n",
    "    print(\"true_negatives\", true_negatives)\n",
    "    print(\"false_positives\", false_positives)\n",
    "    print(\"false_negatives\", false_negatives)\n",
    "    \n",
    "    return true_positives, true_negatives, false_positives, false_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "finnish-gabriel",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set:  0.6083333333333333\n",
      "F1_score:  0.607242339832869\n",
      "Accuracy on validation set:  0.5972222222222222\n",
      "Accuracy on train set:  0.6272727272727273\n",
      "true_positives 904\n",
      "true_negatives 890\n",
      "false_positives 540\n",
      "false_negatives 526\n"
     ]
    }
   ],
   "source": [
    "labs = []\n",
    "preds = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():        \n",
    "    for batch_idx, data in enumerate(test_loader):\n",
    "        # get the input\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.unsqueeze(1)\n",
    "        inputs = inputs.to(device).float()\n",
    "        labels = labels.to(device).float()\n",
    "        \n",
    "        outputs = model(inputs).squeeze()\n",
    "        \n",
    "        labs.extend(labels)\n",
    "        preds.extend(torch.round(outputs))\n",
    "        \n",
    "print(\"Accuracy on test set: \", CheckAccuracy(labs, preds))\n",
    "\n",
    "f1 = f1_score(torch.Tensor(labs).numpy(), torch.Tensor(preds).numpy(), zero_division=1)\n",
    "print(\"F1_score: \", f1)\n",
    "\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():        \n",
    "    for batch_idx, data in enumerate(valid_loader):\n",
    "        # get the input\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.unsqueeze(1)\n",
    "        inputs = inputs.to(device).float()\n",
    "        labels = labels.to(device).float()\n",
    "        \n",
    "        outputs = model(inputs).squeeze()\n",
    "        \n",
    "        labs.extend(labels)\n",
    "        preds.extend(torch.round(outputs))\n",
    "        \n",
    "print(\"Accuracy on validation set: \", CheckAccuracy(labs, preds))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():        \n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        # get the input\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.unsqueeze(1)\n",
    "        inputs = inputs.to(device).float()\n",
    "        labels = labels.to(device).float()\n",
    "        \n",
    "        outputs = model(inputs).squeeze()\n",
    "        \n",
    "        labs.extend(labels)\n",
    "        preds.extend(torch.round(outputs))\n",
    "        \n",
    "print(\"Accuracy on train set: \", CheckAccuracy(labs, preds))\n",
    "\n",
    "\n",
    "\n",
    "true_positives, true_negatives, false_positives, false_negatives = F1_Scores(preds, labs)\n",
    "\n",
    "#print(\"Toxic accuracy: \", true_positives/5640)\n",
    "#print(\"Non-toxic accuracy: \", true_negatives/42235)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-jesus",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-attention",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-penalty",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "billion-toyota",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001\n",
      "F1_score:  0.6660465116279071\n",
      "0.5013888888888889\n",
      "\n",
      "\n",
      "0.001\n",
      "F1_score:  0.011049723756906079\n",
      "0.5027777777777778\n",
      "\n",
      "\n",
      "0.01\n",
      "F1_score:  0.0\n",
      "0.5\n",
      "\n",
      "\n",
      "0.1\n",
      "F1_score:  0.1268292682926829\n",
      "0.5027777777777778\n",
      "\n",
      "\n",
      "1\n",
      "F1_score:  0.47692307692307695\n",
      "0.5277777777777778\n",
      "\n",
      "\n",
      "10\n",
      "F1_score:  0.4914586070959264\n",
      "0.4625\n",
      "\n",
      "\n",
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frede\\anaconda3\\lib\\site-packages\\diffprivlib\\models\\logistic_regression.py:221: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n",
      "C:\\Users\\frede\\anaconda3\\lib\\site-packages\\diffprivlib\\models\\logistic_regression.py:221: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n",
      "C:\\Users\\frede\\anaconda3\\lib\\site-packages\\diffprivlib\\models\\logistic_regression.py:221: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n",
      "C:\\Users\\frede\\anaconda3\\lib\\site-packages\\diffprivlib\\models\\logistic_regression.py:221: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n",
      "C:\\Users\\frede\\anaconda3\\lib\\site-packages\\diffprivlib\\models\\logistic_regression.py:221: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n",
      "C:\\Users\\frede\\anaconda3\\lib\\site-packages\\diffprivlib\\models\\logistic_regression.py:221: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n",
      "C:\\Users\\frede\\anaconda3\\lib\\site-packages\\diffprivlib\\models\\logistic_regression.py:221: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score:  0.545945945945946\n",
      "0.5333333333333333\n",
      "\n",
      "\n",
      "40\n",
      "F1_score:  0.5702364394993046\n",
      "0.5708333333333333\n",
      "\n",
      "\n",
      "50\n",
      "F1_score:  0.5563093622795116\n",
      "0.5458333333333333\n",
      "\n",
      "\n",
      "60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frede\\anaconda3\\lib\\site-packages\\diffprivlib\\models\\logistic_regression.py:221: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n",
      "C:\\Users\\frede\\anaconda3\\lib\\site-packages\\diffprivlib\\models\\logistic_regression.py:394: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"lbfgs failed to converge. Increase the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\frede\\anaconda3\\lib\\site-packages\\diffprivlib\\models\\logistic_regression.py:221: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n",
      "C:\\Users\\frede\\anaconda3\\lib\\site-packages\\diffprivlib\\models\\logistic_regression.py:394: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"lbfgs failed to converge. Increase the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\frede\\anaconda3\\lib\\site-packages\\diffprivlib\\models\\logistic_regression.py:221: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score:  0.5729877216916781\n",
      "0.5652777777777778\n",
      "\n",
      "\n",
      "70\n",
      "F1_score:  0.5950413223140496\n",
      "0.5916666666666667\n",
      "\n",
      "\n",
      "80\n",
      "F1_score:  0.5778401122019634\n",
      "0.5819444444444445\n",
      "\n",
      "\n",
      "90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frede\\anaconda3\\lib\\site-packages\\diffprivlib\\models\\logistic_regression.py:221: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n",
      "C:\\Users\\frede\\anaconda3\\lib\\site-packages\\diffprivlib\\models\\logistic_regression.py:394: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"lbfgs failed to converge. Increase the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\frede\\anaconda3\\lib\\site-packages\\diffprivlib\\models\\logistic_regression.py:221: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n",
      "C:\\Users\\frede\\anaconda3\\lib\\site-packages\\diffprivlib\\models\\logistic_regression.py:394: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"lbfgs failed to converge. Increase the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\frede\\anaconda3\\lib\\site-packages\\diffprivlib\\models\\logistic_regression.py:221: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score:  0.5685425685425686\n",
      "0.5847222222222223\n",
      "\n",
      "\n",
      "1000\n",
      "F1_score:  0.5977961432506887\n",
      "0.5944444444444444\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frede\\anaconda3\\lib\\site-packages\\diffprivlib\\models\\logistic_regression.py:394: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"lbfgs failed to converge. Increase the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\frede\\anaconda3\\lib\\site-packages\\diffprivlib\\models\\logistic_regression.py:221: PrivacyLeakWarning: Data norm has not been specified and will be calculated on the data provided.  This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify `data_norm` at initialisation.\n",
      "  warnings.warn(\"Data norm has not been specified and will be calculated on the data provided.  This will \"\n",
      "C:\\Users\\frede\\anaconda3\\lib\\site-packages\\diffprivlib\\models\\logistic_regression.py:394: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"lbfgs failed to converge. Increase the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from diffprivlib.models import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "epsilons = [0.0001, 0.001, 0.01, 0.1, 1, 10, 30, 40, 50, 60, 70, 80, 90, 1000]\n",
    "\n",
    "\n",
    "\n",
    "for eps in epsilons:\n",
    "    print(eps)\n",
    "    clf = LogisticRegression(epsilon=eps)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "    f1 = f1_score(predictions, Y_test, zero_division=1)\n",
    "    \n",
    "    print(\"F1_score: \", f1)\n",
    "    \n",
    "    print(clf.score(X_test, Y_test))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    #F1_Scores(predictions, Y_test)\n",
    "\n",
    "#predictions = np.array(predictions).reshape(len(predictions), 1)\n",
    "#Y_test = np.array(Y_test).reshape(len(Y_test), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-adrian",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
